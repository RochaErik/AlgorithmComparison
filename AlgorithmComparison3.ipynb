{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RochaErik/AlgorithmComparison/blob/main/AlgorithmComparison3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eemeaAaCsyS"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7sPV5hJCeJ2"
      },
      "source": [
        "# **Evaluating algorithms with hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knwYV1QmCuEU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnwsW6x9w1QO",
        "outputId": "fad3ad0d-f838-4cfe-e95c-f8295d5fd365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (1.2.1)\n",
            "Requirement already satisfied: graphviz in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (3.7.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (2.1.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (1.11.2)\n",
            "Requirement already satisfied: plotly in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (5.16.1)\n",
            "Requirement already satisfied: six in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (6.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.16.2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from lightgbm) (1.11.2)\n",
            "Requirement already satisfied: xgboost in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from xgboost) (1.11.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install lightgbm\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sp9bGvxdqiOw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import scipy.stats as stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB5jc4iDCWZI",
        "outputId": "a417925a-0c0b-4a02-e9a2-ca428226ab51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (1.11.2)\n",
            "Requirement already satisfied: six in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (3.1)\n",
            "Requirement already satisfied: future in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (4.66.1)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pnmKn_fsDTha"
      },
      "outputs": [],
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByCnDDmkDayW"
      },
      "source": [
        "# **Wine Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "23mGy-W6DZLy"
      },
      "outputs": [],
      "source": [
        "wine_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Wine\\wine.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "C0N1S4LWDnbw"
      },
      "outputs": [],
      "source": [
        "X = wine_df.iloc[:, 1:]\n",
        "y = wine_df.iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "omlj8qxkDoM1"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "bEtKdQvTEsAR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcZuN-z4CdXh",
        "outputId": "ee31c32a-6b6b-467e-f741-153da73f7c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 750.0,\n",
              " 'learning_rate': 0.021785402162209068,\n",
              " 'max_depth': 3.0,\n",
              " 'max_features': None,\n",
              " 'min_samples_leaf': 2.0,\n",
              " 'min_samples_split': 2.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['AdaBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'criterion': 'friedman_mse',\n",
              " 'max_features': 'sqrt',\n",
              " 'n_estimators': 100,\n",
              " 'learning_rate': 0.04102652661864284,\n",
              " 'max_depth': 3,\n",
              " 'min_samples_split': 7,\n",
              " 'min_samples_leaf': 7,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'min_impurity_decrease': 1.0,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['GradBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 550,\n",
              " 'learning_rate': 0.0479901225935416,\n",
              " 'min_child_samples': 1,\n",
              " 'max_depth': 6,\n",
              " 'reg_lambda': 3.3766279624518107,\n",
              " 'silent': True,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['CatBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'class_weight': 'balanced',\n",
              " 'boosting_type': 'gbdt',\n",
              " 'num_leaves': 55,\n",
              " 'learning_rate': 0.04496177447997528,\n",
              " 'min_child_samples': 10,\n",
              " 'reg_alpha': 0.3916912792044354,\n",
              " 'reg_lambda': 1.4941077467431771,\n",
              " 'colsample_by_tree': 0.379259630420579,\n",
              " 'verbosity': -1,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['LightGBM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'booster': 'dart',\n",
              " 'learning_rate': 0.09292666170093178,\n",
              " 'gamma': 4,\n",
              " 'max_depth': 4,\n",
              " 'min_child_weight': 1,\n",
              " 'colsample_bytree': 0.8943278668489419,\n",
              " 'colsample_bylevel': 0.2640104690942444,\n",
              " 'colsample_bynode': 0.8937107554719765,\n",
              " 'reg_alpha': 0.056770729092546546,\n",
              " 'reg_lambda': 4.219736540591216,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiGBWUhXmjty"
      },
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7JQf94WmaZT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Wine Dataset ---------\n",
            "[1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 0.94444444 1.         1.         0.94444444 1.         1.\n",
            " 1.         0.94117647 1.         1.         0.88888889 1.\n",
            " 1.         1.         1.         1.         0.94117647 1.\n",
            " 0.94444444 1.         1.         0.94444444 1.         1.\n",
            " 1.         1.         1.         0.94117647 0.94444444 1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 0.94117647 1.         1.         1.         1.         0.94444444\n",
            " 1.         1.         0.94444444 1.         1.         0.94117647\n",
            " 1.         1.         0.94444444 1.         1.         1.\n",
            " 0.94444444 0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 0.94117647 1.         1.         0.94444444 1.         0.94444444\n",
            " 1.         1.         1.         1.         0.94117647 1.\n",
            " 1.         0.94444444 1.         0.94444444 1.         0.88888889\n",
            " 0.94444444 1.         1.         1.        ]\n",
            "Accuracy: 98.14% (3.08%)\n",
            "------------------------------\n",
            "--------- GradBoost on Wine Dataset ---------\n",
            "[1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94444444 0.94444444\n",
            " 1.         0.94117647 1.         1.         0.88888889 0.94444444\n",
            " 1.         1.         1.         1.         0.94117647 0.88235294\n",
            " 0.94444444 1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.82352941 1.         1.\n",
            " 1.         0.94444444 1.         0.94444444 1.         1.\n",
            " 0.94117647 1.         1.         0.94444444 0.94444444 1.\n",
            " 1.         1.         1.         0.94444444 1.         0.94117647\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94117647 1.         1.         1.         0.94444444\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 0.94444444 0.94444444 0.94117647 1.        ]\n",
            "Accuracy: 98.08% (3.44%)\n",
            "------------------------------\n",
            "--------- CatBoost on Wine Dataset ---------\n",
            "[1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94444444 0.94444444\n",
            " 1.         0.94117647 1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.94117647 0.94117647\n",
            " 0.94444444 1.         1.         0.94444444 1.         1.\n",
            " 1.         1.         0.94117647 0.94117647 0.94444444 1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 0.94117647 1.         1.         0.94444444 1.         0.94444444\n",
            " 1.         1.         1.         0.94444444 1.         0.94117647\n",
            " 1.         1.         0.88888889 1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94117647 1.         1.         1.         0.94444444\n",
            " 1.         0.88888889 1.         1.         0.94117647 1.\n",
            " 1.         0.94444444 1.         0.94444444 0.94444444 1.\n",
            " 0.94444444 1.         0.94117647 1.        ]\n",
            "Accuracy: 97.97% (3.03%)\n",
            "------------------------------\n",
            "--------- LightGBM on Wine Dataset ---------\n",
            "[1.         0.94444444 0.94444444 1.         0.94444444 1.\n",
            " 1.         0.77777778 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.88235294 0.94117647\n",
            " 0.94444444 1.         1.         1.         1.         1.\n",
            " 1.         0.88888889 0.94117647 0.94117647 0.94444444 1.\n",
            " 1.         0.94444444 1.         0.94444444 1.         1.\n",
            " 0.88235294 0.94117647 1.         0.94444444 1.         0.94444444\n",
            " 1.         1.         1.         0.94444444 1.         0.94117647\n",
            " 0.94444444 1.         0.94444444 1.         1.         1.\n",
            " 1.         0.94444444 0.88235294 1.         0.94444444 1.\n",
            " 1.         0.94444444 1.         1.         1.         0.94444444\n",
            " 0.94117647 0.94117647 1.         1.         1.         0.88888889\n",
            " 1.         0.88888889 1.         0.94444444 1.         1.\n",
            " 1.         0.94444444 1.         0.94444444 0.88888889 1.\n",
            " 1.         0.94444444 0.94117647 1.        ]\n",
            "Accuracy: 97.12% (4.03%)\n",
            "------------------------------\n",
            "--------- XGBoost on Wine Dataset ---------\n",
            "[1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94444444 0.88888889\n",
            " 1.         0.94117647 1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.94117647 0.88235294\n",
            " 0.94444444 1.         1.         1.         1.         1.\n",
            " 1.         1.         0.94117647 0.88235294 0.94444444 1.\n",
            " 1.         0.94444444 1.         0.94444444 1.         1.\n",
            " 0.94117647 1.         1.         0.94444444 0.94444444 1.\n",
            " 1.         1.         1.         1.         1.         0.94117647\n",
            " 1.         1.         0.88888889 1.         1.         1.\n",
            " 0.94444444 0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         0.94444444\n",
            " 1.         0.94117647 1.         1.         1.         0.94444444\n",
            " 1.         0.88888889 1.         0.94444444 1.         1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 1.         0.94444444 0.94117647 1.        ]\n",
            "Accuracy: 97.80% (3.38%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "wine_scores = []\n",
        "wine_scores_mean = []\n",
        "wine_scores_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    wine_scores.append(results)\n",
        "    wine_scores_mean.append(results.mean()*100)\n",
        "    wine_scores_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Wine Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Wine scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(wine_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results = pd.DataFrame()\n",
        "Algo_results['Names'] = names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Wine'] = wine_scores_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>98.143791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine\n",
              "0   AdaBoost  98.143791\n",
              "1  GradBoost  98.075163\n",
              "2   CatBoost  97.967320\n",
              "3   LightGBM  97.120915\n",
              "4    XGBoost  97.797386"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Breast Cancer Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "breast_cancer_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\BreastCancer\\Breast.dat', sep=',', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = breast_cancer_df.iloc[:, :-1]\n",
        "y = breast_cancer_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 450.0,\n",
              " 'learning_rate': 0.01199453123793802,\n",
              " 'max_depth': 4.0,\n",
              " 'max_features': 2,\n",
              " 'min_samples_leaf': 4.0,\n",
              " 'min_samples_split': 6.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['AdaBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Breast Cancer Dataset ---------\n",
            "[0.95652174 0.95652174 0.97101449 0.94117647 0.97058824 0.98529412\n",
            " 0.95588235 0.97058824 0.98529412 0.97058824 0.98550725 0.95652174\n",
            " 0.97101449 0.97058824 0.95588235 0.95588235 1.         0.94117647\n",
            " 0.98529412 0.97058824 1.         0.95652174 0.97101449 0.97058824\n",
            " 0.97058824 0.98529412 0.95588235 0.98529412 0.94117647 0.98529412\n",
            " 0.98550725 0.94202899 0.98550725 0.97058824 0.98529412 1.\n",
            " 0.98529412 0.97058824 0.94117647 0.97058824 0.95652174 1.\n",
            " 0.98550725 0.98529412 0.98529412 0.95588235 0.95588235 0.98529412\n",
            " 0.95588235 0.94117647 1.         0.92753623 1.         1.\n",
            " 0.94117647 0.98529412 0.97058824 0.98529412 0.97058824 0.97058824\n",
            " 0.95652174 0.98550725 0.97101449 0.92647059 0.98529412 1.\n",
            " 0.94117647 0.97058824 0.95588235 1.         1.         0.98550725\n",
            " 0.97101449 0.95588235 0.98529412 0.94117647 0.97058824 0.98529412\n",
            " 0.95588235 0.97058824 0.95652174 0.97101449 0.95652174 0.98529412\n",
            " 0.97058824 0.97058824 0.97058824 0.98529412 0.98529412 0.98529412\n",
            " 1.         0.95652174 0.98550725 0.97058824 0.97058824 1.\n",
            " 0.95588235 0.98529412 0.95588235 0.94117647]\n",
            "Accuracy: 97.14% (1.82%)\n",
            "------------------------------\n",
            "--------- GradBoost on Breast Cancer Dataset ---------\n",
            "[0.95652174 0.98550725 0.98550725 0.95588235 0.97058824 0.98529412\n",
            " 0.95588235 0.97058824 0.95588235 0.98529412 0.95652174 0.97101449\n",
            " 0.97101449 0.97058824 0.95588235 0.92647059 1.         0.92647059\n",
            " 0.97058824 0.97058824 1.         0.94202899 0.95652174 0.97058824\n",
            " 0.97058824 0.98529412 0.97058824 0.95588235 0.97058824 0.98529412\n",
            " 0.95652174 0.95652174 0.97101449 0.97058824 0.97058824 1.\n",
            " 0.98529412 0.98529412 0.89705882 0.97058824 0.95652174 0.98550725\n",
            " 0.97101449 0.98529412 0.97058824 0.94117647 0.95588235 0.98529412\n",
            " 0.94117647 0.95588235 1.         0.91304348 1.         0.98529412\n",
            " 0.89705882 0.97058824 0.95588235 0.97058824 0.98529412 0.98529412\n",
            " 0.95652174 0.98550725 0.97101449 0.95588235 0.97058824 1.\n",
            " 0.94117647 0.97058824 0.97058824 0.98529412 0.98550725 0.98550725\n",
            " 0.97101449 0.95588235 0.98529412 0.94117647 0.97058824 0.94117647\n",
            " 0.95588235 0.95588235 0.94202899 0.95652174 0.94202899 0.95588235\n",
            " 0.95588235 0.95588235 0.97058824 1.         0.98529412 0.97058824\n",
            " 0.98550725 0.94202899 0.97101449 0.98529412 0.95588235 1.\n",
            " 0.97058824 0.92647059 0.97058824 0.94117647]\n",
            "Accuracy: 96.65% (2.09%)\n",
            "------------------------------\n",
            "--------- CatBoost on Breast Cancer Dataset ---------\n",
            "[0.94202899 0.97101449 0.98550725 0.95588235 0.97058824 1.\n",
            " 0.97058824 0.97058824 0.97058824 0.98529412 0.98550725 0.97101449\n",
            " 0.97101449 0.97058824 0.97058824 0.95588235 1.         0.95588235\n",
            " 1.         0.95588235 1.         0.94202899 0.95652174 0.97058824\n",
            " 0.95588235 1.         0.95588235 0.98529412 0.97058824 0.98529412\n",
            " 0.97101449 0.95652174 0.98550725 0.98529412 0.98529412 1.\n",
            " 0.98529412 0.97058824 0.94117647 0.97058824 0.97101449 0.98550725\n",
            " 1.         1.         0.98529412 0.95588235 0.98529412 0.97058824\n",
            " 0.94117647 0.95588235 1.         0.95652174 1.         0.98529412\n",
            " 0.94117647 0.98529412 0.95588235 0.97058824 0.97058824 0.98529412\n",
            " 0.95652174 0.98550725 0.98550725 0.92647059 0.98529412 1.\n",
            " 0.94117647 0.97058824 0.98529412 0.98529412 1.         1.\n",
            " 0.97101449 0.95588235 0.98529412 0.97058824 0.97058824 0.95588235\n",
            " 0.95588235 0.95588235 0.98550725 0.98550725 0.94202899 0.97058824\n",
            " 0.98529412 0.97058824 0.97058824 1.         0.98529412 0.98529412\n",
            " 0.98550725 0.95652174 0.97101449 1.         0.97058824 1.\n",
            " 0.97058824 0.97058824 0.97058824 0.92647059]\n",
            "Accuracy: 97.38% (1.80%)\n",
            "------------------------------\n",
            "--------- LightGBM on Breast Cancer Dataset ---------\n",
            "[0.97101449 0.97101449 0.95652174 0.95588235 0.97058824 1.\n",
            " 0.95588235 0.97058824 0.98529412 0.98529412 0.98550725 0.97101449\n",
            " 0.98550725 0.98529412 0.97058824 0.92647059 1.         0.95588235\n",
            " 1.         0.95588235 1.         0.94202899 0.95652174 0.97058824\n",
            " 0.95588235 1.         0.97058824 0.98529412 0.97058824 0.97058824\n",
            " 0.97101449 0.95652174 0.97101449 0.97058824 0.98529412 0.97058824\n",
            " 0.98529412 1.         0.94117647 0.97058824 0.95652174 1.\n",
            " 0.98550725 0.98529412 0.98529412 0.95588235 0.98529412 0.97058824\n",
            " 0.95588235 0.95588235 1.         0.91304348 1.         0.98529412\n",
            " 0.89705882 0.97058824 0.97058824 0.98529412 1.         0.98529412\n",
            " 0.95652174 1.         0.98550725 0.92647059 0.98529412 1.\n",
            " 0.94117647 0.97058824 0.98529412 0.95588235 1.         1.\n",
            " 0.97101449 0.95588235 0.98529412 0.94117647 0.97058824 0.98529412\n",
            " 0.98529412 0.97058824 0.94202899 0.98550725 0.95652174 0.98529412\n",
            " 0.98529412 0.97058824 0.98529412 1.         0.98529412 0.97058824\n",
            " 1.         0.97101449 0.98550725 0.98529412 0.97058824 0.98529412\n",
            " 0.94117647 1.         0.97058824 0.94117647]\n",
            "Accuracy: 97.33% (2.05%)\n",
            "------------------------------\n",
            "--------- XGBoost on Breast Cancer Dataset ---------\n",
            "[0.95652174 0.98550725 0.98550725 0.95588235 0.95588235 0.98529412\n",
            " 0.95588235 0.97058824 0.95588235 0.97058824 0.98550725 0.97101449\n",
            " 0.95652174 0.97058824 0.97058824 0.95588235 1.         0.94117647\n",
            " 0.95588235 0.97058824 1.         0.92753623 0.95652174 0.95588235\n",
            " 0.95588235 1.         0.97058824 0.97058824 0.97058824 0.97058824\n",
            " 0.95652174 0.97101449 0.97101449 0.97058824 0.97058824 1.\n",
            " 0.98529412 1.         0.91176471 0.95588235 0.97101449 0.98550725\n",
            " 0.97101449 1.         0.97058824 0.92647059 0.98529412 0.97058824\n",
            " 0.94117647 0.94117647 1.         0.92753623 0.97101449 0.97058824\n",
            " 0.92647059 0.98529412 0.95588235 0.97058824 1.         0.97058824\n",
            " 0.95652174 0.98550725 0.97101449 0.94117647 0.97058824 1.\n",
            " 0.92647059 0.97058824 0.97058824 0.98529412 1.         0.98550725\n",
            " 0.95652174 0.92647059 0.98529412 0.95588235 0.95588235 0.97058824\n",
            " 0.98529412 0.95588235 0.95652174 0.97101449 0.94202899 0.95588235\n",
            " 0.97058824 0.97058824 0.98529412 0.98529412 0.98529412 0.97058824\n",
            " 1.         0.94202899 0.98550725 0.98529412 0.95588235 1.\n",
            " 0.97058824 0.95588235 0.95588235 0.92647059]\n",
            "Accuracy: 96.79% (2.02%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "breast_cancer_scores = []\n",
        "breast_cancer_mean = []\n",
        "breast_cancer_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    breast_cancer_scores.append(results)\n",
        "    breast_cancer_mean.append(results.mean()*100)\n",
        "    breast_cancer_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Breast Cancer Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Breast Cancer scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(breast_cancer_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Breast_Cancer'] = breast_cancer_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>98.143791</td>\n",
              "      <td>97.144075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer\n",
              "0   AdaBoost  98.143791      97.144075\n",
              "1  GradBoost  98.075163      96.646633\n",
              "2   CatBoost  97.967320      97.378303\n",
              "3   LightGBM  97.120915      97.334612\n",
              "4    XGBoost  97.797386      96.792626"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Sonar Dataset** #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "sonar_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Sonar\\Sonar.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = sonar_df.iloc[:, :-1]\n",
        "y = sonar_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 1250.0,\n",
              " 'learning_rate': 0.011066661922600281,\n",
              " 'max_depth': 2.0,\n",
              " 'max_features': 0,\n",
              " 'min_samples_leaf': 5.0,\n",
              " 'min_samples_split': 6.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['AdaBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 171, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 579, in _boost\n    return self._boost_real(iboost, X, y, sample_weight, random_state)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 588, in _boost_real\n    estimator.fit(X, y, sample_weight=sample_weight)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 0 instead.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 52\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m algorithm_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mXGBoost\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     clf \u001b[39m=\u001b[39m XGBClassifier(booster\u001b[39m=\u001b[39mbest_hyperparams[algorithm_name][\u001b[39m'\u001b[39m\u001b[39mbooster\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m                         learning_rate\u001b[39m=\u001b[39mbest_hyperparams[algorithm_name][\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m                         gamma\u001b[39m=\u001b[39mbest_hyperparams[algorithm_name][\u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                         verbosity\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                         random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m results \u001b[39m=\u001b[39m cross_val_score(clf, X, y, cv\u001b[39m=\u001b[39;49mrskf)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m sonar_scores\u001b[39m.\u001b[39mappend(results)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y445sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m sonar_mean\u001b[39m.\u001b[39mappend(results\u001b[39m.\u001b[39mmean()\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[1;32m--> 328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 171, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 579, in _boost\n    return self._boost_real(iboost, X, y, sample_weight, random_state)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 588, in _boost_real\n    estimator.fit(X, y, sample_weight=sample_weight)\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 0 instead.\n"
          ]
        }
      ],
      "source": [
        "sonar_scores = []\n",
        "sonar_mean = []\n",
        "sonar_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    sonar_scores.append(results)\n",
        "    sonar_mean.append(results.mean()*100)\n",
        "    sonar_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Sonar Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Sonar scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(sonar_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Sonar'] = sonar_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n",
            "\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n",
            "\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n",
            "\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n",
            "\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n",
            "\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n",
            "\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n",
            "\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
            "\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n",
            "\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Ionosphere Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ionosphere_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Ionosphere\\ionosphere.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(351, 35)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ionosphere_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = ionosphere_df.iloc[:, :-1]\n",
        "y = ionosphere_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ionosphere_scores = []\n",
        "ionosphere_mean = []\n",
        "ionosphere_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    ionosphere_scores.append(results)\n",
        "    ionosphere_mean.append(results.mean()*100)\n",
        "    ionosphere_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Ionosphere Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Ionosphere scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(ionosphere_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Ionosphere'] = ionosphere_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n",
            "\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n",
            "\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n",
            "\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n",
            "\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n",
            "\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n",
            "\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n",
            "\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
            "\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n",
            "\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Tic-Tac-Toe Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tictactoe_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\TicTacToe\\TicTacToe.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummies = {\n",
        "            'x': 0,\n",
        "            'o': 1,\n",
        "            'b': 2,\n",
        "          }\n",
        "tictactoe_df = tictactoe_df.iloc[:, 0: 9].replace(dummies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = tictactoe_df.iloc[:, :-1]\n",
        "y = tictactoe_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tictactoe_scores = []\n",
        "tictactoe_mean = []\n",
        "tictactoe_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    tictactoe_scores.append(results)\n",
        "    tictactoe_mean.append(results.mean()*100)\n",
        "    tictactoe_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on TicTacToe Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different TicTacToe scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(tictactoe_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['TicTacToe'] = tictactoe_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n",
            "\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n",
            "\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n",
            "\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n",
            "\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n",
            "\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n",
            "\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n",
            "\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
            "\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n",
            "\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Bupa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bupa_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Bupa\\Bupa.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(345, 7)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bupa_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = bupa_df.iloc[:, :-1]\n",
        "y = bupa_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bupa_scores = []\n",
        "bupa_mean = []\n",
        "bupa_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    bupa_scores.append(results)\n",
        "    bupa_mean.append(results.mean()*100)\n",
        "    bupa_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Bupa Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Bupa scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(bupa_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Bupa'] = bupa_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n",
            "\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n",
            "\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n",
            "\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n",
            "\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n",
            "\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n",
            "\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n",
            "\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
            "\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n",
            "\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pima**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pima_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Pima\\Diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pima_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = pima_df.iloc[:, :-1]\n",
        "y = pima_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pima_scores = []\n",
        "pima_mean = []\n",
        "pima_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    pima_scores.append(results)\n",
        "    pima_mean.append(results.mean()*100)\n",
        "    pima_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Pima Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Pima scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(pima_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Pima'] = pima_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n",
            "\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n",
            "\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n",
            "\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n",
            "\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n",
            "\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n",
            "\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n",
            "\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
            "\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n",
            "\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Heart**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "heart_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Heart\\Heart.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = heart_df.iloc[:, :-1]\n",
        "y = heart_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "heart_scores = []\n",
        "heart_mean = []\n",
        "heart_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    heart_scores.append(results)\n",
        "    heart_mean.append(results.mean()*100)\n",
        "    heart_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Heart Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Heart scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(heart_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Heart'] = heart_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n",
            "\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n",
            "\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n",
            "\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n",
            "\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n",
            "\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n",
            "\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n",
            "\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
            "\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n",
            "\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Liver**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "liver_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Liver\\bupa.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = liver_df.iloc[:, :-1]\n",
        "y = liver_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.84trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 750.0, 'learning_rate': 0.021785402162209068, 'max_depth': 3.0, 'max_features': None, 'min_samples_leaf': 2.0, 'min_samples_split': 2.0, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "liver_scores = []\n",
        "liver_mean = []\n",
        "liver_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    liver_scores.append(results)\n",
        "    liver_mean.append(results.mean()*100)\n",
        "    liver_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Liver Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHNCAYAAADMjHveAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABQnklEQVR4nO3deVxU5f4H8M8wwgw7CrKICAJupIKCEhi5hOF6s03KmyIp5ZpFZdoi7lTmdhMjzaWsrqailRpWaNeN0qtgqUimonYF3BIUFZT5/v7wx8mRQRgFD8rn/XrNS+c5zznnOeeZOfOZM885aEREQERERKQSC7UbQERERHUbwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMI3RM0Gg0mTpyodjNM8vHxQZ8+fdRuxn2hS5cu6NKli/I8JycHGo0GS5cuNaqXmpqKoKAg6PV6aDQanD9/HgCwbNkytGzZEpaWlnBycrpr7a7tli5dCo1Gg5ycHLWbQmQSw8g94vDhw3jxxRfh6+sLvV4PBwcHdOrUCXPnzsXly5fVbh5Vo0uXLmHixIn46aef1G5KrXT27Fn0798f1tbWSEpKwrJly2Bra4uDBw9i8ODB8PPzw8KFC7FgwQK1m1qhAwcOYOLEiVUKB++//z40Gg0yMjKMykUE9evXh0ajwdGjR42mXblyBTqdDgMGDKjOZhPVmHpqN4Aqt379ejz99NPQ6XQYNGgQWrdujZKSEmzbtg2vv/469u/fX6sPvNXh8uXLqFevbrxcL126hEmTJgGA0VmCusjb2xuXL1+GpaWlUrZr1y5cuHABU6ZMQWRkpFL+008/wWAwYO7cufD391ejuVV24MABTJo0CV26dIGPj88t6z700EMAgG3btqFdu3ZK+f79+3H+/HnUq1cP27dvR9OmTZVpu3btQklJiTLvwIED8cwzz0Cn01X/xhBVg7pxdL+HHT16FM888wy8vb2xadMmeHh4KNNGjhyJP/74A+vXr1exhTXHYDCgpKQEer0eer1e7eaQCjQaTbm+P3XqFACU+xmmovI7UVRUBFtb22pb3u0ICQmBXq/Htm3bMHr0aKV8+/btcHZ2RkhICLZt24bnnntOmbZt2zYAfwcZrVYLrVZ7dxteS4gIrly5Amtra7WbQrciVKsNGzZMAMj27durVP/q1asyefJk8fX1FSsrK/H29pbx48fLlStXjOp5e3tL7969ZfPmzRIcHCx6vV5at24tmzdvFhGR1atXS+vWrUWn00n79u1lz549RvPHxMSIra2tHD58WB599FGxsbERDw8PmTRpkhgMBqO6M2bMkLCwMGnQoIHo9Xpp3769rFy5slzbAcjIkSPl888/l4CAAKlXr56sWbNGmZaQkKDULSwslDFjxoi3t7dYWVlJw4YNJTIyUnbv3m20zK+++krat28ver1enJ2d5Z///Kf8+eefJrflzz//lMcee0xsbW3FxcVFXn31Vbl27Vql+7xsX27cuFECAwNFp9NJq1atZPXq1eXq/vXXXzJmzBhp3LixWFlZiZ+fn7z77rtSWloqIiJHjx4VAOUeCQkJ8vXXXwsA2bt3r7K8VatWCQB5/PHHjdbTsmVL6d+/v1HZsmXLlH1Rv359iY6OluPHj5dr488//yxRUVHi4OAg1tbW8vDDD8u2bduM6iQkJAgAOXTokMTExIijo6M4ODjI4MGDpaioqNJ9JiLy8ccfi6+vr+j1eunQoYNs2bJFOnfuLJ07d1bqlO2PJUuWiIhI586dy+2bmJgY8fb2NrnPymzYsEEeeughsbGxETs7O+nVq5fs27fPqD1lr4M//vhDevbsKXZ2dvLYY4+JiEhpaanMnj1bAgICRKfTiaurq7zwwgty7tw5o2WUvRa2bt0qHTp0EJ1OJ02bNpVPP/1UqbNkyRKTfVz23jMlIiJCPD09jcoGDhwoffr0kcmTJ0vr1q2NpvXu3VucnJyU11XZOo8ePWpWW8tU9rq9lV27dsmjjz4qzs7OotfrxcfHR2JjY43qlJaWypw5c5RjjouLi0RFRcmuXbuUOuYe21JTUyU4OFh0Op3Mnj3brO3497//Le3btxc7Ozuxt7eX1q1by5w5cyrdVrp9DCO1nKenp/j6+la5fkxMjACQp556SpKSkmTQoEECQPr162dUz9vbW1q0aCEeHh4yceJEmT17tnh6eoqdnZ18/vnn0qRJE3n33Xfl3XffFUdHR/H39zd6w8bExIher5dmzZrJwIEDZd68edKnTx8BIO+8847Ruho3biwjRoyQefPmyaxZs6Rjx44CQNatW2dUD4C0atVKGjZsKJMmTZKkpCTJyMhQpt344TJgwACxsrKS+Ph4+eSTT+S9996Tvn37yueff67UKTsAd+jQQWbPni3jxo0Ta2tr8fHxkb/++qvctjzwwAPy/PPPy0cffSRPPvmkAJD58+dXus+9vb2lefPm4uTkJOPGjZNZs2ZJmzZtxMLCQr7//nulXlFRkbRt21acnZ3lzTfflOTkZBk0aJBoNBoZM2aMiIhcvHhRPvroIyVgLFu2TJYtWyZ79+6Vs2fPikajkQ8//FBZ5pgxY8TCwkIaNmyolJ06dUoAyLx585SyqVOnikajkejoaJk/f75MmjRJXFxcyu2LtLQ0sbKykrCwMJk5c6bMnj1b2rZtK1ZWVvLLL78o9crCSLt27eSJJ56Q+fPny9ChQwWAjB07ttJ99sknnwgACQ8Pl3/961/y8ssvi5OTk/j6+t4yjHz//ffywgsvCACZPHmyLFu2THbs2CFr1qyRxx9/XADIRx99pOwzEZHPPvtMNBqN9OjRQz788EN57733xMfHR5ycnIw+nGNiYkSn04mfn5/ExMRIcnKyfPbZZyIiMnToUKlXr57ExcVJcnKyvPHGG2JraysdOnSQkpISo9dCixYtxM3NTd58802ZN2+etG/fXjQajRJ+Dh8+LC+99JIAkDfffFPp47y8vAr31/jx48uFCV9fX5k+fbr8+OOPotFolH40GAxSv3596dmzp1K3ojBSWVtFqva6rUh+fr7Ur19fmjdvLjNmzJCFCxfKW2+9Ja1atTKqN3jwYAEgPXv2lDlz5sgHH3wgjz32mNFr3Zxjm7+/v9SvX1/GjRsnycnJsnnz5ipvx/fffy8A5JFHHpGkpCRJSkqSUaNGydNPP33LbaU7wzBSixUUFAgA5dtZZTIzMwWADB061Kj8tddeEwCyadMmpazsm+SOHTuUso0bNwoAsba2lmPHjinlH3/8cblvbmUHhtGjRytlBoNBevfuLVZWVnL69Gml/NKlS0btKSkpkdatW0u3bt2MygGIhYWF7N+/v9y23RxGHB0dZeTIkRXui5KSEnF1dZXWrVvL5cuXlfJ169YJAJkwYUK5bZk8ebLRMtq1ayfBwcEVrqNM2b688UxIQUGBeHh4SLt27ZSyKVOmiK2trfz+++9G848bN060Wq1yluL06dPltrfMAw88YHTGo3379vL0008LAMnKyhIRkZSUFKMzKDk5OaLVamXatGlGy/rtt9+kXr16SrnBYJBmzZpJVFSU0dmtS5cuSdOmTaV79+5KWVkYef75542W+fjjj4uzs/Mt91dZ3wQFBUlxcbFSvmDBAgFwyzAi8vcH643fmm9s042vvQsXLoiTk5PExcUZ1c3LyxNHR0ej8rLXwbhx44zqbt26VQDIF198YVSempparrzstbBlyxal7NSpU6LT6eTVV19VylauXFnp2ZAbrV+/XgDIsmXLREQkNzdXAMh//vMfuXDhgmi1Wlm/fr2IiOzbt08AGPV3RWGkKm2t6uvWlDVr1pjsqxtt2rRJAMhLL71UblrZ6/B2jm2pqalGdau6HWPGjBEHB4cqnRWl6sOraWqxwsJCAIC9vX2V6m/YsAEAEB8fb1T+6quvAkC5sSUBAQEICwtTnoeGhgIAunXrhiZNmpQrP3LkSLl1jho1Svm/RqPBqFGjUFJSgh9//FEpv/G32r/++gsFBQWIiIjAnj17yi2vc+fOCAgIqGRLr48L+OWXX3Dy5EmT0//73//i1KlTGDFihNGYg969e6Nly5Ymx9kMGzbM6HlERITJbTalUaNGePzxx5XnDg4OGDRoEDIyMpCXlwcAWLlyJSIiIlC/fn2cOXNGeURGRqK0tBRbtmypdD0RERHYunUrAODChQvYu3cvXnjhBbi4uCjlW7duhZOTE1q3bg0ASElJgcFgQP/+/Y3W6+7ujmbNmmHz5s0AgMzMTBw6dAgDBgzA2bNnlXpFRUV45JFHsGXLFhgMhkr32dmzZ5XXrillfTNs2DBYWVkp5YMHD4ajo2Ol+8AcP/zwA86fP49nn33WaNu1Wi1CQ0OVbb/R8OHDjZ6vXLkSjo6O6N69u9EygoODYWdnV24ZAQEBiIiIUJ43bNgQLVq0qPJryZTw8HBYWFgoY0G2b98OS0tLdOjQAXZ2dmjbti22b9+uTAP+Hi9yK1Vp6528bsvG76xbtw5Xr141WWf16tXQaDRISEgoN02j0QAw/9jWtGlTREVFGZVVdTucnJxQVFSEH374ocLtourHAay1mIODA4DrHzpVcezYMVhYWJS7ksDd3R1OTk44duyYUfmNgQOA8kHg5eVlsvyvv/4yKrewsICvr69RWfPmzQHA6JLFdevWYerUqcjMzERxcbFSXnagudGNVwTcyvvvv4+YmBh4eXkhODgYvXr1wqBBg5T2lG1rixYtys3bsmVL5aBeRq/Xo2HDhkZl9evXL7fNFfH39y+3PTfuC3d3dxw6dAi//vprufWUKRuAeSsRERFITk7GH3/8gcOHD0Oj0SAsLEwJKXFxcdi6dSs6deoEC4vr3zUOHToEEUGzZs1MLrPsSpVDhw4BAGJiYipcf0FBAerXr688v/k1VDbtr7/+Ul6/Nyvrm5vbY2lpWe71dKfKtqlbt24mp9/cxnr16qFx48blllFQUABXV1eTy7i5327eJ4B5ryVTnJyc8MADDxgFjnbt2ilBPzw83GialZUVOnbsWOlyq9LWO3nddu7cGU8++SQmTZqE2bNno0uXLujXrx8GDBigXNlz+PBhNGrUCA0aNKhwOeYe20wdR6q6HSNGjMBXX32Fnj17wtPTE48++ij69++PHj16VNg+unMMI7WYg4MDGjVqhH379pk1n6kPeVMqGl1fUbmImNUO4Pq39H/84x94+OGHMX/+fHh4eMDS0hJLlizBl19+Wa5+VUe89+/fHxEREVizZg2+//57zJgxA++99x5SUlLQs2dPs9t5N640MBgM6N69O8aOHWtyell4uZWyb7tbtmzBkSNH0L59e9ja2iIiIgL/+te/cPHiRWRkZGDatGlG69VoNPjuu+9MbqednZ1SDwBmzJiBoKAgk+svq1umOl8rNaFsm5YtWwZ3d/dy02++XFyn0ykh7sZluLq64osvvjC5jps/3Gpqnzz00ENITk7G+fPnsX37doSHhyvTwsPDsXjxYly9ehXbtm1DcHBwla5Aq0pb7+R1q9FosGrVKvz888/49ttvsXHjRjz//POYOXMmfv7553Kvp8pU9dhm6jhS1e1wdXVFZmYmNm7ciO+++w7fffcdlixZgkGDBuHTTz81q71UdQwjtVyfPn2wYMECpKenG/2kYoq3tzcMBgMOHTqEVq1aKeX5+fk4f/48vL29q7VtBoMBR44cMToY/f777wCg3Dth9erV0Ov12Lhxo9E9DpYsWXLH6/fw8MCIESMwYsQInDp1Cu3bt8e0adPQs2dPZVuzs7PLfSvOzs6u9n3xxx9/QESMDpY37ws/Pz9cvHjR6N4YptzqgNukSRM0adIEW7duxZEjR5RT7A8//DDi4+OxcuVKlJaW4uGHH1bm8fPzg4igadOmt/zg8PPzA3A9BFfWxjtRtu8PHTpk1DdXr17F0aNHERgYWG3rKtsmV1fX294mPz8//Pjjj+jUqVO1XR5a1Q/VGz300EP46KOP8OOPPyIjIwOvv/66Mi08PByXL1/G+vXrceTIETz55JPV0k6g6q/bW3nwwQfx4IMPYtq0afjyyy/xz3/+E8uXL8fQoUPh5+eHjRs34ty5cxWeHamOY5s522FlZYW+ffuib9++MBgMGDFiBD7++GO88847tf4eNvcqjhmp5caOHQtbW1sMHToU+fn55aYfPnwYc+fOBQD06tULADBnzhyjOrNmzQJwfbxEdZs3b57yfxHBvHnzYGlpiUceeQTA9W9eGo0GpaWlSr2cnBysXbv2ttdZWlqKgoICozJXV1c0atRI+RkoJCQErq6uSE5ONvpp6LvvvkNWVla174uTJ09izZo1yvPCwkJ89tlnCAoKUr6R9+/fH+np6di4cWO5+c+fP49r164BAGxsbJQyUyIiIrBp0ybs3LlTCSNBQUGwt7fHu+++C2trawQHByv1n3jiCWi1WkyaNKnct3MRwdmzZwEAwcHB8PPzwwcffICLFy+WW+/p06erujtuKSQkBA0bNkRycjJKSkqU8qVLl1a4zbcrKioKDg4OmD59uskxC1XZpv79+6O0tBRTpkwpN+3atWu31eaye5eYM2/ZWbFZs2bh6tWrRmdGfHx84OHhgffff9+obnWo6uvWlL/++qvca67srFvZ+/LJJ5+EiCg3+rtR2bzVcWyr6naUvR/KWFhYoG3btkZtpurHMyO1nJ+fH7788ktER0ejVatWRndg3bFjB1auXInBgwcDAAIDAxETE4MFCxbg/Pnz6Ny5M3bu3IlPP/0U/fr1Q9euXau1bXq9HqmpqYiJiUFoaCi+++47rF+/Hm+++aZy6rp3796YNWsWevTogQEDBuDUqVNISkqCv78/fv3119ta74ULF9C4cWM89dRTCAwMhJ2dHX788Ufs2rULM2fOBHB9/MF7772H2NhYdO7cGc8++yzy8/Mxd+5c+Pj44JVXXqm2/QBcP8U7ZMgQ7Nq1C25ubli8eDHy8/ONzgC9/vrr+Oabb9CnTx8MHjwYwcHBKCoqwm+//YZVq1YhJycHLi4usLa2RkBAAFasWIHmzZujQYMGaN26tTIgNSIiAl988QU0Go3RTa3Cw8OxceNGdOnSxWhgqJ+fH6ZOnYrx48cjJycH/fr1g729PY4ePYo1a9bghRdewGuvvQYLCwt88skn6NmzJx544AHExsbC09MT//vf/7B582Y4ODjg22+/veN9ZWlpialTp+LFF19Et27dEB0djaNHj2LJkiXVPmbEwcEBH330EQYOHIj27dvjmWeeQcOGDXH8+HGsX78enTp1MgrUpnTu3BkvvvgiEhMTkZmZiUcffRSWlpY4dOgQVq5ciblz5+Kpp54yq11BQUHQarV47733UFBQAJ1Oh27dulU4LgW4flbMy8sL6enp8PHxQaNGjYymh4eHK4NBO3XqZFZ7bqWqr1tTPv30U8yfPx+PP/44/Pz8cOHCBSxcuBAODg5KwOjatSsGDhyIf/3rXzh06BB69OgBg8GArVu3omvXrhg1alS1HNuquh1Dhw7FuXPn0K1bNzRu3BjHjh3Dhx9+iKCgIKOzMlTNVLmGh8z2+++/S1xcnPj4+IiVlZXY29tLp06d5MMPPzS66c/Vq1dl0qRJ0rRpU7G0tBQvL69b3hjoZvj/G4/dqOzyyhkzZihlpm565ubmJgkJCeVuILRo0SJp1qyZ6HQ6admypSxZskS5DLOydd84rexS1+LiYnn99dclMDBQ7O3txdbWVgIDA03eE2TFihXSrl070el00qBBg1ve9Oxmptpoyo03PWvbtq2ynaZu7HbhwgUZP368+Pv7i5WVlbi4uEh4eLh88MEHRver2LFjhwQHB4uVlVW5y3z379+v3JPlRlOnTjV5n5cyq1evloceekhsbW3F1tZWWrZsKSNHjpTs7GyjehkZGfLEE0+Is7Oz6HQ68fb2lv79+0taWlq5fXPjZbQipi8hrcj8+fOladOmotPpJCQkpEo3PbtxHVW5tLfM5s2bJSoqShwdHUWv14ufn58MHjxY/vvf/yp1KnodlFmwYIEEBweLtbW12NvbS5s2bWTs2LFy8uRJpU5F76ubt0tEZOHCheLr6ytarbbKl/k+++yzAkAGDBhQbtqsWbNMvi5Ebn3Ts6q0taqv25vt2bNHnn32WWnSpIlys7g+ffoY7XcRkWvXrsmMGTOkZcuWyk0Me/bsaXQTwzs9tlV1O1atWiWPPvqouLq6ipWVlTRp0kRefPFFyc3NrXA76c5pRGrJSDO6pwwePBirVq0yeTqfiIjIHBwzQkRERKpiGCEiIiJVMYwQERGRqjhmhIiIiFTFMyNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVZoeRLVu2oG/fvmjUqBE0Gg3Wrl1b6Tw//fQT2rdvD51OB39/fyxduvQ2mkpERET3I7PDSFFREQIDA5GUlFSl+kePHkXv3r3RtWtXZGZm4uWXX8bQoUOxceNGsxtLRERE9x+NiMhtz6zRYM2aNejXr1+Fdd544w2sX78e+/btU8qeeeYZnD9/Hqmpqbe7aiIiIrpP1PiYkfT0dERGRhqVRUVFIT09vaZXTURERPeAejW9gry8PLi5uRmVubm5obCwEJcvX4a1tXW5eYqLi1FcXKw8NxgMOHfuHJydnaHRaGq6yURERFQNRAQXLlxAo0aNYGFR8fmPGg8jtyMxMRGTJk1SuxlERERUDU6cOIHGjRtXOL3Gw4i7uzvy8/ONyvLz8+Hg4GDyrAgAjB8/HvHx8crzgoICNGnSBCdOnICDg0ONtHPvf3/BqGej8M4778Db27vS+sUlJcjLza2RttzM3cMDOiurSusdO3YMU6ZMwbx/b0RgSOhdaFnNYF/UHvdDXwD3R3+Y2xfA3esP9kXlauN74270RWFhIby8vGBvb3/LejUeRsLCwrBhwwajsh9++AFhYWEVzqPT6aDT6cqVOzg41FgYsXVyxq+nBL7hj6F9+/Y1so6apt2zB7+emgxbJ+ca2093A/ui9rgf+gK4P/qDfVF7sC/MV9kQC7MHsF68eBGZmZnIzMwEcP3S3czMTBw/fhzA9bMagwYNUuoPGzYMR44cwdixY3Hw4EHMnz8fX331FV555RVzV01ERET3IbPDyH//+1+0a9cO7dq1AwDEx8ejXbt2mDBhAgAgNzdXCSYA0LRpU6xfvx4//PADAgMDMXPmTHzyySeIioqqpk0gIiKie5nZP9N06dIFt7o1iam7q3bp0gUZGRnmruq+kn4yHe/ufBfjOo5DWKOKf6IiIiKqa/i3ae4CEcHcPXNxpOAI5u6Ze8swR3dH+sl0PLb2MaSf5P1u1Ma+ICKGkbtgx8kd2H92PwBg/9n92HFyh8otqtsYDmsP9gWRaXUtpDOM1DARwYcZH8JCc31XW2gs8GHGhzzoqojhsPZgXxCVVxdDOsNIDSs72BrEAAAwiIEHXRUxHNYe7Asi0+piSGcYqUE3H2zL8KCrHobD2oN9QVReXQ3pDCM16OaDbRkedNXBcFh7sC9qp7o2TqE2qqshnWGkhpQdbDUwfdc5DTQ86N5lDIe1B/ui9qmL4xRqm7oc0hlGashVw1XkFeVBYPrFIxDkFeXhquHqXW5Z3cRwWHuwL2qnujhOobapyyG9Vv7V3vuBldYKy/ssx7kr5yqs00DfAFbaqv1xKboz5oRD9knNYl/UPjd+IzeIQfkmHt4ovNK/KULV48aQbuq9URbS79c+YRipQe627nC3dVe7GQSGw9qEfVH73HhWBDD+Jt7Js5OKLas76npIZxihOoPhsPZgX9QeN58VKcOzI3dXXQ/pDCNERHXYzWdFyvDsyN1Xl0M6B7ASEdVRHExMtQXDCBFRHcWr/qi24M80RER1VF0fp0C1B8MIEVEdVpfHKVDtwZ9piIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESq4qW9/+/SpUsAgD179tTI8i9fvoycnBz4+PjA2tq6RtaRlZVVI8u922q6L4Ca7w/2RdXxvVE17Ivag31R/RhG/t/BgwcBAHFxcSq35M7Z29ur3YQ7wr6oPe6nvgDu7f5gX9Qe7IvqxzDy//r16wcAaNmyJWxsbKp9+VlZWXjuuefw+eefo1WrVtW+/DL29vZo1qxZjS3/bqjpvgDuTn+wL6qG742qYV/UHuyL6scw8v9cXFwwdOjQGl9Pq1at0L59+xpfz73sbvUFwP6oDPui9mBf1B7si+rHAaxERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFW3FUaSkpLg4+MDvV6P0NBQ7Ny5s8K6V69exeTJk+Hn5we9Xo/AwECkpqbedoOJiIjo/mJ2GFmxYgXi4+ORkJCAPXv2IDAwEFFRUTh16pTJ+m+//TY+/vhjfPjhhzhw4ACGDRuGxx9/HBkZGXfceCIiIrr3mR1GZs2ahbi4OMTGxiIgIADJycmwsbHB4sWLTdZftmwZ3nzzTfTq1Qu+vr4YPnw4evXqhZkzZ95x44mIiOjeZ1YYKSkpwe7duxEZGfn3AiwsEBkZifT0dJPzFBcXQ6/XG5VZW1tj27ZtFa6nuLgYhYWFRg8iIiK6P5kVRs6cOYPS0lK4ubkZlbu5uSEvL8/kPFFRUZg1axYOHToEg8GAH374ASkpKcjNza1wPYmJiXB0dFQeXl5e5jSTiIiI7iE1fjXN3Llz0axZM7Rs2RJWVlYYNWoUYmNjYWFR8arHjx+PgoIC5XHixImabiYRERGpxKww4uLiAq1Wi/z8fKPy/Px8uLu7m5ynYcOGWLt2LYqKinDs2DEcPHgQdnZ28PX1rXA9Op0ODg4ORg8iIiK6P5kVRqysrBAcHIy0tDSlzGAwIC0tDWFhYbecV6/Xw9PTE9euXcPq1avx2GOP3V6LiYiI6L5Sz9wZ4uPjERMTg5CQEHTs2BFz5sxBUVERYmNjAQCDBg2Cp6cnEhMTAQC//PIL/ve//yEoKAj/+9//MHHiRBgMBowdO7Z6t4SIiIjuSWaHkejoaJw+fRoTJkxAXl4egoKCkJqaqgxqPX78uNF4kCtXruDtt9/GkSNHYGdnh169emHZsmVwcnKqto1Qw6VLl3Dw4MEq18/KyjL61xwtW7aEjY2N2fMR3W3mvi+A239v8H1BdP8wO4wAwKhRozBq1CiT03766Sej5507d8aBAwduZzW12sGDBxEcHGz2fM8995zZ8+zevRvt27c3ez6iu+123xeA+e8Nvi+I7h+3FUbo+rey3bt3V7n+5cuXkZOTAx8fH1hbW5u9LqJ7gbnvC+D23xt8XxDdPxhGbpONjY3Z38o6depUQ60hqh1u530B8L1BVNcxjNA9j+MUiEy7W2Pb+L6oHMcZ3ppGRETtRlSmsLAQjo6OKCgo4D1HqJw9e/bc9jgFc3GcAt1L7tZ7g++LytXV41RVP795ZoTueRynQGTa3RrbxvdF5TjO8NZ4ZoSIiIhqRFU/v2v8b9MQERER3QrDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhV9dRuANHdVlpaiq1btyI3NxceHh6IiIiAVqtVu1lERHUWz4xQnZKSkgJ/f3907doVAwYMQNeuXeHv74+UlBS1m0ZEVGcxjFCdkZKSgqeeegpt2rRBeno6Lly4gPT0dLRp0wZPPfUUAwkRkUo0IiJqN6IyhYWFcHR0REFBARwcHNRuDt2DSktL4e/vjzZt2mDt2rWwsPg7hxsMBvTr1w/79u3DoUOH+JMNEVE1qernN8+MUJ2wdetW5OTk4M033zQKIgBgYWGB8ePH4+jRo9i6datKLSQiqrsYRqhOyM3NBQC0bt3a5PSy8rJ6RER09zCMUJ3g4eEBANi3b5/J6WXlZfWIiOjuYRihOiEiIgI+Pj6YPn06DAaD0TSDwYDExEQ0bdoUERERKrWQiKjuYhihOkGr1WLmzJlYt24d+vXrZ3Q1Tb9+/bBu3Tp88MEHHLxKRKQC3vSM6ownnngCq1atwquvvorw8HClvGnTpli1ahWeeOIJFVtHRFR38dJeqnN4B1Yiorujqp/fPDNCdY5Wq0WXLl3UbgYREf0/jhkhIiIiVd1WGElKSoKPjw/0ej1CQ0Oxc+fOW9afM2cOWrRoAWtra3h5eeGVV17BlStXbqvBREREdH8xO4ysWLEC8fHxSEhIwJ49exAYGIioqCicOnXKZP0vv/wS48aNQ0JCArKysrBo0SKsWLECb7755h03noiIiO59ZoeRWbNmIS4uDrGxsQgICEBycjJsbGywePFik/V37NiBTp06YcCAAfDx8cGjjz6KZ599ttKzKURERFQ3mBVGSkpKsHv3bkRGRv69AAsLREZGIj093eQ84eHh2L17txI+jhw5gg0bNqBXr14Vrqe4uBiFhYVGDyIiIro/mXU1zZkzZ1BaWgo3Nzejcjc3Nxw8eNDkPAMGDMCZM2fw0EMPQURw7do1DBs27JY/0yQmJmLSpEnmNI2IiIjuUTV+Nc1PP/2E6dOnY/78+dizZw9SUlKwfv16TJkypcJ5xo8fj4KCAuVx4sSJmm4mERERqcSsMyMuLi7QarXIz883Ks/Pz4e7u7vJed555x0MHDgQQ4cOBQC0adMGRUVFeOGFF/DWW2+V+3PuAKDT6aDT6cxpGhEREd2jzDozYmVlheDgYKSlpSllBoMBaWlpCAsLMznPpUuXygWOsrtd3gM3fyUiIqIaZvYdWOPj4xETE4OQkBB07NgRc+bMQVFREWJjYwEAgwYNgqenJxITEwEAffv2xaxZs9CuXTuEhobijz/+wDvvvIO+ffvyFtxERERkfhiJjo7G6dOnMWHCBOTl5SEoKAipqanKoNbjx48bnQl5++23odFo8Pbbb+N///sfGjZsiL59+2LatGnVtxVERER0z+IfyiMiIqIawT+UR0REVca/Zk1q4h/KIyKq41JSUuDv74+uXbtiwIAB6Nq1K/z9/ZGSkqJ206iOYBghIqrDUlJS8NRTT6FNmzZIT0/HhQsXkJ6ejjZt2uCpp55iIKG7gmNGiIjqqNLSUvj7+6NNmzZYu3at0cUHBoMB/fr1w759+3Do0CH+ZEO3paqf3zwzQkRUR23duhU5OTl48803y90PysLCAuPHj8fRo0exdetWlVpIdQXDCBFRHZWbmwsAaN26tcnpZeVl9YhqCsMIEVEd5eHhAQDYt2+fyell5WX1iGoKwwgRUR0VEREBHx8fTJ8+HQaDwWiawWBAYmIimjZtioiICJVaSHUFwwgRUR2l1Woxc+ZMrFu3Dv369TO6mqZfv35Yt24dPvjgAw5epRrHm54REdVhTzzxBFatWoVXX30V4eHhSnnTpk2xatUqPPHEEyq2juoKXtpLRES8AyvVCN4OnoiIqkyr1aJLly5qN4PqKI4ZISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGp6rbCSFJSEnx8fKDX6xEaGoqdO3dWWLdLly7QaDTlHr17977tRhMREdH9w+wwsmLFCsTHxyMhIQF79uxBYGAgoqKicOrUKZP1U1JSkJubqzz27dsHrVaLp59++o4bT0RERPc+s8PIrFmzEBcXh9jYWAQEBCA5ORk2NjZYvHixyfoNGjSAu7u78vjhhx9gY2PDMEJEREQAzAwjJSUl2L17NyIjI/9egIUFIiMjkZ6eXqVlLFq0CM888wxsbW0rrFNcXIzCwkKjBxEREd2fzAojZ86cQWlpKdzc3IzK3dzckJeXV+n8O3fuxL59+zB06NBb1ktMTISjo6Py8PLyMqeZREREdA+5q1fTLFq0CG3atEHHjh1vWW/8+PEoKChQHidOnLhLLSQiIqK7rZ45lV1cXKDVapGfn29Unp+fD3d391vOW1RUhOXLl2Py5MmVrken00Gn05nTNCIiIrpHmXVmxMrKCsHBwUhLS1PKDAYD0tLSEBYWdst5V65cieLiYjz33HO311IiIiK6L5l1ZgQA4uPjERMTg5CQEHTs2BFz5sxBUVERYmNjAQCDBg2Cp6cnEhMTjeZbtGgR+vXrB2dn5+ppOREREd0XzA4j0dHROH36NCZMmIC8vDwEBQUhNTVVGdR6/PhxWFgYn3DJzs7Gtm3b8P3331dPq4mIiOi+oRERUbsRlSksLISjoyMKCgrg4OCgdnOIiIioCqr6+c2/TUNERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJV3VYYSUpKgo+PD/R6PUJDQ7Fz585b1j9//jxGjhwJDw8P6HQ6NG/eHBs2bLitBhMREdH9pZ65M6xYsQLx8fFITk5GaGgo5syZg6ioKGRnZ8PV1bVc/ZKSEnTv3h2urq5YtWoVPD09cezYMTg5OVVH+4mIiOgepxERMWeG0NBQdOjQAfPmzQMAGAwGeHl5YfTo0Rg3bly5+snJyZgxYwYOHjwIS0vL22pkYWEhHB0dUVBQAAcHh9taBhEREd1dVf38NutnmpKSEuzevRuRkZF/L8DCApGRkUhPTzc5zzfffIOwsDCMHDkSbm5uaN26NaZPn47S0tIK11NcXIzCwkKjBxEREd2fzAojZ86cQWlpKdzc3IzK3dzckJeXZ3KeI0eOYNWqVSgtLcWGDRvwzjvvYObMmZg6dWqF60lMTISjo6Py8PLyMqeZREREdA+p8atpDAYDXF1dsWDBAgQHByM6OhpvvfUWkpOTK5xn/PjxKCgoUB4nTpyo6WYSERGRSswawOri4gKtVov8/Hyj8vz8fLi7u5ucx8PDA5aWltBqtUpZq1atkJeXh5KSElhZWZWbR6fTQafTmdM0IiIiukeZdWbEysoKwcHBSEtLU8oMBgPS0tIQFhZmcp5OnTrhjz/+gMFgUMp+//13eHh4mAwiREREVLeY/TNNfHw8Fi5ciE8//RRZWVkYPnw4ioqKEBsbCwAYNGgQxo8fr9QfPnw4zp07hzFjxuD333/H+vXrMX36dIwcObL6toKIiIjuWWbfZyQ6OhqnT5/GhAkTkJeXh6CgIKSmpiqDWo8fPw4Li78zjpeXFzZu3IhXXnkFbdu2haenJ8aMGYM33nij+raCiIiI7llm32dEDbzPCBER0b2nRu4zQkRERFTdGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkapuK4wkJSXBx8cHer0eoaGh2LlzZ4V1ly5dCo1GY/TQ6/W33WAiIiK6v5gdRlasWIH4+HgkJCRgz549CAwMRFRUFE6dOlXhPA4ODsjNzVUex44du6NGExER0f3D7DAya9YsxMXFITY2FgEBAUhOToaNjQ0WL15c4TwajQbu7u7Kw83N7Y4aTURERPcPs8JISUkJdu/ejcjIyL8XYGGByMhIpKenVzjfxYsX4e3tDS8vLzz22GPYv3//7beYiIiI7itmhZEzZ86gtLS03JkNNzc35OXlmZynRYsWWLx4Mb7++mt8/vnnMBgMCA8Px59//lnheoqLi1FYWGj0ICIiovtTjV9NExYWhkGDBiEoKAidO3dGSkoKGjZsiI8//rjCeRITE+Ho6Kg8vLy8arqZREREpBKzwoiLiwu0Wi3y8/ONyvPz8+Hu7l6lZVhaWqJdu3b4448/Kqwzfvx4FBQUKI8TJ06Y00wiIiK6h5gVRqysrBAcHIy0tDSlzGAwIC0tDWFhYVVaRmlpKX777Td4eHhUWEen08HBwcHoQURERPeneubOEB8fj5iYGISEhKBjx46YM2cOioqKEBsbCwAYNGgQPD09kZiYCACYPHkyHnzwQfj7++P8+fOYMWMGjh07hqFDh1bvlhAREdE9yewwEh0djdOnT2PChAnIy8tDUFAQUlNTlUGtx48fh4XF3ydc/vrrL8TFxSEvLw/169dHcHAwduzYgYCAgOrbCiIiIrpnaURE1G5EZQoLC+Ho6IiCggL+ZENERHSPqOrnN/82DREREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFR1W2EkKSkJPj4+0Ov1CA0Nxc6dO6s03/Lly6HRaNCvX7/bWS0RERHdh8wOIytWrEB8fDwSEhKwZ88eBAYGIioqCqdOnbrlfDk5OXjttdcQERFx240lIiKi+4/ZYWTWrFmIi4tDbGwsAgICkJycDBsbGyxevLjCeUpLS/HPf/4TkyZNgq+v7x01mIiIiO4vZoWRkpIS7N69G5GRkX8vwMICkZGRSE9Pr3C+yZMnw9XVFUOGDKnSeoqLi1FYWGj0ICIiovuTWWHkzJkzKC0thZubm1G5m5sb8vLyTM6zbds2LFq0CAsXLqzyehITE+Ho6Kg8vLy8zGkmERER3UNq9GqaCxcuYODAgVi4cCFcXFyqPN/48eNRUFCgPE6cOFGDrSQiIiI11TOnsouLC7RaLfLz843K8/Pz4e7uXq7+4cOHkZOTg759+yplBoPh+orr1UN2djb8/PzKzafT6aDT6cxpGhEREd2jzDozYmVlheDgYKSlpSllBoMBaWlpCAsLK1e/ZcuW+O2335CZmak8/vGPf6Br167IzMzkzy9ERERk3pkRAIiPj0dMTAxCQkLQsWNHzJkzB0VFRYiNjQUADBo0CJ6enkhMTIRer0fr1q2N5ndycgKAcuVERERUN5kdRqKjo3H69GlMmDABeXl5CAoKQmpqqjKo9fjx47Cw4I1diYiIqGo0IiJqN6IyhYWFcHR0REFBARwcHNRuDhEREVVBVT+/eQqDiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqrqtMJKUlAQfHx/o9XqEhoZi586dFdZNSUlBSEgInJycYGtri6CgICxbtuy2G0xERET3F7PDyIoVKxAfH4+EhATs2bMHgYGBiIqKwqlTp0zWb9CgAd566y2kp6fj119/RWxsLGJjY7Fx48Y7bjwRERHd+zQiIubMEBoaig4dOmDevHkAAIPBAC8vL4wePRrjxo2r0jLat2+P3r17Y8qUKVWqX1hYCEdHRxQUFMDBwcGc5hIREZFKqvr5Xc+chZaUlGD37t0YP368UmZhYYHIyEikp6dXOr+IYNOmTcjOzsZ7771XYb3i4mIUFxcrzwsKCgBc3ygiIiK6N5R9bld23sOsMHLmzBmUlpbCzc3NqNzNzQ0HDx6scL6CggJ4enqiuLgYWq0W8+fPR/fu3Susn5iYiEmTJpUr9/LyMqe5REREVAtcuHABjo6OFU43K4zcLnt7e2RmZuLixYtIS0tDfHw8fH190aVLF5P1x48fj/j4eOW5wWDAuXPn4OzsDI1GczeaXO0KCwvh5eWFEydO8KemWoD9UXuwL2oP9kXtcb/0hYjgwoULaNSo0S3rmRVGXFxcoNVqkZ+fb1Sen58Pd3f3CuezsLCAv78/ACAoKAhZWVlITEysMIzodDrodDqjMicnJ3OaWms5ODjc0y+s+w37o/ZgX9Qe7Iva437oi1udESlj1tU0VlZWCA4ORlpamlJmMBiQlpaGsLCwKi/HYDAYjQkhIiKiusvsn2ni4+MRExODkJAQdOzYEXPmzEFRURFiY2MBAIMGDYKnpycSExMBXB//ERISAj8/PxQXF2PDhg1YtmwZPvroo+rdEiIiIronmR1GoqOjcfr0aUyYMAF5eXkICgpCamqqMqj1+PHjsLD4+4RLUVERRowYgT///BPW1tZo2bIlPv/8c0RHR1ffVtwDdDodEhISyv38ROpgf9Qe7Ivag31Re9S1vjD7PiNERERE1Yl/m4aIiIhUxTBCREREqmIYISIiIlUxjFRi4sSJCAoKUrsZdAcGDx6Mfv36qd0Mojum0Wiwdu3aKtf/6aefoNFocP78+RprE1F1qJNhJD09HVqtFr17966R5fv4+ECj0UCj0UCr1aJRo0YYMmQI/vrrrxpZnym1+SCUl5eHMWPGwN/fH3q9Hm5ubujUqRM++ugjXLp0qcbXP3jwYKV/NBoNnJ2d0aNHD/z66681vu4bmfvBcrfk5eVh9OjR8PX1hU6ng5eXF/r27Wt0f6FbWbp0qcmbFHbp0sVov7u5ueHpp5/GsWPHqnkLKpaTkwONRoPMzMy7tk5z3So85+bmomfPntW6vlt94crIyEB0dDQ8PDyg0+ng7e2NPn364Ntvv1X+1kjZPi17WFlZwd/fH1OnTjX6eyQTJ06ERqNBjx49yq1nxowZ0Gg0Fd4IszYoLS1FeHg4nnjiCaPygoICeHl54a233lLKVq9ejW7duqF+/fqwtrZGixYt8PzzzyMjI0Ops3TpUqP9Zmdnh+DgYKSkpNy1bQKuvy9ffvnlu7pOU+pkGFm0aBFGjx6NLVu24OTJkzWyjsmTJyM3NxfHjx/HF198gS1btuCll16qkXXdS44cOYJ27drh+++/x/Tp05GRkYH09HSMHTsW69atw48//mhyvqtXr1ZrO3r06IHc3Fzk5uYiLS0N9erVQ58+fap1HfeinJwcBAcHY9OmTZgxYwZ+++03pKamomvXrhg5cuQdLz8uLg65ubk4efIkvv76a5w4cQLPPfdcNbS8bnB3d79rl3p+/fXXePDBB3Hx4kV8+umnyMrKQmpqKh5//HG8/fbbyh8wLfPjjz8iNzcXhw4dwqRJkzBt2jQsXrzYqI6Hhwc2b96MP//806h88eLFaNKkSY1v053QarVYunQpUlNT8cUXXyjlo0ePRoMGDZCQkAAAeOONNxAdHY2goCB88803yM7OxpdffglfX1+jPzILXL+7atlxKCMjA1FRUejfvz+ys7Pv6rbVClLHXLhwQezs7OTgwYMSHR0t06ZNM5qemJgorq6uYmdnJ88//7y88cYbEhgYqEzfuXOnREZGirOzszg4OMjDDz8su3fvNlqGt7e3zJ4926hsypQpEhAQYFS2atUqCQgIECsrK/H29pYPPvjAaPq5c+dk4MCB4uTkJNbW1tKjRw/5/ffflek5OTnSp08fcXJyEhsbGwkICJD169fL0aNHBYDRIyYm5vZ3WjWKioqSxo0by8WLF01ONxgMIiICQObPny99+/YVGxsbSUhIkGvXrsnzzz8vPj4+otfrpXnz5jJnzhyj+a9duyavvPKKODo6SoMGDeT111+XQYMGyWOPPabUiYmJMXouIrJ161YBIKdOnVLKfv31V+natavo9Xpp0KCBxMXFyYULF5TppaWlMmnSJPH09BQrKysJDAyU7777TpleXFwsI0eOFHd3d9HpdNKkSROZPn26iFx/jdzYP97e3rezO6tdz549xdPT02T//PXXXyIiMnPmTGndurXY2NhI48aNZfjw4cp+2bx5c7nXXkJCgoiIdO7cWcaMGWO0zGXLlomNjY1R2U8//SQdOnQQKysrcXd3lzfeeEOuXr2qTL9y5YqMHj1aGjZsKDqdTjp16iQ7d+5Upp87d04GDBggLi4uotfrxd/fXxYvXiwiUq5tnTt3vsM9Vv1MvT7LAJA1a9Yoz7dv3y6BgYGi0+kkODhY1qxZIwAkIyNDRP7ujx9//FGCg4PF2tpawsLC5ODBgyIismTJknL7ZMmSJXLx4kVxdnaWxx9/vMJ2lr1Xy443Zess88gjj8iIESOU5wkJCRIYGCh9+vSRqVOnGm2Di4uLDB8+vFb2x83mzp0r9evXl5MnT8ratWvF0tJSMjMzRUQkPT1dAMjcuXNNzlu2z0Su73tHR0ej6aWlpWJpaSlfffWVUlbZ54BI5Z8lSUlJ4u/vLzqdTlxdXeXJJ58UkeuvtZv7/+jRo7e7a+5InQsjixYtkpCQEBER+fbbb8XPz095gaxYsUJ0Op188skncvDgQXnrrbfE3t7eKIykpaXJsmXLJCsrSw4cOCBDhgwRNzc3KSwsVOrcHEb+/PNP6dixo8TGxipl//3vf8XCwkImT54s2dnZsmTJErG2tpYlS5Yodf7xj39Iq1atZMuWLZKZmSlRUVHi7+8vJSUlIiLSu3dv6d69u/z6669y+PBh+fbbb+U///mPXLt2TVavXi0AJDs7W3Jzc+X8+fM1sDfNc+bMGdFoNJKYmFhpXQDi6uoqixcvlsOHD8uxY8ekpKREJkyYILt27ZIjR47I559/LjY2NrJixQplvvfee0/q168vq1evVvrH3t7+lmHkwoUL8uKLL4q/v7+UlpaKiMjFixfFw8NDnnjiCfntt98kLS1NmjZtahTqZs2aJQ4ODvLvf/9bDh48KGPHjhVLS0vlQDFjxgzx8vKSLVu2SE5OjmzdulW+/PJLERE5deqUcuDPzc01CkFqOXv2rGg0GiUwVWT27NmyadMmOXr0qKSlpUmLFi1k+PDhInI9gM2ZM0ccHBwkNzdXcnNzlaBycxg5e/as9O3bV7p27aqU/fnnn2JjYyMjRoyQrKwsWbNmjbi4uCiBRkTkpZdekkaNGsmGDRtk//79EhMTI/Xr15ezZ8+KiMjIkSMlKChIdu3aJUePHpUffvhBvvnmGxG5/mWi7MM5NzdXmac2qWoYKSgokAYNGshzzz0n+/fvlw0bNkjz5s1NhpHQ0FD56aefZP/+/RIRESHh4eEiInLp0iV59dVX5YEHHlD669KlS5KSkiIAJD09vdL2mgoju3btEicnJ/n000+VsrIwkpKSIv7+/kr5kCFDZMyYMTJmzJh7IowYDAbp0qWLPPLII+Lq6ipTpkxRpr300ktiZ2dnFJ4rcnMYuXbtmixevFgsLS3ljz/+UMor+xyo7LNk165dotVq5csvv5ScnBzZs2ePEpbOnz8vYWFhEhcXp/T/tWvXqmEvma/OhZHw8HDl2/TVq1fFxcVFNm/eLCIiYWFhRkleRCQ0NNQojNystLRU7O3t5dtvv1XKvL29xcrKSmxtbUWv1ysHg7JvliIiAwYMkO7duxst6/XXX1fOnvz+++8CQLZv365MP3PmjFhbWyupuU2bNjJx4kST7So7CN24TrX9/PPPAkBSUlKMyp2dncXW1lZsbW1l7NixInL9oPvyyy9XusyRI0cqKV9ExMPDQ95//33l+dWrV6Vx48blwohWq1XWCUA8PDyMznAtWLBA6tevb3SGYP369WJhYSF5eXkiItKoUaNyZ9Y6dOigvIZGjx4t3bp1M/o2dKObv+Wq7ZdffjHZP5VZuXKlODs7K89NfeMTuR5GLC0txdbWVmxsbASANG/e3Oib2JtvviktWrQw2mdJSUliZ2cnpaWlcvHiRbG0tJQvvvhCmV5SUiKNGjVS+r1v375Gwf9GFX2Lr02qGkY++ugjcXZ2lsuXLyvTFy5cWOGZkTLr168XAMp8ZSHhRu+++64AkHPnzillO3fuVN4ztra2yjGvbJ9aW1uLra2tWFpaCgB54YUXjJZZtp6SkhJxdXWV//znP3Lx4kWxt7eXvXv33jNhREQkKytLAEibNm2MgkePHj2kbdu2RnVnzpxptN/KvhiWnZUqK7ewsBCdTmf0hbQqnwOVfZasXr1aHBwcjL4w38jUGUs11KkxI9nZ2di5cyeeffZZAEC9evUQHR2NRYsWAQCysrIQGhpqNM/NfwAwPz8fcXFxaNasGRwdHeHg4ICLFy/i+PHjRvVef/11ZGZm4tdff1UG/vXu3RulpaXKujp16mQ0T6dOnXDo0CGUlpYiKysL9erVM2qPs7MzWrRogaysLADASy+9hKlTp6JTp05ISEi46wMwq8vOnTuRmZmJBx54wOgPKIaEhJSrm5SUhODgYDRs2BB2dnZYsGCBsu8LCgqQm5trtM/q1atncjldu3ZFZmYmMjMzsXPnTkRFRaFnz57KYMqsrCwEBgbC1tZWmadTp04wGAzIzs5GYWEhTp48abIPy/pn8ODByMzMRIsWLfDSSy/h+++/v4O9VPOkijdj/vHHH/HII4/A09MT9vb2GDhwIM6ePVulwcf//Oc/kZmZib1792Lbtm3w9/fHo48+igsXLgC4vt/DwsKg0WiUeTp16oSLFy/izz//xOHDh3H16lWj/W5paYmOHTsq+3348OFYvnw5goKCMHbsWOzYscOc3XDPyM7ORtu2baHX65Wyjh07mqzbtm1b5f8eHh4AgFOnTpm1vrZt2yrvmaKiIly7ds1o+ooVK5S+/eqrr/D1119j3Lhx5ZZjaWmJ5557DkuWLMHKlSvRvHlzo/bdCxYvXgwbGxscPXq03PiXmz3//PPIzMzExx9/jKKiIqP3mb29vbJPMzIyMH36dAwbNgzffvstAFTpc6Cyz5Lu3bvD29sbvr6+GDhwIL744ou7cqGAuepUGFm0aBGuXbuGRo0aoV69eqhXrx4++ugjrF69utxgrIrExMQgMzMTc+fOxY4dO5CZmQlnZ2eUlJQY1XNxcYG/vz+aNWuGbt26Yc6cOdixYwc2b95cbdszdOhQHDlyBAMHDsRvv/2GkJAQfPjhh9W2/Orm7+8PjUZTbnCWr68v/P39YW1tbVR+YxAAgOXLl+O1117DkCFD8P333yMzMxOxsbHl9n1V2Nrawt/fH/7+/ujQoQM++eQTFBUVYeHCheZvWAXat2+Po0ePYsqUKbh8+TL69++Pp556qtqWX92aNWsGjUaDgwcPVlgnJycHffr0Qdu2bbF69Wrs3r0bSUlJAFClfnB0dFT2e6dOnbBo0SIcOnQIK1asqLbtKAuVr7zyCk6ePIlHHnkEr732WrUt/15kaWmp/L8s6BkMhgrrN2vWDACM3qs6nU7pO1O8vLzg7++PVq1a4emnn8bLL7+MmTNn4sqVK+XqPv/881i5ciWSkpLw/PPP39Y2qWXHjh2YPXs21q1bh44dO2LIkCFKwGjWrBmOHDliNODeyckJ/v7+8PT0LLcsCwsLZZ+2bdsW8fHx6NKlC957771qa6+9vT327NmDf//73/Dw8MCECRMQGBhY6660rDNh5Nq1a/jss88wc+ZMJYmWpfhGjRrh3//+N1q1aoVffvnFaL6ff/7Z6Pn27dvx0ksvoVevXnjggQeg0+lw5syZStev1WoBAJcvXwYAtGrVCtu3by+37ObNm0Or1aJVq1a4du2aUXvOnj2L7OxsBAQEKGVeXl4YNmwYUlJS8OqrryofplZWVgCgnImpDZydndG9e3fMmzcPRUVFZs+/fft2hIeHY8SIEWjXrh38/f1x+PBhZbqjoyM8PDyM9tm1a9ewe/fuSpet0WhgYWFh1D979+41auf27dthYWGBFi1awMHBAY0aNTLZhzf2j4ODA6Kjo7Fw4UKsWLECq1evxrlz5wBc/4CoTf3ToEEDREVFISkpyWT/nD9/Hrt374bBYMDMmTPx4IMPonnz5uWuSLOysqrydpl6X6Snpxt9e9y+fTvs7e3RuHFj+Pn5wcrKymi/X716Fbt27TLa7w0bNkRMTAw+//xzzJkzBwsWLFDaBtSu98XtatGiBX777Tejs4m7du0yezmm+uvRRx9FgwYN7uhDUavV4tq1ayZD6gMPPIAHHngA+/btw4ABA257HXfbpUuXMHjwYAwfPhxdu3bFokWLsHPnTiQnJwMAnn32WVy8eBHz58+/7XVotVqj90NlnwOVfZYA188QR0ZG4v3338evv/6KnJwcbNq0CYB579cape6vRHfPmjVrxMrKyuRAzrFjx0pISIgsX75c9Hq9LF68WLKzs2XChAnlBrC2a9dOunfvLgcOHJCff/5ZIiIixNra2mjAqre3t0yePFlyc3Pl5MmT8ssvv0jnzp2lYcOGcubMGRER2b17t9Ggo6VLl5YbwPrYY49JQECAbN26VTIzM6VHjx5GA5fGjBkjqampcuTIEdm9e7eEhoZK//79ReT6QECNRiNLly6VU6dOGV0FoqY//vhD3NzcpGXLlrJ8+XI5cOCAHDx4UJYtWyZubm4SHx8vIqbHU8ydO1ccHBwkNTVVsrOz5e233xYHBwej/nn33XelQYMGsmbNGsnKypK4uDiTA1h79OihDNg6cOCAjBgxQjQajTJ+qKioSDw8POTJJ5+U3377TTZt2iS+vr5GA1hnz54tDg4Osnz5cjl48KC88cYbRgNYZ86cKV9++aVkZWVJdna2DBkyRNzd3ZVBss2aNZPhw4dLbm6u0W/zajp8+LC4u7tLQECArFq1Sn7//Xc5cOCAzJ07V1q2bCmZmZkCQObMmSOHDx+Wzz77TDw9PY3GJ23fvl0Zp3D69GkpKioSkeu/Td84UC4zM1OefPJJ0ev1ytUdZQNYR44cKVlZWbJ27dpyA1jHjBkjjRo1ku+++85oAGvZPnznnXdk7dq1cujQIdm3b5/06dNHOnbsKCLXxxBZW1vL1KlTJS8vr1YM7L5ZTEyMdOnSRTIyMowex48fNzmAddCgQXLgwAFJTU2Vli1bCgDl6g5TY8cyMjKMrpr44osvxNbWVjIyMuT06dNy5coVERFJSUkRS0tL6dWrl6Smpsrhw4dl79698t577wkAZVBw2ZiRskHBJ06ckA0bNoinp6fR4OSbx6ZcvHjRqF33wpiRl156Sfz9/ZXXtIhIcnKy2NnZKfvz1VdfFa1WK6+88ops3bpVcnJyJD09XZ577jnRaDRSUFAgItfHjNw40PvIkSPy8ccfi1arlUmTJinLr+xzoLLPkm+//Vbmzp0rGRkZkpOTI/PnzxcLCwvZt2+fiIjExcVJhw4d5OjRo3L69Gnl+HS31Zkw0qdPH+nVq5fJaWUD9/bu3SvTpk0TFxcXsbOzk5iYGBk7dqzRG2jPnj0SEhIier1emjVrJitXrix39czNl202bNhQevXqVW7QXNnlWJaWltKkSROZMWOG0fSyS7ocHR3F2tpaoqKijC7pGjVqlPj5+YlOp5OGDRvKwIEDlbAjIjJ58mRxd3cXjUZTay7tFRE5efKkjBo1Spo2bSqWlpZiZ2cnHTt2lBkzZihvclNh5MqVKzJ48GBxdHQUJycnGT58uIwbN86of65evSpjxowRBwcHcXJykvj4eJOX9t7YP/b29tKhQwdZtWqV0fqqcmnvxIkTxdPTUywtLctd2rtgwQIJCgoSW1tbcXBwkEceeUT27NmjTP/mm2/E399f6tWrV2su7RW53j8jR45UBmJ7enrKP/7xDyWozZo1Szw8PJTX5GeffVbuA2/YsGHi7Oxc7tLeG/d7/fr1pXPnzrJp0yaj9Vd2ae/ly5dl9OjR4uLiYvLS3ilTpkirVq3E2tpaGjRoII899pgcOXJEmb5w4ULx8vISCwuLWvnhZ+pySwAyZMgQk5f2tm3bVqysrCQ4OFi+/PJLAaCEu6qEkStXrsiTTz4pTk5OyhVeZXbt2iVPPfWUuLq6Sr169cTZ2VmioqJk+fLl5S7tLXtotVpp3LixxMXFGV0lZmqg7I1qexj56aefRKvVytatW8tNe/TRR40Gq69YsUK6dOkijo6OYmlpKY0bN5YBAwbIzz//rMxz82XVOp1OmjdvLtOmTTO6oqWyzwGRW3+WbN26VTp37iz169cXa2tradu2rdEViNnZ2fLggw+KtbW1qpf2akSqOGqNiIhqtS+++AKxsbEoKCgoNwaLqDarp3YDiIjo9nz22Wfw9fWFp6cn9u7dizfeeAP9+/dnEKF7DsMIEdE9Ki8vDxMmTEBeXh48PDzw9NNPY9q0aWo3i8hs/JmGiIiIVFVnLu0lIiKi2olhhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREanq/wDRTrPB+w4rggAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Liver scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(liver_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Liver'] = liver_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "\u001b[1;32me:\\Cursos\\MestradoCienciaComputação\\Seminario\\Code\\AlgorithmComparison\\AlgorithmComparison\\AlgorithmComparison3.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n",
            "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Cursos/MestradoCienciaComputa%C3%A7%C3%A3o/Seminario/Code/AlgorithmComparison/AlgorithmComparison/AlgorithmComparison3.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Algo_results\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n",
            "\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n",
            "\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n",
            "\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n",
            "\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "\n",
            "File \u001b[1;32mc:\\Users\\ErikC\\anaconda3\\envs\\AlgoComparison\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n",
            "\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n",
            "\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n",
            "\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
            "\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n",
            "\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Tuned_Algo_results_tr = Algo_results.set_index('Names').T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Tuned_Algo_results_tr.to_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Algo_Results\\TunedAlgoResults.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-be3a016f-fc55-428f-9940-db49f5b57083\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Names</th>\n",
              "      <th>AdaBoost</th>\n",
              "      <th>GradBoost</th>\n",
              "      <th>CatBoost</th>\n",
              "      <th>LightGBM</th>\n",
              "      <th>XGBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Wine</th>\n",
              "      <td>91.807190</td>\n",
              "      <td>94.375817</td>\n",
              "      <td>97.852941</td>\n",
              "      <td>97.575163</td>\n",
              "      <td>96.614379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <td>95.620631</td>\n",
              "      <td>96.706948</td>\n",
              "      <td>97.173274</td>\n",
              "      <td>96.792839</td>\n",
              "      <td>96.398551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sonar</th>\n",
              "      <td>82.040476</td>\n",
              "      <td>83.616667</td>\n",
              "      <td>86.102381</td>\n",
              "      <td>87.314286</td>\n",
              "      <td>85.240476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ionosphere</th>\n",
              "      <td>92.931746</td>\n",
              "      <td>93.502381</td>\n",
              "      <td>93.672222</td>\n",
              "      <td>93.845238</td>\n",
              "      <td>92.879365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TicTacToe</th>\n",
              "      <td>73.999781</td>\n",
              "      <td>64.249781</td>\n",
              "      <td>51.880154</td>\n",
              "      <td>56.338487</td>\n",
              "      <td>45.845943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bupa</th>\n",
              "      <td>72.869748</td>\n",
              "      <td>72.792437</td>\n",
              "      <td>74.595798</td>\n",
              "      <td>72.146218</td>\n",
              "      <td>71.145378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pima</th>\n",
              "      <td>75.099624</td>\n",
              "      <td>76.271360</td>\n",
              "      <td>76.308612</td>\n",
              "      <td>74.552973</td>\n",
              "      <td>73.916268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>82.333333</td>\n",
              "      <td>81.222222</td>\n",
              "      <td>80.592593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Liver</th>\n",
              "      <td>72.869748</td>\n",
              "      <td>72.850420</td>\n",
              "      <td>74.595798</td>\n",
              "      <td>72.146218</td>\n",
              "      <td>71.145378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be3a016f-fc55-428f-9940-db49f5b57083')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be3a016f-fc55-428f-9940-db49f5b57083 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be3a016f-fc55-428f-9940-db49f5b57083');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5225df51-780e-4b4a-adc4-f8777e6517eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5225df51-780e-4b4a-adc4-f8777e6517eb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5225df51-780e-4b4a-adc4-f8777e6517eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Names           AdaBoost  GradBoost   CatBoost   LightGBM    XGBoost\n",
              "Wine           91.807190  94.375817  97.852941  97.575163  96.614379\n",
              "Breast_Cancer  95.620631  96.706948  97.173274  96.792839  96.398551\n",
              "Sonar          82.040476  83.616667  86.102381  87.314286  85.240476\n",
              "Ionosphere     92.931746  93.502381  93.672222  93.845238  92.879365\n",
              "TicTacToe      73.999781  64.249781  51.880154  56.338487  45.845943\n",
              "Bupa           72.869748  72.792437  74.595798  72.146218  71.145378\n",
              "Pima           75.099624  76.271360  76.308612  74.552973  73.916268\n",
              "Heart          80.000000  80.000000  82.333333  81.222222  80.592593\n",
              "Liver          72.869748  72.850420  74.595798  72.146218  71.145378"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Tuned_Algo_results_tr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Friedman's Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-posthocs\n",
            "  Downloading scikit_posthocs-0.7.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (1.10.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (0.14.0)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (1.5.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (0.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (3.1.1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->scikit-posthocs) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->scikit-posthocs) (1.16.0)\n",
            "Installing collected packages: scikit-posthocs\n",
            "Successfully installed scikit-posthocs-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-posthocs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scikit_posthocs as sp\n",
        "from scipy.stats import friedmanchisquare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Tuned_Algo_results_tr = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Algo_Results\\TunedAlgoResults.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea2fd95b-2e3e-429c-b8d7-a21f673b77cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AdaBoost</th>\n",
              "      <th>GradBoost</th>\n",
              "      <th>CatBoost</th>\n",
              "      <th>LightGBM</th>\n",
              "      <th>XGBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>91.807190</td>\n",
              "      <td>94.375817</td>\n",
              "      <td>97.852941</td>\n",
              "      <td>97.575163</td>\n",
              "      <td>96.614379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>95.620631</td>\n",
              "      <td>96.706948</td>\n",
              "      <td>97.173274</td>\n",
              "      <td>96.792839</td>\n",
              "      <td>96.398551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>82.040476</td>\n",
              "      <td>83.616667</td>\n",
              "      <td>86.102381</td>\n",
              "      <td>87.314286</td>\n",
              "      <td>85.240476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>92.931746</td>\n",
              "      <td>93.502381</td>\n",
              "      <td>93.672222</td>\n",
              "      <td>93.845238</td>\n",
              "      <td>92.879365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73.999781</td>\n",
              "      <td>64.249781</td>\n",
              "      <td>51.880154</td>\n",
              "      <td>56.338487</td>\n",
              "      <td>45.845943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>72.869748</td>\n",
              "      <td>72.792437</td>\n",
              "      <td>74.595798</td>\n",
              "      <td>72.146218</td>\n",
              "      <td>71.145378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>75.099624</td>\n",
              "      <td>76.271360</td>\n",
              "      <td>76.308612</td>\n",
              "      <td>74.552973</td>\n",
              "      <td>73.916268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>82.333333</td>\n",
              "      <td>81.222222</td>\n",
              "      <td>80.592593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>72.869748</td>\n",
              "      <td>72.850420</td>\n",
              "      <td>74.595798</td>\n",
              "      <td>72.146218</td>\n",
              "      <td>71.145378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea2fd95b-2e3e-429c-b8d7-a21f673b77cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea2fd95b-2e3e-429c-b8d7-a21f673b77cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea2fd95b-2e3e-429c-b8d7-a21f673b77cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddb6d296-ac12-4a7f-a822-40ca174504d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddb6d296-ac12-4a7f-a822-40ca174504d3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddb6d296-ac12-4a7f-a822-40ca174504d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    AdaBoost  GradBoost   CatBoost   LightGBM    XGBoost\n",
              "0  91.807190  94.375817  97.852941  97.575163  96.614379\n",
              "1  95.620631  96.706948  97.173274  96.792839  96.398551\n",
              "2  82.040476  83.616667  86.102381  87.314286  85.240476\n",
              "3  92.931746  93.502381  93.672222  93.845238  92.879365\n",
              "4  73.999781  64.249781  51.880154  56.338487  45.845943\n",
              "5  72.869748  72.792437  74.595798  72.146218  71.145378\n",
              "6  75.099624  76.271360  76.308612  74.552973  73.916268\n",
              "7  80.000000  80.000000  82.333333  81.222222  80.592593\n",
              "8  72.869748  72.850420  74.595798  72.146218  71.145378"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Tuned_Algo_results_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stat, p_value = friedmanchisquare(Tuned_Algo_results_tr['AdaBoost'], Tuned_Algo_results_tr['GradBoost'], Tuned_Algo_results_tr['CatBoost'], Tuned_Algo_results_tr['LightGBM'], Tuned_Algo_results_tr['XGBoost'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.005409356545370461"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "p_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are significant differences among the models.\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print('There are significant differences among the models.')\n",
        "else:\n",
        "    print('There are no significant differences among the models.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Nemenyi test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nemenyi_results = sp.posthoc_nemenyi_friedman(a=Tuned_Algo_results_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8cd9dd92-0d8d-445e-855a-f8d01d079fb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AdaBoost</th>\n",
              "      <th>GradBoost</th>\n",
              "      <th>CatBoost</th>\n",
              "      <th>LightGBM</th>\n",
              "      <th>XGBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.068887</td>\n",
              "      <td>0.686234</td>\n",
              "      <td>0.855438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradBoost</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194391</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.601630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>0.068887</td>\n",
              "      <td>0.194391</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.643932</td>\n",
              "      <td>0.003195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.686234</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.643932</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.166548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.855438</td>\n",
              "      <td>0.601630</td>\n",
              "      <td>0.003195</td>\n",
              "      <td>0.166548</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cd9dd92-0d8d-445e-855a-f8d01d079fb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cd9dd92-0d8d-445e-855a-f8d01d079fb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cd9dd92-0d8d-445e-855a-f8d01d079fb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f10e43a-074d-489f-acff-d2b9a07dbcd8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f10e43a-074d-489f-acff-d2b9a07dbcd8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f10e43a-074d-489f-acff-d2b9a07dbcd8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           AdaBoost  GradBoost  CatBoost  LightGBM   XGBoost\n",
              "AdaBoost   1.000000   0.900000  0.068887  0.686234  0.855438\n",
              "GradBoost  0.900000   1.000000  0.194391  0.900000  0.601630\n",
              "CatBoost   0.068887   0.194391  1.000000  0.643932  0.003195\n",
              "LightGBM   0.686234   0.900000  0.643932  1.000000  0.166548\n",
              "XGBoost    0.855438   0.601630  0.003195  0.166548  1.000000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "nemenyi_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models 1 and 2 are not significantly different (p-value = 0.9000).\n",
            "Models 1 and 3 are not significantly different (p-value = 0.0689).\n",
            "Models 1 and 4 are not significantly different (p-value = 0.6862).\n",
            "Models 1 and 5 are not significantly different (p-value = 0.8554).\n",
            "Models 2 and 3 are not significantly different (p-value = 0.1944).\n",
            "Models 2 and 4 are not significantly different (p-value = 0.9000).\n",
            "Models 2 and 5 are not significantly different (p-value = 0.6016).\n",
            "Models 3 and 4 are not significantly different (p-value = 0.6439).\n",
            "Models 3 and 5 are significantly different (p-value = 0.0032).\n",
            "Models 4 and 5 are not significantly different (p-value = 0.1665).\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.05\n",
        "\n",
        "# Print p-values for all pairs of models\n",
        "for i in range(nemenyi_results.shape[0]):\n",
        "    for j in range(i + 1, nemenyi_results.shape[1]):\n",
        "        model1 = i + 1\n",
        "        model2 = j + 1\n",
        "        p_value = nemenyi_results.iloc[i, j]\n",
        "\n",
        "        if p_value < alpha:\n",
        "            print(f\"Models {model1} and {model2} are significantly different (p-value = {p_value:.4f}).\")\n",
        "        else:\n",
        "            print(f\"Models {model1} and {model2} are not significantly different (p-value = {p_value:.4f}).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Comparison between the balanced and unbalanced dataset algorithm performance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unbalanced_df = pd.read_csv('/content/drive/MyDrive/DatasetSeminario/Algo_results/AlgoResults.csv')\n",
        "# balanced_df = pd.read_csv('/content/drive/MyDrive/DatasetSeminario/Algo_results/StratAlgoResults.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9, 5)\n",
            "(9, 5)\n"
          ]
        }
      ],
      "source": [
        "# print(unbalanced_df.shape)\n",
        "# print(balanced_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# datasets = ['Wine', 'Breast Cancer', 'Sonar', 'Ionosphere', 'TicTacToe', 'Bupa', 'Pima', 'Heart', 'Liver']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison between Wine models results\n",
            "Test Statistic: 7.0\n",
            "P-value: 1.0\n",
            "Fail to reject the null hypothesis: There is no significant difference between Wine models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Breast Cancer models results\n",
            "Test Statistic: 6.0\n",
            "P-value: 0.8125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Breast Cancer models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Sonar models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Sonar models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Ionosphere models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Ionosphere models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between TicTacToe models results\n",
            "Test Statistic: 3.0\n",
            "P-value: 0.3125\n",
            "Fail to reject the null hypothesis: There is no significant difference between TicTacToe models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Bupa models results\n",
            "Test Statistic: 0.0\n",
            "P-value: 0.0625\n",
            "Fail to reject the null hypothesis: There is no significant difference between Bupa models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Pima models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Pima models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Heart models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Heart models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Liver models results\n",
            "Test Statistic: 0.0\n",
            "P-value: 0.0625\n",
            "Fail to reject the null hypothesis: There is no significant difference between Liver models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n"
          ]
        }
      ],
      "source": [
        "# for i, name in enumerate(datasets):\n",
        "#   # Creating two lists of paired data\n",
        "#   before = unbalanced_df.iloc[i, :]\n",
        "#   after = balanced_df.iloc[i, :]\n",
        "\n",
        "#   # Performing the Wilcoxon signed-rank test\n",
        "#   statistic, p_value = stats.wilcoxon(before, after)\n",
        "\n",
        "#   print (f'Comparison between {name} models results')\n",
        "\n",
        "#   # Printing the test statistic and p-value\n",
        "#   print(f\"Test Statistic: {statistic}\")\n",
        "#   print(f\"P-value: {p_value}\")\n",
        "\n",
        "#   # Interpreting the results\n",
        "#   alpha = 0.05\n",
        "#   if p_value < alpha:\n",
        "#       print(f'Reject the null hypothesis: There is a significant difference between {name} models.')\n",
        "#   else:\n",
        "#       print(f'Fail to reject the null hypothesis: There is no significant difference between {name} models.')\n",
        "#   print ('- - - - - - - - - - - - - - - - - - - - -')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMVO8koMTTTdYQJS3YoNuih",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
