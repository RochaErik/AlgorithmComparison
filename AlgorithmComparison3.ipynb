{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RochaErik/AlgorithmComparison/blob/main/AlgorithmComparison3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eemeaAaCsyS"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7sPV5hJCeJ2"
      },
      "source": [
        "# **Evaluating algorithms with hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knwYV1QmCuEU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnwsW6x9w1QO",
        "outputId": "fad3ad0d-f838-4cfe-e95c-f8295d5fd365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (1.2.1)\n",
            "Requirement already satisfied: graphviz in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (3.7.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (2.1.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (1.11.2)\n",
            "Requirement already satisfied: plotly in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (5.16.1)\n",
            "Requirement already satisfied: six in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->catboost) (6.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.16.2)\n",
            "Requirement already satisfied: lightgbm in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from lightgbm) (1.11.2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from xgboost) (1.11.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install lightgbm\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "sp9bGvxdqiOw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import scipy.stats as stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB5jc4iDCWZI",
        "outputId": "a417925a-0c0b-4a02-e9a2-ca428226ab51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (1.11.2)\n",
            "Requirement already satisfied: six in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (3.1)\n",
            "Requirement already satisfied: future in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (4.66.1)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "pnmKn_fsDTha"
      },
      "outputs": [],
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByCnDDmkDayW"
      },
      "source": [
        "# **Wine Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "23mGy-W6DZLy"
      },
      "outputs": [],
      "source": [
        "wine_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Wine\\wine.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "C0N1S4LWDnbw"
      },
      "outputs": [],
      "source": [
        "X = wine_df.iloc[:, 1:]\n",
        "y = wine_df.iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "omlj8qxkDoM1"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "bEtKdQvTEsAR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcZuN-z4CdXh",
        "outputId": "ee31c32a-6b6b-467e-f741-153da73f7c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:11,  4.18trial/s, best loss: -0.9722222222222222]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:26<00:00,  1.90trial/s, best loss: -1.0]              \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 200.0, 'learning_rate': 0.06659352635164861, 'max_depth': 4.0, 'max_features': 'sqrt', 'min_samples_leaf': 3.0, 'min_samples_split': 2.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [01:14<00:00,  1.49s/trial, best loss: -1.0]              \n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.04102652661864284, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 7, 'min_weight_fraction_leaf': 0.0, 'min_impurity_decrease': 1.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [02:39<00:00,  3.19s/trial, best loss: -1.0]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 550, 'learning_rate': 0.0479901225935416, 'min_child_samples': 1, 'max_depth': 6, 'reg_lambda': 3.3766279624518107, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 33.81trial/s, best loss: -0.9722222222222222]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'gbdt', 'num_leaves': 55, 'learning_rate': 0.04496177447997528, 'min_child_samples': 10, 'reg_alpha': 0.3916912792044354, 'reg_lambda': 1.4941077467431771, 'colsample_by_tree': 0.379259630420579, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.08trial/s, best loss: -1.0]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'dart', 'learning_rate': 0.09292666170093178, 'gamma': 4, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.8943278668489419, 'colsample_bylevel': 0.2640104690942444, 'colsample_bynode': 0.8937107554719765, 'reg_alpha': 0.056770729092546546, 'reg_lambda': 4.219736540591216, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 200.0,\n",
              " 'learning_rate': 0.06659352635164861,\n",
              " 'max_depth': 4.0,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 3.0,\n",
              " 'min_samples_split': 2.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['AdaBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'criterion': 'friedman_mse',\n",
              " 'max_features': 'sqrt',\n",
              " 'n_estimators': 100,\n",
              " 'learning_rate': 0.04102652661864284,\n",
              " 'max_depth': 3,\n",
              " 'min_samples_split': 7,\n",
              " 'min_samples_leaf': 7,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'min_impurity_decrease': 1.0,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['GradBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 550,\n",
              " 'learning_rate': 0.0479901225935416,\n",
              " 'min_child_samples': 1,\n",
              " 'max_depth': 6,\n",
              " 'reg_lambda': 3.3766279624518107,\n",
              " 'silent': True,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['CatBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'class_weight': 'balanced',\n",
              " 'boosting_type': 'gbdt',\n",
              " 'num_leaves': 55,\n",
              " 'learning_rate': 0.04496177447997528,\n",
              " 'min_child_samples': 10,\n",
              " 'reg_alpha': 0.3916912792044354,\n",
              " 'reg_lambda': 1.4941077467431771,\n",
              " 'colsample_by_tree': 0.379259630420579,\n",
              " 'verbosity': -1,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['LightGBM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'booster': 'dart',\n",
              " 'learning_rate': 0.09292666170093178,\n",
              " 'gamma': 4,\n",
              " 'max_depth': 4,\n",
              " 'min_child_weight': 1,\n",
              " 'colsample_bytree': 0.8943278668489419,\n",
              " 'colsample_bylevel': 0.2640104690942444,\n",
              " 'colsample_bynode': 0.8937107554719765,\n",
              " 'reg_alpha': 0.056770729092546546,\n",
              " 'reg_lambda': 4.219736540591216,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "AiGBWUhXmjty"
      },
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "x7JQf94WmaZT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Wine Dataset ---------\n",
            "[0.94444444 0.94444444 0.94444444 1.         0.94444444 1.\n",
            " 1.         0.83333333 1.         1.         1.         1.\n",
            " 0.94444444 1.         0.94444444 1.         1.         0.88888889\n",
            " 1.         0.94117647 1.         1.         0.88888889 0.94444444\n",
            " 1.         1.         1.         1.         0.88235294 1.\n",
            " 0.94444444 1.         1.         0.94444444 1.         0.94444444\n",
            " 1.         1.         0.94117647 0.88235294 0.88888889 1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 0.82352941 0.94117647 1.         0.94444444 1.         0.94444444\n",
            " 1.         1.         0.94444444 0.94444444 0.94117647 0.94117647\n",
            " 1.         1.         0.94444444 1.         1.         0.88888889\n",
            " 0.94444444 0.94444444 0.88235294 1.         0.94444444 1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 0.94444444\n",
            " 0.94117647 0.94117647 1.         1.         1.         0.94444444\n",
            " 1.         0.94444444 0.94444444 1.         0.94117647 1.\n",
            " 0.94444444 0.94444444 1.         0.94444444 1.         0.88888889\n",
            " 0.94444444 0.94444444 0.94117647 1.        ]\n",
            "Accuracy: 96.55% (4.09%)\n",
            "------------------------------\n",
            "--------- GradBoost on Wine Dataset ---------\n",
            "[1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94444444 0.94444444\n",
            " 1.         0.94117647 1.         1.         0.88888889 0.94444444\n",
            " 1.         1.         1.         1.         0.94117647 0.88235294\n",
            " 0.94444444 1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.82352941 1.         1.\n",
            " 1.         0.94444444 1.         0.94444444 1.         1.\n",
            " 0.94117647 1.         1.         0.94444444 0.94444444 1.\n",
            " 1.         1.         1.         0.94444444 1.         0.94117647\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94117647 1.         1.         1.         0.94444444\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 0.94444444 0.94444444 0.94117647 1.        ]\n",
            "Accuracy: 98.08% (3.44%)\n",
            "------------------------------\n",
            "--------- CatBoost on Wine Dataset ---------\n",
            "[1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94444444 0.94444444\n",
            " 1.         0.94117647 1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.94117647 0.94117647\n",
            " 0.94444444 1.         1.         0.94444444 1.         1.\n",
            " 1.         1.         0.94117647 0.94117647 0.94444444 1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 0.94117647 1.         1.         0.94444444 1.         0.94444444\n",
            " 1.         1.         1.         0.94444444 1.         0.94117647\n",
            " 1.         1.         0.88888889 1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94117647 1.         1.         1.         0.94444444\n",
            " 1.         0.88888889 1.         1.         0.94117647 1.\n",
            " 1.         0.94444444 1.         0.94444444 0.94444444 1.\n",
            " 0.94444444 1.         0.94117647 1.        ]\n",
            "Accuracy: 97.97% (3.03%)\n",
            "------------------------------\n",
            "--------- LightGBM on Wine Dataset ---------\n",
            "[1.         0.94444444 0.94444444 1.         0.94444444 1.\n",
            " 1.         0.77777778 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.88235294 0.94117647\n",
            " 0.94444444 1.         1.         1.         1.         1.\n",
            " 1.         0.88888889 0.94117647 0.94117647 0.94444444 1.\n",
            " 1.         0.94444444 1.         0.94444444 1.         1.\n",
            " 0.88235294 0.94117647 1.         0.94444444 1.         0.94444444\n",
            " 1.         1.         1.         0.94444444 1.         0.94117647\n",
            " 0.94444444 1.         0.94444444 1.         1.         1.\n",
            " 1.         0.94444444 0.88235294 1.         0.94444444 1.\n",
            " 1.         0.94444444 1.         1.         1.         0.94444444\n",
            " 0.94117647 0.94117647 1.         1.         1.         0.88888889\n",
            " 1.         0.88888889 1.         0.94444444 1.         1.\n",
            " 1.         0.94444444 1.         0.94444444 0.88888889 1.\n",
            " 1.         0.94444444 0.94117647 1.        ]\n",
            "Accuracy: 97.12% (4.03%)\n",
            "------------------------------\n",
            "--------- XGBoost on Wine Dataset ---------\n",
            "[1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 1.         0.88888889 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94444444 0.88888889\n",
            " 1.         0.94117647 1.         1.         0.94444444 0.94444444\n",
            " 1.         1.         1.         1.         0.94117647 0.88235294\n",
            " 0.94444444 1.         1.         1.         1.         1.\n",
            " 1.         1.         0.94117647 0.88235294 0.94444444 1.\n",
            " 1.         0.94444444 1.         0.94444444 1.         1.\n",
            " 0.94117647 1.         1.         0.94444444 0.94444444 1.\n",
            " 1.         1.         1.         1.         1.         0.94117647\n",
            " 1.         1.         0.88888889 1.         1.         1.\n",
            " 0.94444444 0.94444444 1.         1.         1.         1.\n",
            " 1.         0.94444444 1.         1.         1.         0.94444444\n",
            " 1.         0.94117647 1.         1.         1.         0.94444444\n",
            " 1.         0.88888889 1.         0.94444444 1.         1.\n",
            " 1.         0.94444444 1.         1.         0.94444444 1.\n",
            " 1.         0.94444444 0.94117647 1.        ]\n",
            "Accuracy: 97.80% (3.38%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "wine_scores = []\n",
        "wine_scores_mean = []\n",
        "wine_scores_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    wine_scores.append(results)\n",
        "    wine_scores_mean.append(results.mean()*100)\n",
        "    wine_scores_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Wine Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Wine scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(wine_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results = pd.DataFrame()\n",
        "Algo_results['Names'] = names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Wine'] = wine_scores_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine\n",
              "0   AdaBoost  96.552288\n",
              "1  GradBoost  98.075163\n",
              "2   CatBoost  97.967320\n",
              "3   LightGBM  97.120915\n",
              "4    XGBoost  97.797386"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Breast Cancer Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "breast_cancer_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\BreastCancer\\Breast.dat', sep=',', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = breast_cancer_df.iloc[:, :-1]\n",
        "y = breast_cancer_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:44<00:00,  1.12trial/s, best loss: -0.9927007299270073]\n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 450.0, 'learning_rate': 0.01199453123793802, 'max_depth': 4.0, 'max_features': 'log2', 'min_samples_leaf': 4.0, 'min_samples_split': 6.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:18<00:00,  2.67trial/s, best loss: -0.9927007299270073]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 550, 'learning_rate': 0.0611622198189229, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 1.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:40<00:00,  1.23trial/s, best loss: -0.9927007299270073]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 300, 'learning_rate': 0.013094250183297027, 'min_child_samples': 1, 'max_depth': 5, 'reg_lambda': 4.710165866797953, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 36.89trial/s, best loss: -0.9854014598540146]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'goss', 'num_leaves': 70, 'learning_rate': 0.06466735422122151, 'min_child_samples': 60, 'reg_alpha': 1.7712918439651535, 'reg_lambda': 0.09630512995808138, 'colsample_by_tree': 0.9773212695265424, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:09<00:00,  5.36trial/s, best loss: -0.9927007299270073]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'dart', 'learning_rate': 0.01958151011028328, 'gamma': 5, 'max_depth': 3, 'min_child_weight': 3, 'colsample_bytree': 0.17755828466772988, 'colsample_bylevel': 0.2750454258060418, 'colsample_bynode': 0.5404751722067938, 'reg_alpha': 1.5842037921731331, 'reg_lambda': 1.1583230510671016, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 450.0,\n",
              " 'learning_rate': 0.01199453123793802,\n",
              " 'max_depth': 4.0,\n",
              " 'max_features': 'log2',\n",
              " 'min_samples_leaf': 4.0,\n",
              " 'min_samples_split': 6.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['AdaBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['GradBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['CatBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['LightGBM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Breast Cancer Dataset ---------\n",
            "[0.95652174 0.97101449 0.92753623 0.95588235 0.97058824 1.\n",
            " 0.97058824 0.97058824 0.98529412 0.98529412 0.97101449 0.95652174\n",
            " 0.95652174 0.98529412 0.95588235 0.95588235 1.         0.97058824\n",
            " 0.98529412 0.97058824 1.         0.95652174 0.97101449 0.98529412\n",
            " 0.95588235 0.98529412 0.97058824 0.98529412 0.97058824 0.97058824\n",
            " 0.98550725 0.94202899 0.98550725 0.97058824 0.98529412 1.\n",
            " 0.97058824 0.98529412 0.94117647 0.95588235 0.95652174 0.98550725\n",
            " 0.98550725 1.         0.98529412 0.97058824 0.97058824 0.98529412\n",
            " 0.95588235 0.94117647 0.98550725 0.92753623 1.         1.\n",
            " 0.94117647 0.98529412 0.97058824 0.98529412 0.97058824 0.97058824\n",
            " 0.95652174 0.98550725 0.98550725 0.91176471 0.98529412 0.98529412\n",
            " 0.94117647 0.97058824 0.92647059 1.         0.95652174 1.\n",
            " 0.97101449 0.95588235 0.98529412 0.94117647 0.98529412 0.98529412\n",
            " 0.95588235 0.97058824 0.97101449 0.97101449 0.97101449 0.97058824\n",
            " 0.98529412 0.95588235 0.97058824 0.97058824 0.98529412 0.97058824\n",
            " 1.         0.95652174 0.98550725 0.97058824 0.95588235 1.\n",
            " 0.97058824 0.98529412 0.97058824 0.94117647]\n",
            "Accuracy: 97.16% (1.86%)\n",
            "------------------------------\n",
            "--------- GradBoost on Breast Cancer Dataset ---------\n",
            "[0.95652174 0.98550725 0.98550725 0.95588235 0.97058824 0.98529412\n",
            " 0.95588235 0.97058824 0.95588235 0.98529412 0.95652174 0.97101449\n",
            " 0.97101449 0.97058824 0.95588235 0.92647059 1.         0.92647059\n",
            " 0.97058824 0.97058824 1.         0.94202899 0.95652174 0.97058824\n",
            " 0.97058824 0.98529412 0.97058824 0.95588235 0.97058824 0.98529412\n",
            " 0.95652174 0.95652174 0.97101449 0.97058824 0.97058824 1.\n",
            " 0.98529412 0.98529412 0.89705882 0.97058824 0.95652174 0.98550725\n",
            " 0.97101449 0.98529412 0.97058824 0.94117647 0.95588235 0.98529412\n",
            " 0.94117647 0.95588235 1.         0.91304348 1.         0.98529412\n",
            " 0.89705882 0.97058824 0.95588235 0.97058824 0.98529412 0.98529412\n",
            " 0.95652174 0.98550725 0.97101449 0.95588235 0.97058824 1.\n",
            " 0.94117647 0.97058824 0.97058824 0.98529412 0.98550725 0.98550725\n",
            " 0.97101449 0.95588235 0.98529412 0.94117647 0.97058824 0.94117647\n",
            " 0.95588235 0.95588235 0.94202899 0.95652174 0.94202899 0.95588235\n",
            " 0.95588235 0.95588235 0.97058824 1.         0.98529412 0.97058824\n",
            " 0.98550725 0.94202899 0.97101449 0.98529412 0.95588235 1.\n",
            " 0.97058824 0.92647059 0.97058824 0.94117647]\n",
            "Accuracy: 96.65% (2.09%)\n",
            "------------------------------\n",
            "--------- CatBoost on Breast Cancer Dataset ---------\n",
            "[0.94202899 0.97101449 0.98550725 0.95588235 0.97058824 1.\n",
            " 0.97058824 0.97058824 0.97058824 0.98529412 0.98550725 0.97101449\n",
            " 0.97101449 0.97058824 0.97058824 0.95588235 1.         0.95588235\n",
            " 1.         0.95588235 1.         0.94202899 0.95652174 0.97058824\n",
            " 0.95588235 1.         0.95588235 0.98529412 0.97058824 0.98529412\n",
            " 0.97101449 0.95652174 0.98550725 0.98529412 0.98529412 1.\n",
            " 0.98529412 0.97058824 0.94117647 0.97058824 0.97101449 0.98550725\n",
            " 1.         1.         0.98529412 0.95588235 0.98529412 0.97058824\n",
            " 0.94117647 0.95588235 1.         0.95652174 1.         0.98529412\n",
            " 0.94117647 0.98529412 0.95588235 0.97058824 0.97058824 0.98529412\n",
            " 0.95652174 0.98550725 0.98550725 0.92647059 0.98529412 1.\n",
            " 0.94117647 0.97058824 0.98529412 0.98529412 1.         1.\n",
            " 0.97101449 0.95588235 0.98529412 0.97058824 0.97058824 0.95588235\n",
            " 0.95588235 0.95588235 0.98550725 0.98550725 0.94202899 0.97058824\n",
            " 0.98529412 0.97058824 0.97058824 1.         0.98529412 0.98529412\n",
            " 0.98550725 0.95652174 0.97101449 1.         0.97058824 1.\n",
            " 0.97058824 0.97058824 0.97058824 0.92647059]\n",
            "Accuracy: 97.38% (1.80%)\n",
            "------------------------------\n",
            "--------- LightGBM on Breast Cancer Dataset ---------\n",
            "[0.97101449 0.97101449 0.95652174 0.95588235 0.97058824 1.\n",
            " 0.95588235 0.97058824 0.98529412 0.98529412 0.98550725 0.97101449\n",
            " 0.98550725 0.98529412 0.97058824 0.92647059 1.         0.95588235\n",
            " 1.         0.95588235 1.         0.94202899 0.95652174 0.97058824\n",
            " 0.95588235 1.         0.97058824 0.98529412 0.97058824 0.97058824\n",
            " 0.97101449 0.95652174 0.97101449 0.97058824 0.98529412 0.97058824\n",
            " 0.98529412 1.         0.94117647 0.97058824 0.95652174 1.\n",
            " 0.98550725 0.98529412 0.98529412 0.95588235 0.98529412 0.97058824\n",
            " 0.95588235 0.95588235 1.         0.91304348 1.         0.98529412\n",
            " 0.89705882 0.97058824 0.97058824 0.98529412 1.         0.98529412\n",
            " 0.95652174 1.         0.98550725 0.92647059 0.98529412 1.\n",
            " 0.94117647 0.97058824 0.98529412 0.95588235 1.         1.\n",
            " 0.97101449 0.95588235 0.98529412 0.94117647 0.97058824 0.98529412\n",
            " 0.98529412 0.97058824 0.94202899 0.98550725 0.95652174 0.98529412\n",
            " 0.98529412 0.97058824 0.98529412 1.         0.98529412 0.97058824\n",
            " 1.         0.97101449 0.98550725 0.98529412 0.97058824 0.98529412\n",
            " 0.94117647 1.         0.97058824 0.94117647]\n",
            "Accuracy: 97.33% (2.05%)\n",
            "------------------------------\n",
            "--------- XGBoost on Breast Cancer Dataset ---------\n",
            "[0.95652174 0.98550725 0.98550725 0.95588235 0.95588235 0.98529412\n",
            " 0.95588235 0.97058824 0.95588235 0.97058824 0.98550725 0.97101449\n",
            " 0.95652174 0.97058824 0.97058824 0.95588235 1.         0.94117647\n",
            " 0.95588235 0.97058824 1.         0.92753623 0.95652174 0.95588235\n",
            " 0.95588235 1.         0.97058824 0.97058824 0.97058824 0.97058824\n",
            " 0.95652174 0.97101449 0.97101449 0.97058824 0.97058824 1.\n",
            " 0.98529412 1.         0.91176471 0.95588235 0.97101449 0.98550725\n",
            " 0.97101449 1.         0.97058824 0.92647059 0.98529412 0.97058824\n",
            " 0.94117647 0.94117647 1.         0.92753623 0.97101449 0.97058824\n",
            " 0.92647059 0.98529412 0.95588235 0.97058824 1.         0.97058824\n",
            " 0.95652174 0.98550725 0.97101449 0.94117647 0.97058824 1.\n",
            " 0.92647059 0.97058824 0.97058824 0.98529412 1.         0.98550725\n",
            " 0.95652174 0.92647059 0.98529412 0.95588235 0.95588235 0.97058824\n",
            " 0.98529412 0.95588235 0.95652174 0.97101449 0.94202899 0.95588235\n",
            " 0.97058824 0.97058824 0.98529412 0.98529412 0.98529412 0.97058824\n",
            " 1.         0.94202899 0.98550725 0.98529412 0.95588235 1.\n",
            " 0.97058824 0.95588235 0.95588235 0.92647059]\n",
            "Accuracy: 96.79% (2.02%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "breast_cancer_scores = []\n",
        "breast_cancer_mean = []\n",
        "breast_cancer_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    breast_cancer_scores.append(results)\n",
        "    breast_cancer_mean.append(results.mean()*100)\n",
        "    breast_cancer_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Breast Cancer Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Breast Cancer scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(breast_cancer_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Breast_Cancer'] = breast_cancer_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer\n",
              "0   AdaBoost  96.552288      97.159847\n",
              "1  GradBoost  98.075163      96.646633\n",
              "2   CatBoost  97.967320      97.378303\n",
              "3   LightGBM  97.120915      97.334612\n",
              "4    XGBoost  97.797386      96.792626"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Sonar Dataset** #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "sonar_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Sonar\\Sonar.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = sonar_df.iloc[:, :-1]\n",
        "y = sonar_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [02:46<00:00,  3.34s/trial, best loss: -0.9523809523809523]\n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 1250.0, 'learning_rate': 0.011066661922600281, 'max_depth': 2.0, 'max_features': None, 'min_samples_leaf': 5.0, 'min_samples_split': 6.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:55<00:00,  1.12s/trial, best loss: -0.8571428571428571]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.04102652661864284, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 7, 'min_weight_fraction_leaf': 0.0, 'min_impurity_decrease': 1.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [05:28<00:00,  6.57s/trial, best loss: -0.8809523809523809]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 1300, 'learning_rate': 0.014023863721779927, 'min_child_samples': 9, 'max_depth': 7, 'reg_lambda': 0.2645130637158699, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 40.87trial/s, best loss: -0.7857142857142857]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'gbdt', 'num_leaves': 80, 'learning_rate': 0.088633625625231, 'min_child_samples': 60, 'reg_alpha': 0.20114179877735983, 'reg_lambda': 0.021920717955273894, 'colsample_by_tree': 0.9439502913709372, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:10<00:00,  4.68trial/s, best loss: -0.8571428571428571]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'dart', 'learning_rate': 0.044025607478991216, 'gamma': 2, 'max_depth': 5, 'min_child_weight': 1, 'colsample_bytree': 0.3050569452640979, 'colsample_bylevel': 0.914172295823844, 'colsample_bynode': 0.2986672398458319, 'reg_alpha': 0.7657116989618611, 'reg_lambda': 0.8092636688928795, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 1250.0,\n",
              " 'learning_rate': 0.011066661922600281,\n",
              " 'max_depth': 2.0,\n",
              " 'max_features': None,\n",
              " 'min_samples_leaf': 5.0,\n",
              " 'min_samples_split': 6.0,\n",
              " 'random_state': 42}"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams['AdaBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['GradBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['CatBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['LightGBM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparams['XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Sonar Dataset ---------\n",
            "[0.95238095 0.80952381 0.85714286 0.95238095 0.80952381 1.\n",
            " 0.9047619  0.85714286 0.85       1.         0.9047619  0.9047619\n",
            " 0.95238095 0.9047619  0.80952381 0.9047619  0.9047619  0.9047619\n",
            " 0.85       0.75       0.76190476 0.80952381 1.         0.9047619\n",
            " 0.80952381 0.9047619  0.85714286 0.76190476 0.85       0.9\n",
            " 0.95238095 0.85714286 0.9047619  0.71428571 0.85714286 0.80952381\n",
            " 0.80952381 0.9047619  0.85       0.8        0.9047619  0.76190476\n",
            " 0.9047619  0.71428571 0.76190476 0.85714286 0.80952381 0.71428571\n",
            " 0.9        0.95       0.9047619  0.85714286 0.85714286 0.85714286\n",
            " 0.80952381 0.9047619  0.95238095 0.9047619  0.9        0.8\n",
            " 0.66666667 0.85714286 0.9047619  0.9047619  0.76190476 0.9047619\n",
            " 0.80952381 0.9047619  0.65       1.         0.85714286 0.9047619\n",
            " 0.80952381 0.9047619  0.95238095 0.76190476 0.9047619  0.85714286\n",
            " 0.85       0.9        0.76190476 0.76190476 0.76190476 1.\n",
            " 0.95238095 0.95238095 0.9047619  0.9047619  0.9        0.9\n",
            " 0.9047619  0.9047619  0.80952381 0.85714286 0.9047619  0.9047619\n",
            " 0.76190476 0.9047619  0.9        0.8       ]\n",
            "Accuracy: 86.35% (7.35%)\n",
            "------------------------------\n",
            "--------- GradBoost on Sonar Dataset ---------\n",
            "[0.80952381 0.66666667 0.71428571 0.95238095 0.57142857 0.9047619\n",
            " 0.71428571 0.80952381 0.75       0.95       0.71428571 0.71428571\n",
            " 0.80952381 0.95238095 0.85714286 0.76190476 0.85714286 0.76190476\n",
            " 0.9        0.6        0.76190476 0.61904762 0.9047619  0.85714286\n",
            " 0.71428571 0.71428571 0.85714286 0.80952381 0.7        0.8\n",
            " 0.85714286 0.9047619  0.66666667 0.66666667 0.66666667 0.80952381\n",
            " 0.71428571 0.80952381 0.75       0.8        0.9047619  0.76190476\n",
            " 0.85714286 0.66666667 0.61904762 0.76190476 0.76190476 0.61904762\n",
            " 0.9        0.9        0.76190476 0.71428571 0.76190476 0.61904762\n",
            " 0.71428571 0.76190476 0.9047619  0.85714286 0.95       0.75\n",
            " 0.71428571 0.66666667 0.9047619  0.80952381 0.85714286 0.71428571\n",
            " 0.85714286 0.80952381 0.65       0.75       0.9047619  0.85714286\n",
            " 0.76190476 0.76190476 0.85714286 0.71428571 0.76190476 0.76190476\n",
            " 0.8        0.85       0.80952381 0.57142857 0.71428571 0.76190476\n",
            " 0.76190476 0.85714286 0.80952381 0.80952381 0.85       0.85\n",
            " 0.80952381 0.71428571 0.76190476 0.80952381 0.76190476 0.80952381\n",
            " 0.85714286 0.80952381 0.7        0.85      ]\n",
            "Accuracy: 78.15% (8.83%)\n",
            "------------------------------\n",
            "--------- CatBoost on Sonar Dataset ---------\n",
            "[0.95238095 0.76190476 0.85714286 1.         0.71428571 0.95238095\n",
            " 0.9047619  0.85714286 0.85       0.95       0.76190476 0.9047619\n",
            " 0.95238095 0.95238095 0.85714286 0.9047619  0.85714286 0.76190476\n",
            " 0.95       0.75       0.9047619  0.71428571 1.         0.95238095\n",
            " 0.76190476 0.80952381 0.85714286 0.9047619  0.95       0.9\n",
            " 0.95238095 0.95238095 0.85714286 0.76190476 0.85714286 0.80952381\n",
            " 0.9047619  0.9047619  0.85       0.85       0.9047619  0.76190476\n",
            " 0.95238095 0.76190476 0.9047619  0.80952381 0.85714286 0.9047619\n",
            " 0.9        0.9        0.95238095 0.85714286 0.80952381 0.85714286\n",
            " 0.71428571 0.9047619  0.9047619  0.95238095 0.9        0.85\n",
            " 0.85714286 0.80952381 0.9047619  0.85714286 0.80952381 0.95238095\n",
            " 0.95238095 0.9047619  0.65       0.9        0.85714286 0.95238095\n",
            " 0.85714286 0.95238095 0.9047619  0.71428571 0.85714286 0.80952381\n",
            " 0.85       0.9        0.85714286 0.76190476 0.71428571 0.9047619\n",
            " 0.85714286 0.9047619  0.95238095 0.95238095 0.95       0.9\n",
            " 0.9047619  0.80952381 0.71428571 0.85714286 1.         0.9047619\n",
            " 0.85714286 0.9047619  0.85       1.        ]\n",
            "Accuracy: 87.08% (7.54%)\n",
            "------------------------------\n",
            "--------- LightGBM on Sonar Dataset ---------\n",
            "[0.85714286 0.66666667 0.66666667 0.85714286 0.71428571 0.85714286\n",
            " 0.95238095 0.80952381 0.9        0.95       0.66666667 0.76190476\n",
            " 0.85714286 0.80952381 0.80952381 0.9047619  0.76190476 0.85714286\n",
            " 0.9        0.75       0.85714286 0.80952381 0.95238095 0.80952381\n",
            " 0.80952381 0.80952381 0.85714286 0.9047619  0.75       0.7\n",
            " 1.         0.9047619  0.80952381 0.71428571 0.71428571 0.85714286\n",
            " 0.80952381 0.76190476 0.8        0.9        0.9047619  0.80952381\n",
            " 0.9047619  0.66666667 0.76190476 0.80952381 0.9047619  0.71428571\n",
            " 0.85       0.85       0.95238095 0.71428571 0.80952381 0.80952381\n",
            " 0.76190476 0.80952381 0.85714286 0.95238095 0.9        0.9\n",
            " 0.85714286 0.85714286 0.85714286 0.9047619  0.85714286 0.80952381\n",
            " 0.80952381 0.80952381 0.65       0.75       0.9047619  0.76190476\n",
            " 0.80952381 0.80952381 0.9047619  0.85714286 0.76190476 0.80952381\n",
            " 0.75       0.75       0.85714286 0.61904762 0.71428571 0.85714286\n",
            " 0.80952381 0.85714286 0.85714286 0.95238095 0.95       0.85\n",
            " 0.80952381 0.76190476 0.66666667 0.85714286 0.85714286 0.9047619\n",
            " 0.80952381 0.85714286 0.8        0.95      ]\n",
            "Accuracy: 82.36% (7.92%)\n",
            "------------------------------\n",
            "--------- XGBoost on Sonar Dataset ---------\n",
            "[0.9047619  0.80952381 0.76190476 0.95238095 0.71428571 0.95238095\n",
            " 0.80952381 0.85714286 0.8        0.95       0.71428571 0.71428571\n",
            " 0.95238095 0.95238095 0.95238095 0.85714286 0.80952381 0.76190476\n",
            " 0.95       0.7        0.85714286 0.61904762 0.95238095 0.9047619\n",
            " 0.80952381 0.80952381 0.85714286 0.9047619  0.85       0.9\n",
            " 0.95238095 0.9047619  0.85714286 0.80952381 0.80952381 0.85714286\n",
            " 0.71428571 0.76190476 0.8        0.75       0.9047619  0.80952381\n",
            " 0.85714286 0.76190476 0.66666667 0.85714286 0.76190476 0.76190476\n",
            " 0.85       0.9        0.95238095 0.71428571 0.80952381 0.71428571\n",
            " 0.71428571 0.9047619  0.85714286 0.9047619  0.9        0.8\n",
            " 0.76190476 0.76190476 0.9047619  0.9047619  0.9047619  0.85714286\n",
            " 0.95238095 0.85714286 0.65       0.85       0.9047619  0.95238095\n",
            " 0.80952381 0.85714286 0.85714286 0.76190476 0.80952381 0.85714286\n",
            " 0.8        0.85       0.9047619  0.66666667 0.76190476 0.80952381\n",
            " 0.80952381 0.9047619  0.85714286 0.95238095 0.95       0.85\n",
            " 0.85714286 0.80952381 0.66666667 0.80952381 1.         0.85714286\n",
            " 0.9047619  0.85714286 0.8        0.95      ]\n",
            "Accuracy: 83.80% (8.27%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "sonar_scores = []\n",
        "sonar_mean = []\n",
        "sonar_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    sonar_scores.append(results)\n",
        "    sonar_mean.append(results.mean()*100)\n",
        "    sonar_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Sonar Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Sonar scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(sonar_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Sonar'] = sonar_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <th>Sonar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "      <td>86.347619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>78.145238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>87.076190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>82.361905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "      <td>83.802381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer      Sonar\n",
              "0   AdaBoost  96.552288      97.159847  86.347619\n",
              "1  GradBoost  98.075163      96.646633  78.145238\n",
              "2   CatBoost  97.967320      97.378303  87.076190\n",
              "3   LightGBM  97.120915      97.334612  82.361905\n",
              "4    XGBoost  97.797386      96.792626  83.802381"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Ionosphere Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "ionosphere_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Ionosphere\\ionosphere.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(351, 35)"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ionosphere_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = ionosphere_df.iloc[:, :-1]\n",
        "y = ionosphere_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:28<00:00,  1.77s/trial, best loss: -0.971830985915493] \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 50.0, 'learning_rate': 0.046035205781861564, 'max_depth': 6.0, 'max_features': 'log2', 'min_samples_leaf': 5.0, 'min_samples_split': 2.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:55<00:00,  1.11s/trial, best loss: -0.9295774647887324]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 400, 'learning_rate': 0.021178191623985942, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 2.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [07:12<00:00,  8.65s/trial, best loss: -0.9577464788732394]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 750, 'learning_rate': 0.02983152512960275, 'min_child_samples': 3, 'max_depth': 5, 'reg_lambda': 3.8771604915102147, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 38.66trial/s, best loss: -0.9436619718309859]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'gbdt', 'num_leaves': 75, 'learning_rate': 0.09085691661731564, 'min_child_samples': 20, 'reg_alpha': 0.8776705363565946, 'reg_lambda': 2.021006183231964, 'colsample_by_tree': 0.5358470999804816, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:08<00:00,  5.91trial/s, best loss: -0.9436619718309859]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'gbtree', 'learning_rate': 0.011777426690454684, 'gamma': 2, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.6642423404208758, 'colsample_bylevel': 0.8389604376670141, 'colsample_bynode': 0.46801910869053165, 'reg_alpha': 1.3842922617481603, 'reg_lambda': 0.25127542856871243, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Ionosphere Dataset ---------\n",
            "[1.         0.91428571 0.91428571 0.94285714 0.97142857 0.91428571\n",
            " 0.94285714 0.97142857 0.97142857 0.88571429 0.97222222 0.94285714\n",
            " 0.97142857 0.97142857 1.         0.94285714 0.91428571 0.88571429\n",
            " 0.91428571 0.88571429 0.86111111 0.85714286 0.97142857 0.94285714\n",
            " 0.97142857 0.94285714 1.         0.94285714 0.88571429 1.\n",
            " 0.91666667 0.97142857 0.94285714 1.         0.91428571 0.91428571\n",
            " 0.85714286 0.91428571 0.94285714 0.88571429 0.97222222 1.\n",
            " 0.91428571 0.91428571 0.97142857 0.82857143 1.         0.97142857\n",
            " 0.91428571 0.85714286 0.94444444 0.97142857 0.91428571 1.\n",
            " 0.94285714 0.97142857 0.97142857 0.91428571 0.91428571 0.88571429\n",
            " 0.97222222 0.91428571 0.91428571 0.94285714 0.97142857 0.91428571\n",
            " 1.         0.88571429 1.         0.94285714 0.97222222 0.88571429\n",
            " 0.91428571 0.94285714 0.88571429 0.88571429 1.         0.91428571\n",
            " 0.97142857 1.         0.91666667 0.94285714 0.94285714 0.97142857\n",
            " 0.8        1.         0.91428571 1.         0.91428571 0.91428571\n",
            " 0.91666667 0.88571429 1.         0.88571429 0.94285714 0.94285714\n",
            " 0.94285714 1.         0.94285714 0.97142857]\n",
            "Accuracy: 93.82% (4.34%)\n",
            "------------------------------\n",
            "--------- GradBoost on Ionosphere Dataset ---------\n",
            "[0.94444444 0.97142857 0.94285714 0.85714286 0.91428571 0.85714286\n",
            " 0.88571429 0.91428571 0.82857143 0.91428571 0.83333333 0.88571429\n",
            " 0.91428571 0.94285714 0.91428571 0.94285714 0.94285714 0.94285714\n",
            " 0.85714286 0.91428571 0.80555556 0.8        1.         0.97142857\n",
            " 1.         0.85714286 0.91428571 0.88571429 0.94285714 0.97142857\n",
            " 1.         1.         1.         0.97142857 0.85714286 0.94285714\n",
            " 0.82857143 0.94285714 0.82857143 0.77142857 0.94444444 0.97142857\n",
            " 0.91428571 0.94285714 0.97142857 0.82857143 0.85714286 0.88571429\n",
            " 0.91428571 0.88571429 0.97222222 0.94285714 0.97142857 0.91428571\n",
            " 0.85714286 0.91428571 0.94285714 0.82857143 0.91428571 0.82857143\n",
            " 0.88888889 0.97142857 0.88571429 0.82857143 0.94285714 0.85714286\n",
            " 0.85714286 0.94285714 0.94285714 0.91428571 0.88888889 0.85714286\n",
            " 0.91428571 0.77142857 0.88571429 0.94285714 1.         0.94285714\n",
            " 0.88571429 0.88571429 0.91666667 0.88571429 0.88571429 0.97142857\n",
            " 0.85714286 1.         0.88571429 0.94285714 0.91428571 0.94285714\n",
            " 0.88888889 0.91428571 1.         0.91428571 0.85714286 0.91428571\n",
            " 0.82857143 0.91428571 0.85714286 0.94285714]\n",
            "Accuracy: 90.85% (5.39%)\n",
            "------------------------------\n",
            "--------- CatBoost on Ionosphere Dataset ---------\n",
            "[0.91666667 0.91428571 0.97142857 0.94285714 0.97142857 0.88571429\n",
            " 0.91428571 1.         0.97142857 0.91428571 0.94444444 0.97142857\n",
            " 1.         0.97142857 0.85714286 0.91428571 0.97142857 0.91428571\n",
            " 0.88571429 0.91428571 0.94444444 0.85714286 0.97142857 0.94285714\n",
            " 0.97142857 0.91428571 0.94285714 0.91428571 0.94285714 0.97142857\n",
            " 1.         1.         1.         1.         0.88571429 0.91428571\n",
            " 0.82857143 0.97142857 0.88571429 0.85714286 0.94444444 1.\n",
            " 1.         0.94285714 0.94285714 0.82857143 0.97142857 1.\n",
            " 0.91428571 0.88571429 0.94444444 0.97142857 0.94285714 0.94285714\n",
            " 0.94285714 0.97142857 0.97142857 0.88571429 0.88571429 0.85714286\n",
            " 0.94444444 0.97142857 0.91428571 0.88571429 0.94285714 0.85714286\n",
            " 0.91428571 0.94285714 1.         1.         0.97222222 0.88571429\n",
            " 0.91428571 0.88571429 0.94285714 0.91428571 0.97142857 0.91428571\n",
            " 0.97142857 0.97142857 0.91666667 0.94285714 0.97142857 0.97142857\n",
            " 0.88571429 1.         0.94285714 0.97142857 0.94285714 0.88571429\n",
            " 0.94444444 0.94285714 1.         0.91428571 0.97142857 0.91428571\n",
            " 0.91428571 0.94285714 0.94285714 0.97142857]\n",
            "Accuracy: 93.82% (4.22%)\n",
            "------------------------------\n",
            "--------- LightGBM on Ionosphere Dataset ---------\n",
            "[0.94444444 0.91428571 0.94285714 0.91428571 0.94285714 0.88571429\n",
            " 0.94285714 0.97142857 0.88571429 0.88571429 0.91666667 0.94285714\n",
            " 0.94285714 0.97142857 0.85714286 0.91428571 0.97142857 0.94285714\n",
            " 0.88571429 0.97142857 0.86111111 0.8        0.97142857 0.97142857\n",
            " 0.97142857 0.94285714 0.94285714 0.91428571 0.94285714 0.97142857\n",
            " 1.         1.         1.         0.97142857 0.91428571 0.91428571\n",
            " 0.82857143 0.94285714 0.94285714 0.82857143 0.94444444 0.97142857\n",
            " 0.97142857 0.94285714 0.97142857 0.82857143 0.91428571 0.97142857\n",
            " 0.94285714 0.85714286 0.94444444 0.94285714 0.94285714 0.94285714\n",
            " 0.88571429 0.97142857 0.97142857 0.85714286 0.88571429 0.88571429\n",
            " 0.88888889 0.94285714 0.91428571 0.88571429 0.94285714 0.85714286\n",
            " 0.85714286 0.91428571 1.         1.         0.97222222 0.94285714\n",
            " 0.88571429 0.82857143 0.94285714 0.88571429 0.97142857 0.94285714\n",
            " 0.94285714 0.97142857 0.88888889 0.88571429 0.97142857 0.97142857\n",
            " 0.85714286 1.         0.88571429 0.97142857 0.91428571 0.94285714\n",
            " 0.91666667 0.94285714 1.         0.91428571 0.91428571 0.91428571\n",
            " 0.91428571 0.97142857 0.88571429 0.97142857]\n",
            "Accuracy: 92.85% (4.53%)\n",
            "------------------------------\n",
            "--------- XGBoost on Ionosphere Dataset ---------\n",
            "[0.91666667 0.91428571 0.97142857 0.94285714 0.94285714 0.88571429\n",
            " 0.88571429 1.         0.85714286 0.88571429 0.94444444 0.94285714\n",
            " 1.         0.97142857 0.88571429 0.91428571 0.97142857 0.94285714\n",
            " 0.88571429 0.88571429 0.91666667 0.85714286 1.         0.94285714\n",
            " 0.97142857 0.91428571 0.94285714 0.91428571 0.94285714 0.97142857\n",
            " 1.         1.         0.97142857 1.         0.88571429 0.94285714\n",
            " 0.82857143 0.97142857 0.85714286 0.82857143 0.91666667 0.97142857\n",
            " 1.         0.94285714 0.94285714 0.82857143 0.91428571 0.94285714\n",
            " 0.91428571 0.88571429 0.94444444 0.94285714 0.94285714 0.94285714\n",
            " 0.91428571 0.97142857 0.97142857 0.88571429 0.88571429 0.88571429\n",
            " 0.94444444 0.97142857 0.85714286 0.88571429 0.94285714 0.85714286\n",
            " 0.91428571 0.94285714 1.         0.97142857 0.91666667 0.88571429\n",
            " 0.94285714 0.82857143 0.94285714 0.94285714 0.97142857 0.94285714\n",
            " 0.94285714 1.         0.94444444 0.91428571 0.94285714 0.97142857\n",
            " 0.85714286 1.         0.91428571 0.94285714 0.91428571 0.88571429\n",
            " 0.94444444 0.91428571 1.         0.91428571 0.94285714 0.94285714\n",
            " 0.85714286 0.94285714 0.88571429 0.97142857]\n",
            "Accuracy: 92.96% (4.43%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "ionosphere_scores = []\n",
        "ionosphere_mean = []\n",
        "ionosphere_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    ionosphere_scores.append(results)\n",
        "    ionosphere_mean.append(results.mean()*100)\n",
        "    ionosphere_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Ionosphere Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Ionosphere scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(ionosphere_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Ionosphere'] = ionosphere_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <th>Sonar</th>\n",
              "      <th>Ionosphere</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "      <td>86.347619</td>\n",
              "      <td>93.815873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>90.854762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>93.815079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>92.849206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "      <td>83.802381</td>\n",
              "      <td>92.960317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer      Sonar  Ionosphere\n",
              "0   AdaBoost  96.552288      97.159847  86.347619   93.815873\n",
              "1  GradBoost  98.075163      96.646633  78.145238   90.854762\n",
              "2   CatBoost  97.967320      97.378303  87.076190   93.815079\n",
              "3   LightGBM  97.120915      97.334612  82.361905   92.849206\n",
              "4    XGBoost  97.797386      96.792626  83.802381   92.960317"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Tic-Tac-Toe Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "tictactoe_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\TicTacToe\\TicTacToe.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummies = {\n",
        "            'x': 0,\n",
        "            'o': 1,\n",
        "            'b': 2,\n",
        "          }\n",
        "tictactoe_df = tictactoe_df.iloc[:, 0: 9].replace(dummies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = tictactoe_df.iloc[:, :-1]\n",
        "y = tictactoe_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:01<01:32,  1.89s/trial, best loss: -0.4895833333333333]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:10<00:00,  1.42s/trial, best loss: -0.8125]            \n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 1200.0, 'learning_rate': 0.06916005440000361, 'max_depth': 2.0, 'max_features': None, 'min_samples_leaf': 4.0, 'min_samples_split': 4.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [01:13<00:00,  1.47s/trial, best loss: -0.8177083333333334]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 850, 'learning_rate': 0.09835742587463962, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:35<00:00,  1.40trial/s, best loss: -0.71875]           \n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 1350, 'learning_rate': 0.052871577465477125, 'min_child_samples': 9, 'max_depth': 1, 'reg_lambda': 3.1381917920726017, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:03<00:00, 15.70trial/s, best loss: -0.6197916666666666]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'gbdt', 'num_leaves': 85, 'learning_rate': 0.08722980007927972, 'min_child_samples': 50, 'reg_alpha': 1.2108510802433148, 'reg_lambda': 0.47150609574550806, 'colsample_by_tree': 0.6838724853092855, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:12<00:00,  3.86trial/s, best loss: -0.6458333333333334]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'gbtree', 'learning_rate': 0.0842954898912899, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.8901045127889909, 'colsample_bylevel': 0.3718676252172074, 'colsample_bynode': 0.8158357971054165, 'reg_alpha': 1.8194669780226551, 'reg_lambda': 2.2864326222504214, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on TicTacToe Dataset ---------\n",
            "[0.875      0.88541667 0.77083333 0.82291667 0.875      0.73958333\n",
            " 0.84375    0.79166667 0.84210526 0.78947368 0.79166667 0.8125\n",
            " 0.76041667 0.84375    0.78125    0.8125     0.8125     0.85416667\n",
            " 0.78947368 0.82105263 0.83333333 0.78125    0.75       0.85416667\n",
            " 0.90625    0.80208333 0.89583333 0.79166667 0.83157895 0.8\n",
            " 0.80208333 0.84375    0.85416667 0.84375    0.76041667 0.77083333\n",
            " 0.79166667 0.77083333 0.87368421 0.77894737 0.80208333 0.79166667\n",
            " 0.76041667 0.73958333 0.75       0.78125    0.875      0.83333333\n",
            " 0.83157895 0.86315789 0.80208333 0.80208333 0.80208333 0.80208333\n",
            " 0.8125     0.80208333 0.82291667 0.82291667 0.78947368 0.81052632\n",
            " 0.85416667 0.80208333 0.83333333 0.75       0.80208333 0.88541667\n",
            " 0.77083333 0.78125    0.78947368 0.78947368 0.80208333 0.80208333\n",
            " 0.73958333 0.79166667 0.85416667 0.84375    0.84375    0.75\n",
            " 0.8        0.85263158 0.72916667 0.84375    0.79166667 0.84375\n",
            " 0.8125     0.92708333 0.82291667 0.78125    0.72631579 0.81052632\n",
            " 0.8125     0.70833333 0.80208333 0.86458333 0.83333333 0.86458333\n",
            " 0.75       0.83333333 0.8        0.81052632]\n",
            "Accuracy: 81.05% (4.18%)\n",
            "------------------------------\n",
            "--------- GradBoost on TicTacToe Dataset ---------\n",
            "[0.875      0.83333333 0.79166667 0.82291667 0.8125     0.77083333\n",
            " 0.89583333 0.79166667 0.78947368 0.78947368 0.8125     0.79166667\n",
            " 0.80208333 0.84375    0.82291667 0.83333333 0.82291667 0.84375\n",
            " 0.83157895 0.84210526 0.86458333 0.82291667 0.78125    0.8125\n",
            " 0.875      0.79166667 0.88541667 0.78125    0.84210526 0.84210526\n",
            " 0.84375    0.84375    0.82291667 0.85416667 0.79166667 0.875\n",
            " 0.8125     0.77083333 0.86315789 0.85263158 0.85416667 0.83333333\n",
            " 0.82291667 0.79166667 0.78125    0.77083333 0.86458333 0.82291667\n",
            " 0.84210526 0.87368421 0.84375    0.80208333 0.83333333 0.79166667\n",
            " 0.80208333 0.79166667 0.8125     0.8125     0.78947368 0.86315789\n",
            " 0.8125     0.83333333 0.83333333 0.79166667 0.76041667 0.83333333\n",
            " 0.76041667 0.85416667 0.77894737 0.81052632 0.8125     0.80208333\n",
            " 0.83333333 0.83333333 0.86458333 0.82291667 0.84375    0.76041667\n",
            " 0.83157895 0.82105263 0.76041667 0.84375    0.83333333 0.80208333\n",
            " 0.8125     0.86458333 0.85416667 0.83333333 0.8        0.81052632\n",
            " 0.85416667 0.79166667 0.84375    0.86458333 0.84375    0.80208333\n",
            " 0.78125    0.83333333 0.83157895 0.82105263]\n",
            "Accuracy: 82.22% (3.08%)\n",
            "------------------------------\n",
            "--------- CatBoost on TicTacToe Dataset ---------\n",
            "[0.77083333 0.73958333 0.71875    0.71875    0.69791667 0.72916667\n",
            " 0.72916667 0.71875    0.69473684 0.72631579 0.75       0.73958333\n",
            " 0.71875    0.6875     0.71875    0.72916667 0.66666667 0.73958333\n",
            " 0.75789474 0.71578947 0.77083333 0.70833333 0.67708333 0.71875\n",
            " 0.71875    0.71875    0.71875    0.6875     0.74736842 0.72631579\n",
            " 0.78125    0.72916667 0.75       0.72916667 0.6875     0.72916667\n",
            " 0.69791667 0.70833333 0.75789474 0.70526316 0.6875     0.71875\n",
            " 0.75       0.73958333 0.6875     0.72916667 0.71875    0.72916667\n",
            " 0.72631579 0.74736842 0.72916667 0.75       0.67708333 0.75\n",
            " 0.73958333 0.67708333 0.70833333 0.75       0.74736842 0.72631579\n",
            " 0.71875    0.69791667 0.76041667 0.73958333 0.70833333 0.72916667\n",
            " 0.70833333 0.6875     0.72631579 0.72631579 0.73958333 0.71875\n",
            " 0.70833333 0.72916667 0.67708333 0.72916667 0.71875    0.77083333\n",
            " 0.72631579 0.73684211 0.69791667 0.72916667 0.70833333 0.73958333\n",
            " 0.69791667 0.73958333 0.72916667 0.73958333 0.71578947 0.69473684\n",
            " 0.69791667 0.69791667 0.75       0.69791667 0.73958333 0.70833333\n",
            " 0.73958333 0.76041667 0.70526316 0.74736842]\n",
            "Accuracy: 72.32% (2.36%)\n",
            "------------------------------\n",
            "--------- LightGBM on TicTacToe Dataset ---------\n",
            "[0.72916667 0.70833333 0.65625    0.57291667 0.67708333 0.52083333\n",
            " 0.64583333 0.64583333 0.61052632 0.61052632 0.58333333 0.61458333\n",
            " 0.59375    0.63541667 0.57291667 0.6875     0.57291667 0.60416667\n",
            " 0.62105263 0.63157895 0.6875     0.60416667 0.55208333 0.66666667\n",
            " 0.61458333 0.57291667 0.72916667 0.57291667 0.68421053 0.56842105\n",
            " 0.63541667 0.59375    0.64583333 0.625      0.61458333 0.61458333\n",
            " 0.54166667 0.60416667 0.6        0.57894737 0.61458333 0.625\n",
            " 0.63541667 0.61458333 0.67708333 0.53125    0.65625    0.60416667\n",
            " 0.64210526 0.66315789 0.67708333 0.64583333 0.63541667 0.61458333\n",
            " 0.61458333 0.60416667 0.65625    0.61458333 0.61052632 0.6\n",
            " 0.61458333 0.61458333 0.63541667 0.63541667 0.57291667 0.73958333\n",
            " 0.51041667 0.52083333 0.63157895 0.65263158 0.63541667 0.59375\n",
            " 0.58333333 0.61458333 0.63541667 0.65625    0.58333333 0.57291667\n",
            " 0.56842105 0.58947368 0.5625     0.63541667 0.55208333 0.65625\n",
            " 0.63541667 0.6875     0.64583333 0.58333333 0.55789474 0.57894737\n",
            " 0.61458333 0.60416667 0.66666667 0.60416667 0.66666667 0.61458333\n",
            " 0.59375    0.66666667 0.55789474 0.63157895]\n",
            "Accuracy: 61.81% (4.48%)\n",
            "------------------------------\n",
            "--------- XGBoost on TicTacToe Dataset ---------\n",
            "[0.70833333 0.64583333 0.67708333 0.58333333 0.67708333 0.63541667\n",
            " 0.66666667 0.61458333 0.64210526 0.65263158 0.72916667 0.67708333\n",
            " 0.5625     0.65625    0.63541667 0.6875     0.67708333 0.625\n",
            " 0.66315789 0.66315789 0.72916667 0.65625    0.61458333 0.64583333\n",
            " 0.6875     0.625      0.65625    0.65625    0.68421053 0.64210526\n",
            " 0.73958333 0.67708333 0.69791667 0.625      0.64583333 0.61458333\n",
            " 0.625      0.64583333 0.69473684 0.69473684 0.65625    0.60416667\n",
            " 0.70833333 0.63541667 0.66666667 0.625      0.66666667 0.67708333\n",
            " 0.69473684 0.70526316 0.625      0.67708333 0.63541667 0.6875\n",
            " 0.59375    0.63541667 0.65625    0.6875     0.64210526 0.68421053\n",
            " 0.63541667 0.64583333 0.70833333 0.64583333 0.64583333 0.6875\n",
            " 0.65625    0.61458333 0.61052632 0.68421053 0.70833333 0.63541667\n",
            " 0.625      0.69791667 0.61458333 0.6875     0.61458333 0.71875\n",
            " 0.64210526 0.69473684 0.59375    0.65625    0.63541667 0.65625\n",
            " 0.67708333 0.69791667 0.65625    0.66666667 0.63157895 0.62105263\n",
            " 0.65625    0.64583333 0.69791667 0.60416667 0.70833333 0.63541667\n",
            " 0.66666667 0.66666667 0.64210526 0.63157895]\n",
            "Accuracy: 65.72% (3.43%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "tictactoe_scores = []\n",
        "tictactoe_mean = []\n",
        "tictactoe_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    tictactoe_scores.append(results)\n",
        "    tictactoe_mean.append(results.mean()*100)\n",
        "    tictactoe_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on TicTacToe Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different TicTacToe scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(tictactoe_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['TicTacToe'] = tictactoe_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <th>Sonar</th>\n",
              "      <th>Ionosphere</th>\n",
              "      <th>TicTacToe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "      <td>86.347619</td>\n",
              "      <td>93.815873</td>\n",
              "      <td>81.054167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>90.854762</td>\n",
              "      <td>82.224232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>93.815079</td>\n",
              "      <td>72.318311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>92.849206</td>\n",
              "      <td>61.814474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "      <td>83.802381</td>\n",
              "      <td>92.960317</td>\n",
              "      <td>65.721053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer      Sonar  Ionosphere  TicTacToe\n",
              "0   AdaBoost  96.552288      97.159847  86.347619   93.815873  81.054167\n",
              "1  GradBoost  98.075163      96.646633  78.145238   90.854762  82.224232\n",
              "2   CatBoost  97.967320      97.378303  87.076190   93.815079  72.318311\n",
              "3   LightGBM  97.120915      97.334612  82.361905   92.849206  61.814474\n",
              "4    XGBoost  97.797386      96.792626  83.802381   92.960317  65.721053"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Bupa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "bupa_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Bupa\\Bupa.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(345, 7)"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bupa_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = bupa_df.iloc[:, :-1]\n",
        "y = bupa_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:07<00:00,  1.35s/trial, best loss: -0.8695652173913043]\n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 1150.0, 'learning_rate': 0.036566586849114326, 'max_depth': 6.0, 'max_features': 'sqrt', 'min_samples_leaf': 3.0, 'min_samples_split': 2.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.54trial/s, best loss: -0.8115942028985508]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 650, 'learning_rate': 0.06856648459048352, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [01:02<00:00,  1.25s/trial, best loss: -0.7971014492753623]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 1000, 'learning_rate': 0.07885766008379519, 'min_child_samples': 8, 'max_depth': 2, 'reg_lambda': 2.215819236413667, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 46.39trial/s, best loss: -0.7391304347826086]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'goss', 'num_leaves': 50, 'learning_rate': 0.030743334125495195, 'min_child_samples': 20, 'reg_alpha': 1.2374175460929842, 'reg_lambda': 2.7904588669270254, 'colsample_by_tree': 0.6043264075687251, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:06<00:00,  7.32trial/s, best loss: -0.7971014492753623]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'dart', 'learning_rate': 0.04329402990235971, 'gamma': 0, 'max_depth': 6, 'min_child_weight': 2, 'colsample_bytree': 0.8839036553414338, 'colsample_bylevel': 0.13572776354954574, 'colsample_bynode': 0.32883430164648214, 'reg_alpha': 0.43424116154739917, 'reg_lambda': 1.9753629991445285, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Bupa Dataset ---------\n",
            "[0.77142857 0.74285714 0.71428571 0.71428571 0.77142857 0.88235294\n",
            " 0.67647059 0.64705882 0.67647059 0.61764706 0.65714286 0.57142857\n",
            " 0.68571429 0.8        0.68571429 0.70588235 0.70588235 0.76470588\n",
            " 0.73529412 0.67647059 0.65714286 0.71428571 0.8        0.74285714\n",
            " 0.77142857 0.70588235 0.79411765 0.73529412 0.70588235 0.67647059\n",
            " 0.77142857 0.77142857 0.74285714 0.82857143 0.74285714 0.79411765\n",
            " 0.64705882 0.70588235 0.70588235 0.67647059 0.74285714 0.8\n",
            " 0.65714286 0.68571429 0.77142857 0.73529412 0.73529412 0.64705882\n",
            " 0.67647059 0.70588235 0.65714286 0.77142857 0.74285714 0.62857143\n",
            " 0.77142857 0.70588235 0.70588235 0.70588235 0.58823529 0.58823529\n",
            " 0.74285714 0.77142857 0.6        0.57142857 0.68571429 0.73529412\n",
            " 0.61764706 0.82352941 0.85294118 0.67647059 0.8        0.65714286\n",
            " 0.82857143 0.74285714 0.65714286 0.79411765 0.76470588 0.70588235\n",
            " 0.67647059 0.73529412 0.8        0.68571429 0.71428571 0.82857143\n",
            " 0.68571429 0.70588235 0.76470588 0.64705882 0.73529412 0.64705882\n",
            " 0.82857143 0.74285714 0.74285714 0.6        0.65714286 0.82352941\n",
            " 0.64705882 0.76470588 0.61764706 0.67647059]\n",
            "Accuracy: 71.67% (6.58%)\n",
            "------------------------------\n",
            "--------- GradBoost on Bupa Dataset ---------\n",
            "[0.88571429 0.71428571 0.71428571 0.71428571 0.74285714 0.82352941\n",
            " 0.67647059 0.70588235 0.67647059 0.67647059 0.6        0.68571429\n",
            " 0.65714286 0.77142857 0.68571429 0.67647059 0.76470588 0.61764706\n",
            " 0.64705882 0.79411765 0.62857143 0.68571429 0.71428571 0.71428571\n",
            " 0.74285714 0.79411765 0.82352941 0.61764706 0.67647059 0.73529412\n",
            " 0.71428571 0.8        0.71428571 0.8        0.77142857 0.64705882\n",
            " 0.64705882 0.70588235 0.70588235 0.58823529 0.68571429 0.71428571\n",
            " 0.74285714 0.68571429 0.74285714 0.76470588 0.64705882 0.61764706\n",
            " 0.64705882 0.70588235 0.68571429 0.8        0.65714286 0.65714286\n",
            " 0.77142857 0.67647059 0.67647059 0.70588235 0.73529412 0.64705882\n",
            " 0.62857143 0.74285714 0.62857143 0.62857143 0.6        0.70588235\n",
            " 0.44117647 0.91176471 0.70588235 0.70588235 0.82857143 0.65714286\n",
            " 0.68571429 0.71428571 0.68571429 0.73529412 0.73529412 0.61764706\n",
            " 0.61764706 0.70588235 0.71428571 0.71428571 0.65714286 0.8\n",
            " 0.77142857 0.64705882 0.55882353 0.61764706 0.64705882 0.61764706\n",
            " 0.68571429 0.74285714 0.8        0.48571429 0.6        0.79411765\n",
            " 0.73529412 0.64705882 0.67647059 0.76470588]\n",
            "Accuracy: 69.78% (7.34%)\n",
            "------------------------------\n",
            "--------- CatBoost on Bupa Dataset ---------\n",
            "[0.85714286 0.77142857 0.71428571 0.68571429 0.65714286 0.82352941\n",
            " 0.58823529 0.55882353 0.61764706 0.70588235 0.74285714 0.6\n",
            " 0.62857143 0.71428571 0.65714286 0.64705882 0.73529412 0.61764706\n",
            " 0.73529412 0.73529412 0.65714286 0.62857143 0.65714286 0.74285714\n",
            " 0.68571429 0.67647059 0.79411765 0.64705882 0.73529412 0.70588235\n",
            " 0.77142857 0.68571429 0.68571429 0.77142857 0.82857143 0.88235294\n",
            " 0.61764706 0.64705882 0.70588235 0.64705882 0.77142857 0.68571429\n",
            " 0.74285714 0.65714286 0.77142857 0.67647059 0.70588235 0.61764706\n",
            " 0.70588235 0.70588235 0.71428571 0.68571429 0.68571429 0.65714286\n",
            " 0.8        0.73529412 0.70588235 0.76470588 0.67647059 0.64705882\n",
            " 0.74285714 0.68571429 0.62857143 0.6        0.77142857 0.73529412\n",
            " 0.52941176 0.82352941 0.85294118 0.61764706 0.77142857 0.57142857\n",
            " 0.71428571 0.82857143 0.71428571 0.79411765 0.73529412 0.58823529\n",
            " 0.64705882 0.64705882 0.74285714 0.74285714 0.6        0.77142857\n",
            " 0.65714286 0.61764706 0.76470588 0.64705882 0.64705882 0.70588235\n",
            " 0.65714286 0.65714286 0.74285714 0.6        0.71428571 0.85294118\n",
            " 0.64705882 0.64705882 0.55882353 0.79411765]\n",
            "Accuracy: 69.85% (7.31%)\n",
            "------------------------------\n",
            "--------- LightGBM on Bupa Dataset ---------\n",
            "[0.8        0.74285714 0.65714286 0.65714286 0.6        0.73529412\n",
            " 0.55882353 0.73529412 0.58823529 0.76470588 0.6        0.68571429\n",
            " 0.6        0.8        0.77142857 0.73529412 0.79411765 0.64705882\n",
            " 0.73529412 0.73529412 0.6        0.54285714 0.68571429 0.68571429\n",
            " 0.82857143 0.82352941 0.85294118 0.55882353 0.76470588 0.67647059\n",
            " 0.71428571 0.68571429 0.71428571 0.82857143 0.71428571 0.76470588\n",
            " 0.52941176 0.73529412 0.79411765 0.64705882 0.62857143 0.77142857\n",
            " 0.71428571 0.68571429 0.77142857 0.73529412 0.70588235 0.55882353\n",
            " 0.58823529 0.70588235 0.65714286 0.77142857 0.65714286 0.54285714\n",
            " 0.82857143 0.79411765 0.82352941 0.76470588 0.70588235 0.64705882\n",
            " 0.6        0.8        0.71428571 0.74285714 0.68571429 0.58823529\n",
            " 0.61764706 0.85294118 0.67647059 0.61764706 0.68571429 0.68571429\n",
            " 0.68571429 0.71428571 0.74285714 0.79411765 0.70588235 0.58823529\n",
            " 0.58823529 0.79411765 0.74285714 0.74285714 0.8        0.8\n",
            " 0.62857143 0.70588235 0.58823529 0.76470588 0.58823529 0.64705882\n",
            " 0.62857143 0.68571429 0.74285714 0.51428571 0.71428571 0.73529412\n",
            " 0.70588235 0.67647059 0.76470588 0.58823529]\n",
            "Accuracy: 69.79% (8.14%)\n",
            "------------------------------\n",
            "--------- XGBoost on Bupa Dataset ---------\n",
            "[0.91428571 0.8        0.71428571 0.71428571 0.62857143 0.79411765\n",
            " 0.64705882 0.76470588 0.70588235 0.73529412 0.71428571 0.74285714\n",
            " 0.65714286 0.82857143 0.77142857 0.70588235 0.85294118 0.67647059\n",
            " 0.67647059 0.79411765 0.77142857 0.68571429 0.82857143 0.71428571\n",
            " 0.85714286 0.76470588 0.79411765 0.61764706 0.67647059 0.73529412\n",
            " 0.77142857 0.77142857 0.71428571 0.85714286 0.77142857 0.76470588\n",
            " 0.61764706 0.76470588 0.73529412 0.73529412 0.8        0.74285714\n",
            " 0.71428571 0.74285714 0.71428571 0.85294118 0.67647059 0.67647059\n",
            " 0.73529412 0.76470588 0.77142857 0.8        0.74285714 0.65714286\n",
            " 0.8        0.76470588 0.79411765 0.70588235 0.76470588 0.70588235\n",
            " 0.74285714 0.85714286 0.71428571 0.71428571 0.71428571 0.70588235\n",
            " 0.61764706 0.85294118 0.88235294 0.67647059 0.82857143 0.65714286\n",
            " 0.82857143 0.82857143 0.74285714 0.76470588 0.73529412 0.61764706\n",
            " 0.61764706 0.70588235 0.77142857 0.74285714 0.8        0.82857143\n",
            " 0.74285714 0.70588235 0.79411765 0.70588235 0.61764706 0.76470588\n",
            " 0.68571429 0.77142857 0.85714286 0.6        0.68571429 0.88235294\n",
            " 0.76470588 0.76470588 0.76470588 0.70588235]\n",
            "Accuracy: 74.48% (6.77%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "bupa_scores = []\n",
        "bupa_mean = []\n",
        "bupa_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    bupa_scores.append(results)\n",
        "    bupa_mean.append(results.mean()*100)\n",
        "    bupa_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Bupa Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Bupa scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(bupa_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Bupa'] = bupa_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <th>Sonar</th>\n",
              "      <th>Ionosphere</th>\n",
              "      <th>TicTacToe</th>\n",
              "      <th>Bupa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "      <td>86.347619</td>\n",
              "      <td>93.815873</td>\n",
              "      <td>81.054167</td>\n",
              "      <td>71.669748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>90.854762</td>\n",
              "      <td>82.224232</td>\n",
              "      <td>69.783193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>93.815079</td>\n",
              "      <td>72.318311</td>\n",
              "      <td>69.846218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>92.849206</td>\n",
              "      <td>61.814474</td>\n",
              "      <td>69.794118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "      <td>83.802381</td>\n",
              "      <td>92.960317</td>\n",
              "      <td>65.721053</td>\n",
              "      <td>74.475630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer      Sonar  Ionosphere  TicTacToe  \\\n",
              "0   AdaBoost  96.552288      97.159847  86.347619   93.815873  81.054167   \n",
              "1  GradBoost  98.075163      96.646633  78.145238   90.854762  82.224232   \n",
              "2   CatBoost  97.967320      97.378303  87.076190   93.815079  72.318311   \n",
              "3   LightGBM  97.120915      97.334612  82.361905   92.849206  61.814474   \n",
              "4    XGBoost  97.797386      96.792626  83.802381   92.960317  65.721053   \n",
              "\n",
              "        Bupa  \n",
              "0  71.669748  \n",
              "1  69.783193  \n",
              "2  69.846218  \n",
              "3  69.794118  \n",
              "4  74.475630  "
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pima**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "pima_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Pima\\Diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pima_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = pima_df.iloc[:, :-1]\n",
        "y = pima_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:36<00:00,  1.94s/trial, best loss: -0.7857142857142857]\n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 1500.0, 'learning_rate': 0.010436960322525368, 'max_depth': 1.0, 'max_features': None, 'min_samples_leaf': 5.0, 'min_samples_split': 4.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:24<00:00,  2.00trial/s, best loss: -0.7922077922077922]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 200, 'learning_rate': 0.05871692740564188, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 2.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [01:13<00:00,  1.46s/trial, best loss: -0.7792207792207793]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 50, 'learning_rate': 0.010922414344918462, 'min_child_samples': 10, 'max_depth': 4, 'reg_lambda': 4.685483905860218, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 36.95trial/s, best loss: -0.7922077922077922]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'dart', 'num_leaves': 95, 'learning_rate': 0.04955748086609083, 'min_child_samples': 140, 'reg_alpha': 1.1745781431363478, 'reg_lambda': 1.5581466068782919, 'colsample_by_tree': 0.9952093023356591, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:05<00:00,  8.41trial/s, best loss: -0.7987012987012987]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'gbtree', 'learning_rate': 0.011777426690454684, 'gamma': 2, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.6642423404208758, 'colsample_bylevel': 0.8389604376670141, 'colsample_bynode': 0.46801910869053165, 'reg_alpha': 1.3842922617481603, 'reg_lambda': 0.25127542856871243, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Pima Dataset ---------\n",
            "[0.80519481 0.76623377 0.75324675 0.85714286 0.81818182 0.74025974\n",
            " 0.74025974 0.71428571 0.75       0.69736842 0.77922078 0.7012987\n",
            " 0.75324675 0.74025974 0.74025974 0.84415584 0.80519481 0.72727273\n",
            " 0.73684211 0.82894737 0.81818182 0.74025974 0.77922078 0.68831169\n",
            " 0.75324675 0.76623377 0.74025974 0.81818182 0.71052632 0.69736842\n",
            " 0.80519481 0.75324675 0.76623377 0.77922078 0.79220779 0.74025974\n",
            " 0.77922078 0.80519481 0.76315789 0.67105263 0.76623377 0.77922078\n",
            " 0.84415584 0.81818182 0.80519481 0.75324675 0.68831169 0.77922078\n",
            " 0.73684211 0.69736842 0.76623377 0.77922078 0.76623377 0.72727273\n",
            " 0.76623377 0.80519481 0.71428571 0.74025974 0.76315789 0.72368421\n",
            " 0.76623377 0.74025974 0.75324675 0.76623377 0.71428571 0.83116883\n",
            " 0.74025974 0.74025974 0.76315789 0.75       0.80519481 0.75324675\n",
            " 0.72727273 0.84415584 0.74025974 0.74025974 0.77922078 0.72727273\n",
            " 0.75       0.73684211 0.72727273 0.72727273 0.79220779 0.79220779\n",
            " 0.77922078 0.81818182 0.74025974 0.67532468 0.76315789 0.81578947\n",
            " 0.79220779 0.76623377 0.80519481 0.77922078 0.75324675 0.77922078\n",
            " 0.76623377 0.71428571 0.69736842 0.76315789]\n",
            "Accuracy: 76.10% (3.95%)\n",
            "------------------------------\n",
            "--------- GradBoost on Pima Dataset ---------\n",
            "[0.74025974 0.77922078 0.77922078 0.81818182 0.79220779 0.76623377\n",
            " 0.72727273 0.74025974 0.71052632 0.75       0.76623377 0.7012987\n",
            " 0.80519481 0.75324675 0.72727273 0.85714286 0.83116883 0.76623377\n",
            " 0.71052632 0.82894737 0.75324675 0.74025974 0.80519481 0.7012987\n",
            " 0.79220779 0.77922078 0.75324675 0.83116883 0.73684211 0.75\n",
            " 0.79220779 0.75324675 0.76623377 0.80519481 0.81818182 0.72727273\n",
            " 0.81818182 0.79220779 0.73684211 0.64473684 0.74025974 0.77922078\n",
            " 0.83116883 0.79220779 0.80519481 0.76623377 0.7012987  0.83116883\n",
            " 0.77631579 0.69736842 0.79220779 0.75324675 0.76623377 0.74025974\n",
            " 0.77922078 0.81818182 0.76623377 0.67532468 0.72368421 0.75\n",
            " 0.74025974 0.71428571 0.72727273 0.81818182 0.7012987  0.84415584\n",
            " 0.74025974 0.72727273 0.77631579 0.76315789 0.79220779 0.75324675\n",
            " 0.72727273 0.83116883 0.76623377 0.77922078 0.76623377 0.75324675\n",
            " 0.69736842 0.80263158 0.75324675 0.7012987  0.81818182 0.79220779\n",
            " 0.81818182 0.77922078 0.75324675 0.66233766 0.71052632 0.80263158\n",
            " 0.77922078 0.79220779 0.79220779 0.76623377 0.74025974 0.79220779\n",
            " 0.76623377 0.75324675 0.73684211 0.76315789]\n",
            "Accuracy: 76.43% (4.16%)\n",
            "------------------------------\n",
            "--------- CatBoost on Pima Dataset ---------\n",
            "[0.77922078 0.74025974 0.76623377 0.84415584 0.80519481 0.72727273\n",
            " 0.72727273 0.74025974 0.69736842 0.77631579 0.72727273 0.68831169\n",
            " 0.79220779 0.71428571 0.67532468 0.87012987 0.83116883 0.74025974\n",
            " 0.67105263 0.78947368 0.72727273 0.74025974 0.80519481 0.68831169\n",
            " 0.77922078 0.75324675 0.80519481 0.81818182 0.72368421 0.73684211\n",
            " 0.80519481 0.76623377 0.75324675 0.76623377 0.79220779 0.7012987\n",
            " 0.77922078 0.77922078 0.75       0.64473684 0.71428571 0.81818182\n",
            " 0.79220779 0.77922078 0.76623377 0.76623377 0.66233766 0.77922078\n",
            " 0.76315789 0.72368421 0.83116883 0.76623377 0.72727273 0.71428571\n",
            " 0.75324675 0.81818182 0.75324675 0.72727273 0.73684211 0.76315789\n",
            " 0.74025974 0.76623377 0.72727273 0.77922078 0.74025974 0.85714286\n",
            " 0.75324675 0.67532468 0.76315789 0.73684211 0.76623377 0.76623377\n",
            " 0.74025974 0.80519481 0.72727273 0.75324675 0.76623377 0.79220779\n",
            " 0.71052632 0.73684211 0.76623377 0.71428571 0.79220779 0.84415584\n",
            " 0.77922078 0.75324675 0.75324675 0.67532468 0.64473684 0.81578947\n",
            " 0.72727273 0.74025974 0.75324675 0.71428571 0.76623377 0.80519481\n",
            " 0.81818182 0.74025974 0.71052632 0.73684211]\n",
            "Accuracy: 75.53% (4.47%)\n",
            "------------------------------\n",
            "--------- LightGBM on Pima Dataset ---------\n",
            "[0.79220779 0.79220779 0.74025974 0.81818182 0.81818182 0.74025974\n",
            " 0.80519481 0.72727273 0.65789474 0.68421053 0.68831169 0.71428571\n",
            " 0.81818182 0.74025974 0.77922078 0.85714286 0.72727273 0.77922078\n",
            " 0.71052632 0.85526316 0.79220779 0.75324675 0.77922078 0.62337662\n",
            " 0.80519481 0.74025974 0.71428571 0.79220779 0.75       0.72368421\n",
            " 0.79220779 0.74025974 0.80519481 0.79220779 0.76623377 0.74025974\n",
            " 0.76623377 0.77922078 0.76315789 0.69736842 0.72727273 0.84415584\n",
            " 0.79220779 0.77922078 0.76623377 0.83116883 0.63636364 0.77922078\n",
            " 0.75       0.75       0.80519481 0.77922078 0.76623377 0.74025974\n",
            " 0.79220779 0.77922078 0.66233766 0.68831169 0.80263158 0.78947368\n",
            " 0.79220779 0.83116883 0.71428571 0.81818182 0.7012987  0.79220779\n",
            " 0.75324675 0.74025974 0.75       0.75       0.83116883 0.74025974\n",
            " 0.68831169 0.79220779 0.68831169 0.76623377 0.76623377 0.77922078\n",
            " 0.72368421 0.75       0.71428571 0.76623377 0.76623377 0.77922078\n",
            " 0.74025974 0.77922078 0.75324675 0.7012987  0.71052632 0.78947368\n",
            " 0.75324675 0.79220779 0.79220779 0.71428571 0.79220779 0.72727273\n",
            " 0.76623377 0.80519481 0.75       0.73684211]\n",
            "Accuracy: 75.92% (4.53%)\n",
            "------------------------------\n",
            "--------- XGBoost on Pima Dataset ---------\n",
            "[0.76623377 0.74025974 0.74025974 0.84415584 0.81818182 0.76623377\n",
            " 0.71428571 0.72727273 0.71052632 0.71052632 0.71428571 0.68831169\n",
            " 0.77922078 0.76623377 0.67532468 0.84415584 0.79220779 0.71428571\n",
            " 0.72368421 0.77631579 0.76623377 0.75324675 0.77922078 0.72727273\n",
            " 0.77922078 0.7012987  0.72727273 0.84415584 0.72368421 0.72368421\n",
            " 0.72727273 0.77922078 0.77922078 0.79220779 0.77922078 0.71428571\n",
            " 0.77922078 0.75324675 0.72368421 0.69736842 0.76623377 0.72727273\n",
            " 0.80519481 0.77922078 0.74025974 0.76623377 0.72727273 0.74025974\n",
            " 0.76315789 0.71052632 0.76623377 0.72727273 0.76623377 0.75324675\n",
            " 0.74025974 0.77922078 0.75324675 0.75324675 0.72368421 0.76315789\n",
            " 0.77922078 0.75324675 0.77922078 0.75324675 0.72727273 0.81818182\n",
            " 0.74025974 0.74025974 0.77631579 0.75       0.80519481 0.72727273\n",
            " 0.76623377 0.79220779 0.74025974 0.72727273 0.80519481 0.74025974\n",
            " 0.72368421 0.72368421 0.7012987  0.68831169 0.80519481 0.77922078\n",
            " 0.81818182 0.77922078 0.74025974 0.67532468 0.69736842 0.82894737\n",
            " 0.76623377 0.75324675 0.77922078 0.75324675 0.74025974 0.76623377\n",
            " 0.76623377 0.74025974 0.71052632 0.76315789]\n",
            "Accuracy: 75.33% (3.63%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "pima_scores = []\n",
        "pima_mean = []\n",
        "pima_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    pima_scores.append(results)\n",
        "    pima_mean.append(results.mean()*100)\n",
        "    pima_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Pima Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Pima scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(pima_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Pima'] = pima_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <th>Sonar</th>\n",
              "      <th>Ionosphere</th>\n",
              "      <th>TicTacToe</th>\n",
              "      <th>Bupa</th>\n",
              "      <th>Pima</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "      <td>86.347619</td>\n",
              "      <td>93.815873</td>\n",
              "      <td>81.054167</td>\n",
              "      <td>71.669748</td>\n",
              "      <td>76.101504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>90.854762</td>\n",
              "      <td>82.224232</td>\n",
              "      <td>69.783193</td>\n",
              "      <td>76.426863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>93.815079</td>\n",
              "      <td>72.318311</td>\n",
              "      <td>69.846218</td>\n",
              "      <td>75.527683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>92.849206</td>\n",
              "      <td>61.814474</td>\n",
              "      <td>69.794118</td>\n",
              "      <td>75.920711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "      <td>83.802381</td>\n",
              "      <td>92.960317</td>\n",
              "      <td>65.721053</td>\n",
              "      <td>74.475630</td>\n",
              "      <td>75.334074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer      Sonar  Ionosphere  TicTacToe  \\\n",
              "0   AdaBoost  96.552288      97.159847  86.347619   93.815873  81.054167   \n",
              "1  GradBoost  98.075163      96.646633  78.145238   90.854762  82.224232   \n",
              "2   CatBoost  97.967320      97.378303  87.076190   93.815079  72.318311   \n",
              "3   LightGBM  97.120915      97.334612  82.361905   92.849206  61.814474   \n",
              "4    XGBoost  97.797386      96.792626  83.802381   92.960317  65.721053   \n",
              "\n",
              "        Bupa       Pima  \n",
              "0  71.669748  76.101504  \n",
              "1  69.783193  76.426863  \n",
              "2  69.846218  75.527683  \n",
              "3  69.794118  75.920711  \n",
              "4  74.475630  75.334074  "
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Heart**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "heart_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Heart\\Heart.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = heart_df.iloc[:, :-1]\n",
        "y = heart_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:36<00:00,  1.93s/trial, best loss: -0.7857142857142857]\n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 1500.0, 'learning_rate': 0.010436960322525368, 'max_depth': 1.0, 'max_features': None, 'min_samples_leaf': 5.0, 'min_samples_split': 4.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:24<00:00,  2.02trial/s, best loss: -0.7922077922077922]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 200, 'learning_rate': 0.05871692740564188, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 2.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [01:11<00:00,  1.42s/trial, best loss: -0.7792207792207793]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 50, 'learning_rate': 0.010922414344918462, 'min_child_samples': 10, 'max_depth': 4, 'reg_lambda': 4.685483905860218, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 33.19trial/s, best loss: -0.7922077922077922]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'dart', 'num_leaves': 95, 'learning_rate': 0.04955748086609083, 'min_child_samples': 140, 'reg_alpha': 1.1745781431363478, 'reg_lambda': 1.5581466068782919, 'colsample_by_tree': 0.9952093023356591, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:06<00:00,  8.27trial/s, best loss: -0.7987012987012987]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'gbtree', 'learning_rate': 0.011777426690454684, 'gamma': 2, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.6642423404208758, 'colsample_bylevel': 0.8389604376670141, 'colsample_bynode': 0.46801910869053165, 'reg_alpha': 1.3842922617481603, 'reg_lambda': 0.25127542856871243, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Heart Dataset ---------\n",
            "[0.81481481 0.81481481 0.81481481 0.96296296 0.77777778 0.85185185\n",
            " 0.88888889 0.77777778 0.81481481 0.96296296 0.85185185 0.77777778\n",
            " 0.88888889 0.81481481 0.88888889 0.85185185 0.96296296 0.66666667\n",
            " 0.81481481 0.85185185 0.77777778 0.96296296 0.81481481 0.74074074\n",
            " 0.96296296 0.81481481 0.81481481 0.74074074 0.81481481 0.92592593\n",
            " 0.81481481 0.88888889 0.85185185 0.81481481 0.81481481 0.88888889\n",
            " 0.81481481 0.77777778 0.85185185 0.81481481 0.81481481 0.96296296\n",
            " 0.74074074 0.88888889 0.7037037  0.88888889 0.77777778 0.88888889\n",
            " 0.77777778 0.88888889 0.66666667 0.81481481 0.85185185 0.85185185\n",
            " 0.77777778 0.88888889 0.85185185 0.81481481 0.81481481 0.85185185\n",
            " 0.85185185 0.88888889 0.85185185 0.88888889 0.85185185 0.77777778\n",
            " 0.85185185 0.74074074 0.77777778 0.92592593 0.88888889 0.85185185\n",
            " 0.77777778 0.88888889 0.81481481 0.88888889 0.77777778 0.88888889\n",
            " 0.81481481 0.85185185 0.92592593 0.85185185 0.85185185 0.85185185\n",
            " 0.74074074 0.81481481 0.85185185 0.7037037  0.88888889 0.85185185\n",
            " 0.85185185 0.88888889 0.88888889 0.81481481 0.88888889 0.7037037\n",
            " 0.81481481 0.85185185 0.77777778 0.85185185]\n",
            "Accuracy: 83.59% (6.27%)\n",
            "------------------------------\n",
            "--------- GradBoost on Heart Dataset ---------\n",
            "[0.81481481 0.85185185 0.85185185 0.88888889 0.77777778 0.85185185\n",
            " 0.81481481 0.7037037  0.77777778 0.92592593 0.85185185 0.85185185\n",
            " 0.85185185 0.77777778 0.85185185 0.85185185 0.96296296 0.74074074\n",
            " 0.85185185 0.81481481 0.66666667 0.96296296 0.77777778 0.85185185\n",
            " 1.         0.81481481 0.81481481 0.77777778 0.77777778 0.92592593\n",
            " 0.88888889 0.92592593 0.88888889 0.81481481 0.74074074 0.88888889\n",
            " 0.81481481 0.85185185 0.81481481 0.81481481 0.77777778 0.92592593\n",
            " 0.88888889 0.92592593 0.7037037  0.81481481 0.74074074 0.85185185\n",
            " 0.81481481 0.85185185 0.7037037  0.81481481 0.85185185 0.88888889\n",
            " 0.77777778 0.88888889 0.92592593 0.77777778 0.85185185 0.88888889\n",
            " 0.81481481 0.85185185 0.92592593 0.88888889 0.85185185 0.77777778\n",
            " 0.85185185 0.74074074 0.88888889 0.85185185 0.88888889 0.85185185\n",
            " 0.77777778 0.81481481 0.85185185 0.85185185 0.77777778 0.88888889\n",
            " 0.77777778 0.92592593 0.92592593 0.85185185 0.77777778 0.85185185\n",
            " 0.74074074 0.81481481 0.77777778 0.81481481 0.85185185 0.81481481\n",
            " 0.81481481 0.92592593 0.88888889 0.85185185 0.88888889 0.77777778\n",
            " 0.81481481 0.77777778 0.85185185 0.88888889]\n",
            "Accuracy: 83.70% (6.18%)\n",
            "------------------------------\n",
            "--------- CatBoost on Heart Dataset ---------\n",
            "[0.77777778 0.85185185 0.88888889 0.88888889 0.77777778 0.85185185\n",
            " 0.81481481 0.66666667 0.77777778 0.92592593 0.81481481 0.81481481\n",
            " 0.92592593 0.81481481 0.81481481 0.81481481 0.92592593 0.7037037\n",
            " 0.85185185 0.81481481 0.66666667 0.96296296 0.81481481 0.81481481\n",
            " 0.96296296 0.81481481 0.85185185 0.81481481 0.85185185 0.96296296\n",
            " 0.85185185 0.92592593 0.85185185 0.92592593 0.7037037  0.92592593\n",
            " 0.81481481 0.85185185 0.77777778 0.81481481 0.77777778 0.92592593\n",
            " 0.85185185 0.88888889 0.7037037  0.81481481 0.74074074 0.85185185\n",
            " 0.85185185 0.88888889 0.66666667 0.88888889 0.85185185 0.92592593\n",
            " 0.77777778 0.88888889 0.88888889 0.74074074 0.85185185 0.88888889\n",
            " 0.81481481 0.88888889 0.88888889 0.88888889 0.81481481 0.74074074\n",
            " 0.81481481 0.7037037  0.88888889 0.85185185 0.92592593 0.85185185\n",
            " 0.81481481 0.85185185 0.85185185 0.85185185 0.81481481 0.88888889\n",
            " 0.81481481 0.88888889 0.88888889 0.85185185 0.77777778 0.85185185\n",
            " 0.77777778 0.85185185 0.77777778 0.81481481 0.88888889 0.77777778\n",
            " 0.85185185 0.92592593 0.81481481 0.85185185 0.88888889 0.77777778\n",
            " 0.81481481 0.81481481 0.81481481 0.92592593]\n",
            "Accuracy: 83.74% (6.50%)\n",
            "------------------------------\n",
            "--------- LightGBM on Heart Dataset ---------\n",
            "[0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
            " 0.44444444 0.44444444 0.44444444 0.44444444]\n",
            "Accuracy: 44.44% (0.00%)\n",
            "------------------------------\n",
            "--------- XGBoost on Heart Dataset ---------\n",
            "[0.77777778 0.88888889 0.85185185 0.96296296 0.74074074 0.81481481\n",
            " 0.85185185 0.81481481 0.81481481 0.96296296 0.81481481 0.81481481\n",
            " 0.88888889 0.77777778 0.88888889 0.85185185 0.96296296 0.7037037\n",
            " 0.81481481 0.85185185 0.77777778 0.96296296 0.77777778 0.85185185\n",
            " 0.96296296 0.77777778 0.92592593 0.81481481 0.77777778 0.92592593\n",
            " 0.88888889 0.92592593 0.81481481 0.81481481 0.77777778 0.88888889\n",
            " 0.77777778 0.81481481 0.88888889 0.85185185 0.77777778 0.96296296\n",
            " 0.85185185 0.92592593 0.74074074 0.88888889 0.81481481 0.85185185\n",
            " 0.81481481 0.85185185 0.7037037  0.81481481 0.88888889 0.92592593\n",
            " 0.81481481 0.81481481 0.81481481 0.81481481 0.85185185 0.96296296\n",
            " 0.85185185 0.88888889 0.81481481 0.85185185 0.88888889 0.77777778\n",
            " 0.85185185 0.74074074 0.88888889 0.92592593 0.88888889 0.77777778\n",
            " 0.74074074 0.85185185 0.85185185 0.81481481 0.77777778 0.88888889\n",
            " 0.85185185 0.88888889 0.92592593 0.88888889 0.92592593 0.85185185\n",
            " 0.66666667 0.81481481 0.85185185 0.77777778 0.85185185 0.88888889\n",
            " 0.85185185 0.92592593 0.88888889 0.81481481 0.88888889 0.77777778\n",
            " 0.81481481 0.77777778 0.81481481 0.88888889]\n",
            "Accuracy: 84.44% (6.31%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "heart_scores = []\n",
        "heart_mean = []\n",
        "heart_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    heart_scores.append(results)\n",
        "    heart_mean.append(results.mean()*100)\n",
        "    heart_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Heart Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Heart scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(heart_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Heart'] = heart_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <th>Sonar</th>\n",
              "      <th>Ionosphere</th>\n",
              "      <th>TicTacToe</th>\n",
              "      <th>Bupa</th>\n",
              "      <th>Pima</th>\n",
              "      <th>Heart</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "      <td>86.347619</td>\n",
              "      <td>93.815873</td>\n",
              "      <td>81.054167</td>\n",
              "      <td>71.669748</td>\n",
              "      <td>76.101504</td>\n",
              "      <td>83.592593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>90.854762</td>\n",
              "      <td>82.224232</td>\n",
              "      <td>69.783193</td>\n",
              "      <td>76.426863</td>\n",
              "      <td>83.703704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>93.815079</td>\n",
              "      <td>72.318311</td>\n",
              "      <td>69.846218</td>\n",
              "      <td>75.527683</td>\n",
              "      <td>83.740741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>92.849206</td>\n",
              "      <td>61.814474</td>\n",
              "      <td>69.794118</td>\n",
              "      <td>75.920711</td>\n",
              "      <td>44.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "      <td>83.802381</td>\n",
              "      <td>92.960317</td>\n",
              "      <td>65.721053</td>\n",
              "      <td>74.475630</td>\n",
              "      <td>75.334074</td>\n",
              "      <td>84.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer      Sonar  Ionosphere  TicTacToe  \\\n",
              "0   AdaBoost  96.552288      97.159847  86.347619   93.815873  81.054167   \n",
              "1  GradBoost  98.075163      96.646633  78.145238   90.854762  82.224232   \n",
              "2   CatBoost  97.967320      97.378303  87.076190   93.815079  72.318311   \n",
              "3   LightGBM  97.120915      97.334612  82.361905   92.849206  61.814474   \n",
              "4    XGBoost  97.797386      96.792626  83.802381   92.960317  65.721053   \n",
              "\n",
              "        Bupa       Pima      Heart  \n",
              "0  71.669748  76.101504  83.592593  \n",
              "1  69.783193  76.426863  83.703704  \n",
              "2  69.846218  75.527683  83.740741  \n",
              "3  69.794118  75.920711  44.444444  \n",
              "4  74.475630  75.334074  84.444444  "
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Liver**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "liver_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Liver\\Bupa.data', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = liver_df.iloc[:, :-1]\n",
        "y = liver_df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:39<00:00,  2.00s/trial, best loss: -0.7857142857142857]\n",
            "Best hyperparameters for AdaBoost:\n",
            "{'n_estimators': 1500.0, 'learning_rate': 0.010436960322525368, 'max_depth': 1.0, 'max_features': None, 'min_samples_leaf': 5.0, 'min_samples_split': 4.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:25<00:00,  1.94trial/s, best loss: -0.7922077922077922]\n",
            "Best hyperparameters for GradBoost:\n",
            "{'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 200, 'learning_rate': 0.05871692740564188, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 2.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
            "100%|██████████| 50/50 [01:13<00:00,  1.47s/trial, best loss: -0.7792207792207793]\n",
            "Best hyperparameters for CatBoost:\n",
            "{'n_estimators': 50, 'learning_rate': 0.010922414344918462, 'min_child_samples': 10, 'max_depth': 4, 'reg_lambda': 4.685483905860218, 'silent': True, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:01<00:00, 32.84trial/s, best loss: -0.7922077922077922]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'class_weight': 'balanced', 'boosting_type': 'dart', 'num_leaves': 95, 'learning_rate': 0.04955748086609083, 'min_child_samples': 140, 'reg_alpha': 1.1745781431363478, 'reg_lambda': 1.5581466068782919, 'colsample_by_tree': 0.9952093023356591, 'verbosity': -1, 'random_state': 42}\n",
            "100%|██████████| 50/50 [00:06<00:00,  7.34trial/s, best loss: -0.7987012987012987]\n",
            "Best hyperparameters for XGBoost:\n",
            "{'booster': 'gbtree', 'learning_rate': 0.011777426690454684, 'gamma': 2, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.6642423404208758, 'colsample_bylevel': 0.8389604376670141, 'colsample_bynode': 0.46801910869053165, 'reg_alpha': 1.3842922617481603, 'reg_lambda': 0.25127542856871243, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt.pyll import scope\n",
        "import warnings\n",
        "\n",
        "# Filter out the FutureWarning related to is_sparse\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
        "\n",
        "best_hyperparams = {\n",
        "    'AdaBoost': {},\n",
        "    'GradBoost': {},\n",
        "    'CatBoost': {},\n",
        "    'LightGBM': {},\n",
        "    'XGBoost': {}\n",
        "}\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_adaboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'estimator': {\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "        'max_features': hp.choice('max_features', max_features_choices),\n",
        "    },\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "criterion_choices = ['friedman_mse', 'squared_error']\n",
        "max_features_choices = [None, 'sqrt', 'log2']\n",
        "space_gradientboost = {\n",
        "    'criterion': hp.choice('criterion', criterion_choices),\n",
        "    'max_features': hp.choice('max_features', max_features_choices),\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
        "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
        "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
        "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "space_catboost = {\n",
        "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'silent': True\n",
        "}\n",
        "\n",
        "class_weight_choices = ['balanced']\n",
        "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
        "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "booster_choices = ['gbtree', 'dart']\n",
        "space_xgboost = {\n",
        "    'booster': hp.choice('booster', booster_choices),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
        "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
        "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
        "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
        "]\n",
        "\n",
        "\n",
        "# Performing hyperparameter tuning for each algorithm\n",
        "\n",
        "rstate=np.random.default_rng(42)\n",
        "\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best AdaBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': best['n_estimators'],\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': best['max_depth'],\n",
        "            'max_features': max_features_label,\n",
        "            'min_samples_leaf': best['min_samples_leaf'],\n",
        "            'min_samples_split': best['min_samples_split'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "\n",
        "\n",
        "        # Map the choice labels        \n",
        "        criterion_label = criterion_choices[best['criterion']]\n",
        "        max_features_label = max_features_choices[best['max_features']]\n",
        "\n",
        "        # Store the best GradBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'criterion': criterion_label,\n",
        "            'max_features': max_features_label,\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_samples_split': int(best['min_samples_split']),\n",
        "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
        "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
        "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
        "            'ccp_alpha': best['ccp_alpha'],\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])           \n",
        "    \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Store the best CatBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'n_estimators': int(best['n_estimators']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'silent': True,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'LightGBM':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        class_weight_label = class_weight_choices[best['class_weight']]\n",
        "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
        "\n",
        "        # Store the best LightGBM hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'class_weight': class_weight_label,\n",
        "            'boosting_type': boosting_type_label,\n",
        "            'num_leaves': int(best['num_leaves']),\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'min_child_samples': int(best['min_child_samples']),\n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],\n",
        "            'colsample_by_tree': best['colsample_by_tree'],\n",
        "            'verbosity': -1,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])\n",
        "\n",
        "    if algorithm_name == 'XGBoost':\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
        "        \n",
        "        # Map the choice labels\n",
        "        booster_label = booster_choices[best['booster']]        \n",
        " \n",
        "        # Store the best XGBoost hyperparameters\n",
        "        best_hyperparams[algorithm_name] = {\n",
        "            'booster': booster_label,\n",
        "            'learning_rate': best['learning_rate'],\n",
        "            'gamma': int(best['gamma']),\n",
        "            'max_depth': int(best['max_depth']),\n",
        "            'min_child_weight': int(best['min_child_weight']),\n",
        "            'colsample_bytree': best['colsample_bytree'],\n",
        "            'colsample_bylevel': best['colsample_bylevel'],\n",
        "            'colsample_bynode': best['colsample_bynode'],            \n",
        "            'reg_alpha': best['reg_alpha'],\n",
        "            'reg_lambda': best['reg_lambda'],            \n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "        print(best_hyperparams[algorithm_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- AdaBoost on Liver Dataset ---------\n",
            "[0.91428571 0.8        0.62857143 0.77142857 0.62857143 0.85294118\n",
            " 0.79411765 0.61764706 0.64705882 0.70588235 0.77142857 0.65714286\n",
            " 0.62857143 0.8        0.8        0.70588235 0.76470588 0.64705882\n",
            " 0.70588235 0.76470588 0.62857143 0.54285714 0.77142857 0.8\n",
            " 0.8        0.85294118 0.79411765 0.58823529 0.67647059 0.70588235\n",
            " 0.8        0.77142857 0.71428571 0.85714286 0.74285714 0.76470588\n",
            " 0.64705882 0.70588235 0.70588235 0.64705882 0.65714286 0.74285714\n",
            " 0.68571429 0.57142857 0.8        0.73529412 0.76470588 0.67647059\n",
            " 0.70588235 0.76470588 0.71428571 0.74285714 0.74285714 0.65714286\n",
            " 0.74285714 0.76470588 0.76470588 0.82352941 0.70588235 0.64705882\n",
            " 0.68571429 0.88571429 0.62857143 0.68571429 0.71428571 0.67647059\n",
            " 0.70588235 0.79411765 0.76470588 0.61764706 0.82857143 0.6\n",
            " 0.8        0.77142857 0.77142857 0.82352941 0.76470588 0.64705882\n",
            " 0.70588235 0.67647059 0.65714286 0.74285714 0.77142857 0.8\n",
            " 0.74285714 0.73529412 0.76470588 0.67647059 0.70588235 0.70588235\n",
            " 0.71428571 0.8        0.71428571 0.68571429 0.65714286 0.88235294\n",
            " 0.76470588 0.64705882 0.79411765 0.73529412]\n",
            "Accuracy: 72.78% (7.25%)\n",
            "------------------------------\n",
            "--------- GradBoost on Liver Dataset ---------\n",
            "[0.68571429 0.71428571 0.54285714 0.68571429 0.65714286 0.67647059\n",
            " 0.61764706 0.64705882 0.64705882 0.64705882 0.65714286 0.54285714\n",
            " 0.57142857 0.6        0.6        0.64705882 0.70588235 0.64705882\n",
            " 0.64705882 0.61764706 0.62857143 0.65714286 0.65714286 0.57142857\n",
            " 0.57142857 0.61764706 0.64705882 0.5        0.61764706 0.67647059\n",
            " 0.68571429 0.68571429 0.6        0.68571429 0.65714286 0.70588235\n",
            " 0.55882353 0.58823529 0.73529412 0.58823529 0.6        0.62857143\n",
            " 0.6        0.6        0.62857143 0.67647059 0.58823529 0.64705882\n",
            " 0.61764706 0.64705882 0.6        0.68571429 0.65714286 0.62857143\n",
            " 0.6        0.70588235 0.70588235 0.67647059 0.67647059 0.58823529\n",
            " 0.62857143 0.68571429 0.62857143 0.62857143 0.54285714 0.64705882\n",
            " 0.67647059 0.61764706 0.70588235 0.61764706 0.62857143 0.62857143\n",
            " 0.65714286 0.71428571 0.68571429 0.67647059 0.64705882 0.67647059\n",
            " 0.58823529 0.61764706 0.6        0.57142857 0.68571429 0.68571429\n",
            " 0.57142857 0.64705882 0.73529412 0.61764706 0.67647059 0.55882353\n",
            " 0.74285714 0.6        0.6        0.65714286 0.57142857 0.73529412\n",
            " 0.64705882 0.67647059 0.61764706 0.67647059]\n",
            "Accuracy: 63.92% (4.85%)\n",
            "------------------------------\n",
            "--------- CatBoost on Liver Dataset ---------\n",
            "[0.77142857 0.77142857 0.65714286 0.68571429 0.68571429 0.70588235\n",
            " 0.64705882 0.58823529 0.61764706 0.64705882 0.71428571 0.68571429\n",
            " 0.62857143 0.8        0.68571429 0.67647059 0.67647059 0.61764706\n",
            " 0.64705882 0.73529412 0.65714286 0.65714286 0.68571429 0.6\n",
            " 0.82857143 0.61764706 0.70588235 0.61764706 0.76470588 0.67647059\n",
            " 0.68571429 0.68571429 0.68571429 0.82857143 0.68571429 0.67647059\n",
            " 0.52941176 0.70588235 0.70588235 0.61764706 0.62857143 0.65714286\n",
            " 0.62857143 0.62857143 0.77142857 0.82352941 0.58823529 0.73529412\n",
            " 0.55882353 0.73529412 0.71428571 0.74285714 0.68571429 0.62857143\n",
            " 0.68571429 0.67647059 0.73529412 0.67647059 0.76470588 0.61764706\n",
            " 0.71428571 0.77142857 0.62857143 0.62857143 0.65714286 0.64705882\n",
            " 0.58823529 0.79411765 0.73529412 0.64705882 0.74285714 0.65714286\n",
            " 0.74285714 0.71428571 0.71428571 0.70588235 0.67647059 0.64705882\n",
            " 0.55882353 0.64705882 0.65714286 0.71428571 0.68571429 0.74285714\n",
            " 0.65714286 0.73529412 0.79411765 0.61764706 0.73529412 0.58823529\n",
            " 0.65714286 0.65714286 0.68571429 0.65714286 0.68571429 0.73529412\n",
            " 0.64705882 0.76470588 0.67647059 0.67647059]\n",
            "Accuracy: 68.33% (6.02%)\n",
            "------------------------------\n",
            "--------- LightGBM on Liver Dataset ---------\n",
            "[0.62857143 0.65714286 0.6        0.57142857 0.68571429 0.52941176\n",
            " 0.58823529 0.47058824 0.58823529 0.67647059 0.62857143 0.68571429\n",
            " 0.54285714 0.71428571 0.62857143 0.73529412 0.61764706 0.44117647\n",
            " 0.52941176 0.64705882 0.68571429 0.6        0.54285714 0.45714286\n",
            " 0.74285714 0.64705882 0.61764706 0.5        0.64705882 0.61764706\n",
            " 0.6        0.6        0.54285714 0.77142857 0.65714286 0.58823529\n",
            " 0.44117647 0.70588235 0.76470588 0.47058824 0.42857143 0.6\n",
            " 0.51428571 0.51428571 0.62857143 0.76470588 0.5        0.52941176\n",
            " 0.61764706 0.73529412 0.6        0.62857143 0.65714286 0.54285714\n",
            " 0.6        0.64705882 0.70588235 0.61764706 0.58823529 0.55882353\n",
            " 0.54285714 0.57142857 0.57142857 0.65714286 0.57142857 0.70588235\n",
            " 0.61764706 0.73529412 0.61764706 0.58823529 0.62857143 0.6\n",
            " 0.65714286 0.6        0.6        0.70588235 0.52941176 0.55882353\n",
            " 0.58823529 0.58823529 0.62857143 0.62857143 0.65714286 0.65714286\n",
            " 0.6        0.70588235 0.64705882 0.58823529 0.52941176 0.5\n",
            " 0.65714286 0.57142857 0.54285714 0.65714286 0.57142857 0.67647059\n",
            " 0.55882353 0.61764706 0.58823529 0.55882353]\n",
            "Accuracy: 60.72% (7.36%)\n",
            "------------------------------\n",
            "--------- XGBoost on Liver Dataset ---------\n",
            "[0.8        0.8        0.6        0.74285714 0.68571429 0.79411765\n",
            " 0.70588235 0.70588235 0.64705882 0.70588235 0.74285714 0.68571429\n",
            " 0.62857143 0.8        0.8        0.67647059 0.76470588 0.61764706\n",
            " 0.64705882 0.70588235 0.68571429 0.65714286 0.71428571 0.62857143\n",
            " 0.77142857 0.70588235 0.73529412 0.58823529 0.67647059 0.70588235\n",
            " 0.74285714 0.77142857 0.65714286 0.88571429 0.71428571 0.70588235\n",
            " 0.55882353 0.76470588 0.70588235 0.61764706 0.68571429 0.74285714\n",
            " 0.65714286 0.68571429 0.71428571 0.79411765 0.64705882 0.73529412\n",
            " 0.70588235 0.73529412 0.71428571 0.71428571 0.74285714 0.62857143\n",
            " 0.65714286 0.70588235 0.82352941 0.67647059 0.76470588 0.67647059\n",
            " 0.68571429 0.77142857 0.65714286 0.68571429 0.65714286 0.64705882\n",
            " 0.64705882 0.85294118 0.79411765 0.61764706 0.74285714 0.68571429\n",
            " 0.77142857 0.74285714 0.74285714 0.73529412 0.73529412 0.70588235\n",
            " 0.58823529 0.58823529 0.74285714 0.71428571 0.74285714 0.71428571\n",
            " 0.65714286 0.70588235 0.76470588 0.64705882 0.76470588 0.61764706\n",
            " 0.74285714 0.68571429 0.68571429 0.65714286 0.57142857 0.82352941\n",
            " 0.67647059 0.70588235 0.73529412 0.70588235]\n",
            "Accuracy: 70.57% (6.21%)\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "liver_scores = []\n",
        "liver_mean = []\n",
        "liver_std = []\n",
        "model_names = []\n",
        "\n",
        "for algorithm_name in names:\n",
        "    if algorithm_name == 'AdaBoost':\n",
        "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
        "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
        "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
        "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
        "\n",
        "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
        "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                random_state=42)    \n",
        "\n",
        "    if algorithm_name == 'GradBoost':\n",
        "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
        "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
        "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
        "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
        "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
        "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
        "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
        "                                        random_state=42)\n",
        "         \n",
        "    if algorithm_name == 'CatBoost':\n",
        "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
        "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
        "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                                silent=True,\n",
        "                                random_state=42)                        \n",
        "        \n",
        "    if algorithm_name == 'LightGBM':\n",
        "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
        "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
        "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
        "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=-1,\n",
        "                            random_state=42)\n",
        "               \n",
        "    if algorithm_name == 'XGBoost':\n",
        "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
        "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
        "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
        "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
        "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
        "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
        "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
        "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
        "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
        "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
        "                            verbosity=0,\n",
        "                            random_state=42)\n",
        "        \n",
        "    results = cross_val_score(clf, X, y, cv=rskf)\n",
        "    liver_scores.append(results)\n",
        "    liver_mean.append(results.mean()*100)\n",
        "    liver_std.append(results.std()*100)\n",
        "    model_names.append(algorithm_name)\n",
        "    print(f'--------- {algorithm_name} on Liver Dataset ---------')\n",
        "    print(results)\n",
        "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# algorithm comparison\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison between different Liver scores')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ylim(0.3, 1)\n",
        "plt.boxplot(liver_scores, showmeans=True)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "Algo_results['Liver'] = liver_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Wine</th>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <th>Sonar</th>\n",
              "      <th>Ionosphere</th>\n",
              "      <th>TicTacToe</th>\n",
              "      <th>Bupa</th>\n",
              "      <th>Pima</th>\n",
              "      <th>Heart</th>\n",
              "      <th>Liver</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>96.552288</td>\n",
              "      <td>97.159847</td>\n",
              "      <td>86.347619</td>\n",
              "      <td>93.815873</td>\n",
              "      <td>81.054167</td>\n",
              "      <td>71.669748</td>\n",
              "      <td>76.101504</td>\n",
              "      <td>83.592593</td>\n",
              "      <td>72.778151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GradBoost</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>90.854762</td>\n",
              "      <td>82.224232</td>\n",
              "      <td>69.783193</td>\n",
              "      <td>76.426863</td>\n",
              "      <td>83.703704</td>\n",
              "      <td>63.923529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>93.815079</td>\n",
              "      <td>72.318311</td>\n",
              "      <td>69.846218</td>\n",
              "      <td>75.527683</td>\n",
              "      <td>83.740741</td>\n",
              "      <td>68.334454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>92.849206</td>\n",
              "      <td>61.814474</td>\n",
              "      <td>69.794118</td>\n",
              "      <td>75.920711</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>60.722689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>97.797386</td>\n",
              "      <td>96.792626</td>\n",
              "      <td>83.802381</td>\n",
              "      <td>92.960317</td>\n",
              "      <td>65.721053</td>\n",
              "      <td>74.475630</td>\n",
              "      <td>75.334074</td>\n",
              "      <td>84.444444</td>\n",
              "      <td>70.573109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Names       Wine  Breast_Cancer      Sonar  Ionosphere  TicTacToe  \\\n",
              "0   AdaBoost  96.552288      97.159847  86.347619   93.815873  81.054167   \n",
              "1  GradBoost  98.075163      96.646633  78.145238   90.854762  82.224232   \n",
              "2   CatBoost  97.967320      97.378303  87.076190   93.815079  72.318311   \n",
              "3   LightGBM  97.120915      97.334612  82.361905   92.849206  61.814474   \n",
              "4    XGBoost  97.797386      96.792626  83.802381   92.960317  65.721053   \n",
              "\n",
              "        Bupa       Pima      Heart      Liver  \n",
              "0  71.669748  76.101504  83.592593  72.778151  \n",
              "1  69.783193  76.426863  83.703704  63.923529  \n",
              "2  69.846218  75.527683  83.740741  68.334454  \n",
              "3  69.794118  75.920711  44.444444  60.722689  \n",
              "4  74.475630  75.334074  84.444444  70.573109  "
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Algo_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [],
      "source": [
        "Tuned_Algo_results_tr = Algo_results.set_index('Names').T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "Tuned_Algo_results_tr.to_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Algo_Results\\TunedAlgoResults.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Names</th>\n",
              "      <th>AdaBoost</th>\n",
              "      <th>GradBoost</th>\n",
              "      <th>CatBoost</th>\n",
              "      <th>LightGBM</th>\n",
              "      <th>XGBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Wine</th>\n",
              "      <td>96.552288</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.797386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Breast_Cancer</th>\n",
              "      <td>97.159847</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>96.792626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sonar</th>\n",
              "      <td>86.347619</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>83.802381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ionosphere</th>\n",
              "      <td>93.815873</td>\n",
              "      <td>90.854762</td>\n",
              "      <td>93.815079</td>\n",
              "      <td>92.849206</td>\n",
              "      <td>92.960317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TicTacToe</th>\n",
              "      <td>81.054167</td>\n",
              "      <td>82.224232</td>\n",
              "      <td>72.318311</td>\n",
              "      <td>61.814474</td>\n",
              "      <td>65.721053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bupa</th>\n",
              "      <td>71.669748</td>\n",
              "      <td>69.783193</td>\n",
              "      <td>69.846218</td>\n",
              "      <td>69.794118</td>\n",
              "      <td>74.475630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pima</th>\n",
              "      <td>76.101504</td>\n",
              "      <td>76.426863</td>\n",
              "      <td>75.527683</td>\n",
              "      <td>75.920711</td>\n",
              "      <td>75.334074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heart</th>\n",
              "      <td>83.592593</td>\n",
              "      <td>83.703704</td>\n",
              "      <td>83.740741</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>84.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Liver</th>\n",
              "      <td>72.778151</td>\n",
              "      <td>63.923529</td>\n",
              "      <td>68.334454</td>\n",
              "      <td>60.722689</td>\n",
              "      <td>70.573109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Names           AdaBoost  GradBoost   CatBoost   LightGBM    XGBoost\n",
              "Wine           96.552288  98.075163  97.967320  97.120915  97.797386\n",
              "Breast_Cancer  97.159847  96.646633  97.378303  97.334612  96.792626\n",
              "Sonar          86.347619  78.145238  87.076190  82.361905  83.802381\n",
              "Ionosphere     93.815873  90.854762  93.815079  92.849206  92.960317\n",
              "TicTacToe      81.054167  82.224232  72.318311  61.814474  65.721053\n",
              "Bupa           71.669748  69.783193  69.846218  69.794118  74.475630\n",
              "Pima           76.101504  76.426863  75.527683  75.920711  75.334074\n",
              "Heart          83.592593  83.703704  83.740741  44.444444  84.444444\n",
              "Liver          72.778151  63.923529  68.334454  60.722689  70.573109"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Tuned_Algo_results_tr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Friedman's Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-posthocs\n",
            "  Downloading scikit_posthocs-0.7.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from scikit-posthocs) (1.25.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from scikit-posthocs) (1.11.2)\n",
            "Collecting statsmodels (from scikit-posthocs)\n",
            "  Downloading statsmodels-0.14.0-cp39-cp39-win_amd64.whl (9.4 MB)\n",
            "     ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.1/9.4 MB 2.8 MB/s eta 0:00:04\n",
            "     -- ------------------------------------- 0.6/9.4 MB 7.1 MB/s eta 0:00:02\n",
            "     ---- ----------------------------------- 1.0/9.4 MB 8.3 MB/s eta 0:00:02\n",
            "     ---- ----------------------------------- 1.0/9.4 MB 8.3 MB/s eta 0:00:02\n",
            "     ---- ----------------------------------- 1.0/9.4 MB 8.3 MB/s eta 0:00:02\n",
            "     --------- ------------------------------ 2.2/9.4 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 4.2/9.4 MB 13.3 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 4.2/9.4 MB 13.3 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 5.4/9.4 MB 13.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 8.9/9.4 MB 19.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 9.4/9.4 MB 19.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from scikit-posthocs) (2.1.0)\n",
            "Requirement already satisfied: seaborn in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from scikit-posthocs) (0.12.2)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from scikit-posthocs) (3.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from matplotlib->scikit-posthocs) (6.0.1)\n",
            "Collecting patsy>=0.5.2 (from statsmodels->scikit-posthocs)\n",
            "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->scikit-posthocs) (3.16.2)\n",
            "Requirement already satisfied: six in c:\\users\\erikc\\anaconda3\\envs\\algocomparison\\lib\\site-packages (from patsy>=0.5.2->statsmodels->scikit-posthocs) (1.16.0)\n",
            "Installing collected packages: patsy, statsmodels, scikit-posthocs\n",
            "Successfully installed patsy-0.5.3 scikit-posthocs-0.7.0 statsmodels-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-posthocs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scikit_posthocs as sp\n",
        "from scipy.stats import friedmanchisquare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [],
      "source": [
        "Tuned_Algo_results_tr = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Algo_Results\\TunedAlgoResults.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AdaBoost</th>\n",
              "      <th>GradBoost</th>\n",
              "      <th>CatBoost</th>\n",
              "      <th>LightGBM</th>\n",
              "      <th>XGBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.552288</td>\n",
              "      <td>98.075163</td>\n",
              "      <td>97.967320</td>\n",
              "      <td>97.120915</td>\n",
              "      <td>97.797386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>97.159847</td>\n",
              "      <td>96.646633</td>\n",
              "      <td>97.378303</td>\n",
              "      <td>97.334612</td>\n",
              "      <td>96.792626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86.347619</td>\n",
              "      <td>78.145238</td>\n",
              "      <td>87.076190</td>\n",
              "      <td>82.361905</td>\n",
              "      <td>83.802381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>93.815873</td>\n",
              "      <td>90.854762</td>\n",
              "      <td>93.815079</td>\n",
              "      <td>92.849206</td>\n",
              "      <td>92.960317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>81.054167</td>\n",
              "      <td>82.224232</td>\n",
              "      <td>72.318311</td>\n",
              "      <td>61.814474</td>\n",
              "      <td>65.721053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>71.669748</td>\n",
              "      <td>69.783193</td>\n",
              "      <td>69.846218</td>\n",
              "      <td>69.794118</td>\n",
              "      <td>74.475630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>76.101504</td>\n",
              "      <td>76.426863</td>\n",
              "      <td>75.527683</td>\n",
              "      <td>75.920711</td>\n",
              "      <td>75.334074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>83.592593</td>\n",
              "      <td>83.703704</td>\n",
              "      <td>83.740741</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>84.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>72.778151</td>\n",
              "      <td>63.923529</td>\n",
              "      <td>68.334454</td>\n",
              "      <td>60.722689</td>\n",
              "      <td>70.573109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    AdaBoost  GradBoost   CatBoost   LightGBM    XGBoost\n",
              "0  96.552288  98.075163  97.967320  97.120915  97.797386\n",
              "1  97.159847  96.646633  97.378303  97.334612  96.792626\n",
              "2  86.347619  78.145238  87.076190  82.361905  83.802381\n",
              "3  93.815873  90.854762  93.815079  92.849206  92.960317\n",
              "4  81.054167  82.224232  72.318311  61.814474  65.721053\n",
              "5  71.669748  69.783193  69.846218  69.794118  74.475630\n",
              "6  76.101504  76.426863  75.527683  75.920711  75.334074\n",
              "7  83.592593  83.703704  83.740741  44.444444  84.444444\n",
              "8  72.778151  63.923529  68.334454  60.722689  70.573109"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Tuned_Algo_results_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [],
      "source": [
        "stat, p_value = friedmanchisquare(Tuned_Algo_results_tr['AdaBoost'], Tuned_Algo_results_tr['GradBoost'], Tuned_Algo_results_tr['CatBoost'], Tuned_Algo_results_tr['LightGBM'], Tuned_Algo_results_tr['XGBoost'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.149383786120395"
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are no significant differences among the models.\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print('There are significant differences among the models.')\n",
        "else:\n",
        "    print('There are no significant differences among the models.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Nemenyi test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "nemenyi_results = sp.posthoc_nemenyi_friedman(a=Tuned_Algo_results_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AdaBoost</th>\n",
              "      <th>GradBoost</th>\n",
              "      <th>CatBoost</th>\n",
              "      <th>LightGBM</th>\n",
              "      <th>XGBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.728536</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.225673</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradBoost</th>\n",
              "      <td>0.728536</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.643932</td>\n",
              "      <td>0.897740</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.643932</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.166548</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.225673</td>\n",
              "      <td>0.897740</td>\n",
              "      <td>0.166548</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.559331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.559331</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           AdaBoost  GradBoost  CatBoost  LightGBM   XGBoost\n",
              "AdaBoost   1.000000   0.728536  0.900000  0.225673  0.900000\n",
              "GradBoost  0.728536   1.000000  0.643932  0.897740  0.900000\n",
              "CatBoost   0.900000   0.643932  1.000000  0.166548  0.900000\n",
              "LightGBM   0.225673   0.897740  0.166548  1.000000  0.559331\n",
              "XGBoost    0.900000   0.900000  0.900000  0.559331  1.000000"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nemenyi_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models 1 and 2 are not significantly different (p-value = 0.7285).\n",
            "Models 1 and 3 are not significantly different (p-value = 0.9000).\n",
            "Models 1 and 4 are not significantly different (p-value = 0.2257).\n",
            "Models 1 and 5 are not significantly different (p-value = 0.9000).\n",
            "Models 2 and 3 are not significantly different (p-value = 0.6439).\n",
            "Models 2 and 4 are not significantly different (p-value = 0.8977).\n",
            "Models 2 and 5 are not significantly different (p-value = 0.9000).\n",
            "Models 3 and 4 are not significantly different (p-value = 0.1665).\n",
            "Models 3 and 5 are not significantly different (p-value = 0.9000).\n",
            "Models 4 and 5 are not significantly different (p-value = 0.5593).\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.05\n",
        "\n",
        "# Print p-values for all pairs of models\n",
        "for i in range(nemenyi_results.shape[0]):\n",
        "    for j in range(i + 1, nemenyi_results.shape[1]):\n",
        "        model1 = i + 1\n",
        "        model2 = j + 1\n",
        "        p_value = nemenyi_results.iloc[i, j]\n",
        "\n",
        "        if p_value < alpha:\n",
        "            print(f\"Models {model1} and {model2} are significantly different (p-value = {p_value:.4f}).\")\n",
        "        else:\n",
        "            print(f\"Models {model1} and {model2} are not significantly different (p-value = {p_value:.4f}).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Comparison between the balanced and unbalanced dataset algorithm performance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unbalanced_df = pd.read_csv('/content/drive/MyDrive/DatasetSeminario/Algo_results/AlgoResults.csv')\n",
        "# balanced_df = pd.read_csv('/content/drive/MyDrive/DatasetSeminario/Algo_results/StratAlgoResults.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(unbalanced_df.shape)\n",
        "# print(balanced_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [],
      "source": [
        "# datasets = ['Wine', 'Breast Cancer', 'Sonar', 'Ionosphere', 'TicTacToe', 'Bupa', 'Pima', 'Heart', 'Liver']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i, name in enumerate(datasets):\n",
        "#   # Creating two lists of paired data\n",
        "#   before = unbalanced_df.iloc[i, :]\n",
        "#   after = balanced_df.iloc[i, :]\n",
        "\n",
        "#   # Performing the Wilcoxon signed-rank test\n",
        "#   statistic, p_value = stats.wilcoxon(before, after)\n",
        "\n",
        "#   print (f'Comparison between {name} models results')\n",
        "\n",
        "#   # Printing the test statistic and p-value\n",
        "#   print(f\"Test Statistic: {statistic}\")\n",
        "#   print(f\"P-value: {p_value}\")\n",
        "\n",
        "#   # Interpreting the results\n",
        "#   alpha = 0.05\n",
        "#   if p_value < alpha:\n",
        "#       print(f'Reject the null hypothesis: There is a significant difference between {name} models.')\n",
        "#   else:\n",
        "#       print(f'Fail to reject the null hypothesis: There is no significant difference between {name} models.')\n",
        "#   print ('- - - - - - - - - - - - - - - - - - - - -')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMVO8koMTTTdYQJS3YoNuih",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
