{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT8RkV+XlWgDxsIqRlz+WV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RochaErik/AlgorithmComparison/blob/main/AlgorithmComparison3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Ovui6IygCKFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparison between the balanced and unbalanced dataset algorithm performance**"
      ],
      "metadata": {
        "id": "Kq1yJ3_wCN2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "IdOfaVtTCOjx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnwsW6x9w1QO",
        "outputId": "fad3ad0d-f838-4cfe-e95c-f8295d5fd365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.1-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.1\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install lightgbm\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp9bGvxdqiOw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import scipy.stats as stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unbalanced_df = pd.read_csv('/content/drive/MyDrive/DatasetSeminario/Algo_results/AlgoResults.csv')\n",
        "balanced_df = pd.read_csv('/content/drive/MyDrive/DatasetSeminario/Algo_results/StratAlgoResults.csv')"
      ],
      "metadata": {
        "id": "QlpvMAw8CLjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unbalanced_df.shape)\n",
        "print(balanced_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L_gd_NGU0Vk",
        "outputId": "38730e0f-c197-4a7a-caa1-03ff7996fd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 5)\n",
            "(9, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['Wine', 'Breast Cancer', 'Sonar', 'Ionosphere', 'TicTacToe', 'Bupa', 'Pima', 'Heart', 'Liver']"
      ],
      "metadata": {
        "id": "0fCzOZ6DXSa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, name in enumerate(datasets):\n",
        "  # Creating two lists of paired data\n",
        "  before = unbalanced_df.iloc[i, :]\n",
        "  after = balanced_df.iloc[i, :]\n",
        "\n",
        "  # Performing the Wilcoxon signed-rank test\n",
        "  statistic, p_value = stats.wilcoxon(before, after)\n",
        "\n",
        "  print (f'Comparison between {name} models results')\n",
        "\n",
        "  # Printing the test statistic and p-value\n",
        "  print(f\"Test Statistic: {statistic}\")\n",
        "  print(f\"P-value: {p_value}\")\n",
        "\n",
        "  # Interpreting the results\n",
        "  alpha = 0.05\n",
        "  if p_value < alpha:\n",
        "      print(f'Reject the null hypothesis: There is a significant difference between {name} models.')\n",
        "  else:\n",
        "      print(f'Fail to reject the null hypothesis: There is no significant difference between {name} models.')\n",
        "  print ('- - - - - - - - - - - - - - - - - - - - -')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw0BH8LqWjzX",
        "outputId": "256714d8-b068-4304-8d9f-9e987c1b4756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison between Wine models results\n",
            "Test Statistic: 7.0\n",
            "P-value: 1.0\n",
            "Fail to reject the null hypothesis: There is no significant difference between Wine models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Breast Cancer models results\n",
            "Test Statistic: 6.0\n",
            "P-value: 0.8125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Breast Cancer models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Sonar models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Sonar models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Ionosphere models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Ionosphere models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between TicTacToe models results\n",
            "Test Statistic: 3.0\n",
            "P-value: 0.3125\n",
            "Fail to reject the null hypothesis: There is no significant difference between TicTacToe models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Bupa models results\n",
            "Test Statistic: 0.0\n",
            "P-value: 0.0625\n",
            "Fail to reject the null hypothesis: There is no significant difference between Bupa models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Pima models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Pima models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Heart models results\n",
            "Test Statistic: 1.0\n",
            "P-value: 0.125\n",
            "Fail to reject the null hypothesis: There is no significant difference between Heart models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n",
            "Comparison between Liver models results\n",
            "Test Statistic: 0.0\n",
            "P-value: 0.0625\n",
            "Fail to reject the null hypothesis: There is no significant difference between Liver models.\n",
            "- - - - - - - - - - - - - - - - - - - - -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-eemeaAaCsyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating algorithms with hyperparameter tuning**"
      ],
      "metadata": {
        "id": "O7sPV5hJCeJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "knwYV1QmCuEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB5jc4iDCWZI",
        "outputId": "a417925a-0c0b-4a02-e9a2-ca428226ab51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "pnmKn_fsDTha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Wine Dataset**"
      ],
      "metadata": {
        "id": "ByCnDDmkDayW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df = pd.read_csv('/content/drive/MyDrive/DatasetSeminario/Wine/wine.data', header=None)"
      ],
      "metadata": {
        "id": "23mGy-W6DZLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = wine_df.iloc[:, 1:]\n",
        "y = wine_df.iloc[:, 0]"
      ],
      "metadata": {
        "id": "C0N1S4LWDnbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "omlj8qxkDoM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bEtKdQvTEsAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hyperopt.pyll\n",
        "from hyperopt.pyll import scope\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "# def optimize_adaboost(params):\n",
        "#     clf = AdaBoostClassifier(**params)\n",
        "#     clf.fit(X_train, y_train)\n",
        "#     y_pred = clf.predict(X_test)\n",
        "#     return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_adaboost(params):\n",
        "    estimator_params = params['estimator']\n",
        "    estimator = DecisionTreeClassifier(**estimator_params)\n",
        "\n",
        "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_gradientboost(params):\n",
        "    clf = GradientBoostingClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_catboost(params):\n",
        "    clf = CatBoostClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_lightgbm(params):\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "def optimize_xgboost(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return -accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Define the hyperparameter search space for each algorithm\n",
        "\n",
        "# space_adaboost = {\n",
        "#     'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
        "#     'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "#     'estimator': {\n",
        "#         'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
        "#         'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
        "#         'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
        "#         'max_features': hp.choice('max_features', [None, 'sqrt', 'log2']),\n",
        "#     },\n",
        "#     'random_state': 42\n",
        "# }\n",
        "\n",
        "# space_gradientboost = {\n",
        "#     'n_estimators': hp.choice('n_estimators', range(50, 200)),\n",
        "#     'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
        "#     'max_depth': hp.choice('max_depth', range(1, 11)),\n",
        "# }\n",
        "\n",
        "# space_catboost = {\n",
        "#     'iterations': hp.choice('iterations', range(50, 200)),\n",
        "#     'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
        "#     'silent': True\n",
        "# }\n",
        "\n",
        "# space_lightgbm = {\n",
        "#     'n_estimators': hp.choice('n_estimators', range(50, 200)),\n",
        "#     'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
        "#     'max_depth': hp.choice('max_depth', range(1, 11)),\n",
        "#     'verbosity': -1\n",
        "# }\n",
        "\n",
        "space_lightgbm = {\n",
        "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
        "    'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss']),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 20, 200, 10)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# space_xgboost = {\n",
        "#     'n_estimators': hp.choice('n_estimators', range(50, 200)),\n",
        "#     'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
        "#     'max_depth': hp.choice('max_depth', range(1, 11)),\n",
        "# }\n",
        "\n",
        "# Define optimization functions and algorithm names\n",
        "optimizers = [\n",
        "    # (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
        "    # (optimize_gradientboost, space_gradientboost, 'Gradient Boosting'),\n",
        "    # (optimize_catboost, space_catboost, 'CatBoost'),\n",
        "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
        "    # (optimize_xgboost, space_xgboost, 'XGBoost'),\n",
        "]\n",
        "\n",
        "# Perform hyperparameter tuning for each algorithm\n",
        "for optimize_fn, space, algorithm_name in optimizers:\n",
        "    trials = Trials()\n",
        "    best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
        "\n",
        "    print(f\"Best hyperparameters for {algorithm_name}:\")\n",
        "    print(best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcZuN-z4CdXh",
        "outputId": "ee31c32a-6b6b-467e-f741-153da73f7c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 50/50 [00:03<00:00, 14.38trial/s, best loss: -1.0]\n",
            "Best hyperparameters for LightGBM:\n",
            "{'boosting_type': 1, 'class_weight': 0, 'colsample_by_tree': 0.7120419182084488, 'learning_rate': 0.06977031230342506, 'min_child_samples': 20.0, 'num_leaves': 60.0, 'reg_alpha': 0.8045671848719448, 'reg_lambda': 0.6867854908439323}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
      ],
      "metadata": {
        "id": "AiGBWUhXmjty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine_scores = []\n",
        "wine_scores_mean = []\n",
        "wine_scores_std = []\n",
        "model_names = []\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  results = cross_val_score(clf, X, y, cv=rskf)\n",
        "  wine_scores.append(results)\n",
        "  wine_scores_mean.append(results.mean()*100)\n",
        "  wine_scores_std.append(results.std()*100)\n",
        "  model_names.append(name)\n",
        "  print(f'--------- {name} on Wine Dataset ---------')\n",
        "  print(results)\n",
        "  print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
        "  print('------------------------------')"
      ],
      "metadata": {
        "id": "x7JQf94WmaZT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}