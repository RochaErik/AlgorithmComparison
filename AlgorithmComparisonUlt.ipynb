{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Splice-junction Gene Sequences (High-Dimensional Data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\Datasets2\\MolecularBiology\\dna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>A171</th>\n",
       "      <th>A172</th>\n",
       "      <th>A173</th>\n",
       "      <th>A174</th>\n",
       "      <th>A175</th>\n",
       "      <th>A176</th>\n",
       "      <th>A177</th>\n",
       "      <th>A178</th>\n",
       "      <th>A179</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A0  A1  A2  A3  A4  A5  A6  A7  A8  A9  ...  A171  A172  A173  A174  A175  \\\n",
       "0   0   1   0   0   0   0   1   0   0   0  ...     1     0     0     0     0   \n",
       "1   0   0   1   0   0   1   0   0   0   0  ...     0     0     0     1     0   \n",
       "2   0   0   1   0   0   1   0   1   0   0  ...     0     1     0     0     0   \n",
       "3   0   0   0   0   0   0   0   1   0   0  ...     0     0     1     0     0   \n",
       "4   0   1   0   0   0   0   0   1   0   0  ...     0     1     0     0     1   \n",
       "\n",
       "   A176  A177  A178  A179  class  \n",
       "0     1     1     0     0      3  \n",
       "1     0     0     1     0      3  \n",
       "2     1     0     0     1      3  \n",
       "3     1     0     0     1      1  \n",
       "4     0     1     0     0      2  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3186, 181)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dna_df.iloc[:, 0:-1]\n",
    "y = dna_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:17<00:00,  6.35s/trial, best loss: -0.9733542319749217]\n",
      "Best hyperparameters for AdaBoost:\n",
      "{'n_estimators': 1450.0, 'learning_rate': 0.010021975389469587, 'max_depth': 6.0, 'max_features': 'sqrt', 'min_samples_leaf': 5.0, 'min_samples_split': 4.0, 'random_state': 42}\n",
      "100%|██████████| 50/50 [08:34<00:00, 10.30s/trial, best loss: -0.9592476489028213]\n",
      "Best hyperparameters for GradBoost:\n",
      "{'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 850, 'learning_rate': 0.053611707225416305, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
      "100%|██████████| 50/50 [14:51<00:00, 17.83s/trial, best loss: -0.9639498432601881]\n",
      "Best hyperparameters for CatBoost:\n",
      "{'n_estimators': 550, 'learning_rate': 0.0479901225935416, 'min_child_samples': 1, 'max_depth': 6, 'reg_lambda': 3.3766279624518107, 'silent': True, 'random_state': 42}\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.10trial/s, best loss: -0.9639498432601881]\n",
      "Best hyperparameters for LightGBM:\n",
      "{'class_weight': 'balanced', 'boosting_type': 'gbdt', 'num_leaves': 55, 'learning_rate': 0.09578057421742088, 'min_child_samples': 160, 'reg_alpha': 1.325148207180948, 'reg_lambda': 1.5835889584699392, 'colsample_by_tree': 0.7698282950807432, 'verbosity': -1, 'random_state': 42}\n",
      "100%|██████████| 50/50 [02:39<00:00,  3.20s/trial, best loss: -0.9655172413793104]\n",
      "Best hyperparameters for XGBoost:\n",
      "{'booster': 'dart', 'learning_rate': 0.0970555552704317, 'gamma': 0, 'max_depth': 6, 'min_child_weight': 2, 'colsample_bytree': 0.8595368886902741, 'colsample_bylevel': 0.6403611592687698, 'colsample_bynode': 0.31242767744556366, 'reg_alpha': 0.4347613450196888, 'reg_lambda': 3.700875165239519, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt.pyll import scope\n",
    "import warnings\n",
    "\n",
    "# Filter out the FutureWarning related to is_sparse\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
    "\n",
    "best_hyperparams = {\n",
    "    'AdaBoost': {},\n",
    "    'GradBoost': {},\n",
    "    'CatBoost': {},\n",
    "    'LightGBM': {},\n",
    "    'XGBoost': {}\n",
    "}\n",
    "\n",
    "# Define the hyperparameter search space for each algorithm\n",
    "\n",
    "def optimize_adaboost(params):\n",
    "    estimator_params = params['estimator']\n",
    "    estimator = DecisionTreeClassifier(**estimator_params)\n",
    "\n",
    "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_gradientboost(params):\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_catboost(params):\n",
    "    clf = CatBoostClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_lightgbm(params):\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_xgboost(params):\n",
    "    clf = XGBClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Define the hyperparameter search space for each algorithm\n",
    "\n",
    "max_features_choices = [None, 'sqrt', 'log2']\n",
    "space_adaboost = {\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'estimator': {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
    "        'max_features': hp.choice('max_features', max_features_choices),\n",
    "    },\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "criterion_choices = ['friedman_mse', 'squared_error']\n",
    "max_features_choices = [None, 'sqrt', 'log2']\n",
    "space_gradientboost = {\n",
    "    'criterion': hp.choice('criterion', criterion_choices),\n",
    "    'max_features': hp.choice('max_features', max_features_choices),\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
    "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
    "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
    "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "space_catboost = {\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'silent': True\n",
    "}\n",
    "\n",
    "class_weight_choices = ['balanced']\n",
    "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
    "space_lightgbm = {\n",
    "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
    "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
    "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "booster_choices = ['gbtree', 'dart']\n",
    "space_xgboost = {\n",
    "    'booster': hp.choice('booster', booster_choices),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
    "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'verbosity': 0,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Define optimization functions and algorithm names\n",
    "optimizers = [\n",
    "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
    "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
    "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
    "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
    "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
    "]\n",
    "\n",
    "\n",
    "# Performing hyperparameter tuning for each algorithm\n",
    "\n",
    "rstate=np.random.default_rng(42)\n",
    "\n",
    "for optimize_fn, space, algorithm_name in optimizers:\n",
    "    if algorithm_name == 'AdaBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        max_features_label = max_features_choices[best['max_features']]\n",
    "\n",
    "        # Store the best AdaBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'n_estimators': best['n_estimators'],\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'max_depth': best['max_depth'],\n",
    "            'max_features': max_features_label,\n",
    "            'min_samples_leaf': best['min_samples_leaf'],\n",
    "            'min_samples_split': best['min_samples_split'],\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'GradBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "\n",
    "\n",
    "        # Map the choice labels        \n",
    "        criterion_label = criterion_choices[best['criterion']]\n",
    "        max_features_label = max_features_choices[best['max_features']]\n",
    "\n",
    "        # Store the best GradBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'criterion': criterion_label,\n",
    "            'max_features': max_features_label,\n",
    "            'n_estimators': int(best['n_estimators']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'min_samples_split': int(best['min_samples_split']),\n",
    "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
    "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
    "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
    "            'ccp_alpha': best['ccp_alpha'],\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])           \n",
    "    \n",
    "    if algorithm_name == 'CatBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Store the best CatBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'n_estimators': int(best['n_estimators']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'min_child_samples': int(best['min_child_samples']),\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'silent': True,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'LightGBM':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        class_weight_label = class_weight_choices[best['class_weight']]\n",
    "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
    "\n",
    "        # Store the best LightGBM hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'class_weight': class_weight_label,\n",
    "            'boosting_type': boosting_type_label,\n",
    "            'num_leaves': int(best['num_leaves']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'min_child_samples': int(best['min_child_samples']),\n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'colsample_by_tree': best['colsample_by_tree'],\n",
    "            'verbosity': -1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'XGBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        booster_label = booster_choices[best['booster']]        \n",
    " \n",
    "        # Store the best XGBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'booster': booster_label,\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'gamma': int(best['gamma']),\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'min_child_weight': int(best['min_child_weight']),\n",
    "            'colsample_bytree': best['colsample_bytree'],\n",
    "            'colsample_bylevel': best['colsample_bylevel'],\n",
    "            'colsample_bynode': best['colsample_bynode'],            \n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],            \n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1450.0,\n",
       " 'learning_rate': 0.010021975389469587,\n",
       " 'max_depth': 6.0,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 5.0,\n",
       " 'min_samples_split': 4.0,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams['AdaBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'max_features': None,\n",
       " 'n_estimators': 850,\n",
       " 'learning_rate': 0.053611707225416305,\n",
       " 'max_depth': 3,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_weight_fraction_leaf': 0.1,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams['GradBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 550,\n",
       " 'learning_rate': 0.0479901225935416,\n",
       " 'min_child_samples': 1,\n",
       " 'max_depth': 6,\n",
       " 'reg_lambda': 3.3766279624518107,\n",
       " 'silent': True,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams['CatBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'boosting_type': 'gbdt',\n",
       " 'num_leaves': 55,\n",
       " 'learning_rate': 0.09578057421742088,\n",
       " 'min_child_samples': 160,\n",
       " 'reg_alpha': 1.325148207180948,\n",
       " 'reg_lambda': 1.5835889584699392,\n",
       " 'colsample_by_tree': 0.7698282950807432,\n",
       " 'verbosity': -1,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams['LightGBM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'dart',\n",
       " 'learning_rate': 0.0970555552704317,\n",
       " 'gamma': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 2,\n",
       " 'colsample_bytree': 0.8595368886902741,\n",
       " 'colsample_bylevel': 0.6403611592687698,\n",
       " 'colsample_bynode': 0.31242767744556366,\n",
       " 'reg_alpha': 0.4347613450196888,\n",
       " 'reg_lambda': 3.700875165239519,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams['XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- AdaBoost on DNA Dataset ---------\n",
      "[0.95924765 0.97178683 0.94984326 0.96865204 0.95611285 0.96551724\n",
      " 0.96226415 0.97169811 0.94654088 0.96226415 0.94984326 0.96865204\n",
      " 0.95924765 0.98432602 0.93730408 0.96865204 0.97484277 0.98113208\n",
      " 0.94339623 0.97169811 0.95924765 0.95611285 0.96238245 0.94357367\n",
      " 0.95924765 0.95297806 0.94025157 0.98427673 0.96540881 0.97169811\n",
      " 0.95924765 0.96238245 0.96551724 0.94670846 0.98746082 0.95924765\n",
      " 0.95597484 0.97484277 0.9591195  0.96226415 0.96238245 0.95611285\n",
      " 0.94984326 0.98432602 0.96238245 0.96238245 0.95597484 0.96540881\n",
      " 0.95597484 0.9591195  0.96551724 0.95611285 0.96238245 0.95924765\n",
      " 0.96551724 0.96865204 0.96226415 0.96855346 0.96540881 0.96226415\n",
      " 0.96238245 0.96551724 0.94043887 0.96551724 0.96551724 0.96238245\n",
      " 0.96855346 0.97169811 0.97798742 0.95283019 0.96238245 0.96865204\n",
      " 0.94670846 0.95297806 0.96551724 0.97178683 0.9591195  0.94654088\n",
      " 0.97169811 0.96540881 0.96238245 0.97178683 0.95924765 0.97492163\n",
      " 0.95924765 0.95297806 0.96226415 0.96540881 0.97169811 0.95597484\n",
      " 0.95611285 0.95611285 0.95924765 0.95611285 0.96238245 0.97805643\n",
      " 0.95597484 0.96226415 0.96226415 0.96540881]\n",
      "Accuracy: 96.22% (0.97%)\n",
      "Execution Time: 877.85 seconds\n",
      "------------------------------\n",
      "--------- GradBoost on DNA Dataset ---------\n",
      "[0.96238245 0.96865204 0.94670846 0.97178683 0.96238245 0.96551724\n",
      " 0.96540881 0.96226415 0.94025157 0.9591195  0.94670846 0.96238245\n",
      " 0.96238245 0.97805643 0.92789969 0.96551724 0.98113208 0.96540881\n",
      " 0.94339623 0.9591195  0.95297806 0.96865204 0.97178683 0.95611285\n",
      " 0.96238245 0.94357367 0.96226415 0.97798742 0.96540881 0.96226415\n",
      " 0.95924765 0.95611285 0.96238245 0.94670846 0.98432602 0.95611285\n",
      " 0.9591195  0.98113208 0.94654088 0.94339623 0.96238245 0.95297806\n",
      " 0.95611285 0.97492163 0.96238245 0.97178683 0.96540881 0.95597484\n",
      " 0.9591195  0.96540881 0.95611285 0.95611285 0.95611285 0.94984326\n",
      " 0.95297806 0.96551724 0.95283019 0.97798742 0.9591195  0.96540881\n",
      " 0.96238245 0.96865204 0.94984326 0.96551724 0.94357367 0.95611285\n",
      " 0.96226415 0.97169811 0.96855346 0.94968553 0.95611285 0.94984326\n",
      " 0.94984326 0.96551724 0.96865204 0.94357367 0.96540881 0.9591195\n",
      " 0.97169811 0.97169811 0.96551724 0.96238245 0.95611285 0.96551724\n",
      " 0.96865204 0.96551724 0.95283019 0.96226415 0.97484277 0.94968553\n",
      " 0.95611285 0.95611285 0.96551724 0.95611285 0.96551724 0.97805643\n",
      " 0.95283019 0.96540881 0.9591195  0.96855346]\n",
      "Accuracy: 96.08% (0.99%)\n",
      "Execution Time: 2370.68 seconds\n",
      "------------------------------\n",
      "--------- CatBoost on DNA Dataset ---------\n",
      "[0.96551724 0.95924765 0.94043887 0.98119122 0.95297806 0.95297806\n",
      " 0.96540881 0.96855346 0.95283019 0.9591195  0.95611285 0.96865204\n",
      " 0.96865204 0.96865204 0.93103448 0.96551724 0.99056604 0.95597484\n",
      " 0.94025157 0.95283019 0.95924765 0.96551724 0.96238245 0.95924765\n",
      " 0.95924765 0.94043887 0.96226415 0.99056604 0.97169811 0.94654088\n",
      " 0.96551724 0.96238245 0.95297806 0.95297806 0.97805643 0.95924765\n",
      " 0.95597484 0.9591195  0.94339623 0.96226415 0.95924765 0.94984326\n",
      " 0.96238245 0.97492163 0.96551724 0.96865204 0.96226415 0.94654088\n",
      " 0.95283019 0.9591195  0.94984326 0.94670846 0.96865204 0.94357367\n",
      " 0.96551724 0.95924765 0.95597484 0.97169811 0.9591195  0.96540881\n",
      " 0.95924765 0.96238245 0.94670846 0.96865204 0.95611285 0.96238245\n",
      " 0.9591195  0.96540881 0.96540881 0.95283019 0.94984326 0.96551724\n",
      " 0.96238245 0.96865204 0.96551724 0.95924765 0.9591195  0.94339623\n",
      " 0.96226415 0.96540881 0.96551724 0.95611285 0.95611285 0.96865204\n",
      " 0.95611285 0.96238245 0.95283019 0.95597484 0.97798742 0.95283019\n",
      " 0.95611285 0.95297806 0.96238245 0.95297806 0.96865204 0.97805643\n",
      " 0.94025157 0.95283019 0.96226415 0.96855346]\n",
      "Accuracy: 95.99% (1.01%)\n",
      "Execution Time: 584.76 seconds\n",
      "------------------------------\n",
      "--------- LightGBM on DNA Dataset ---------\n",
      "[0.95924765 0.96238245 0.93416928 0.97805643 0.96238245 0.94357367\n",
      " 0.96855346 0.97169811 0.95283019 0.96226415 0.94984326 0.96865204\n",
      " 0.96238245 0.96551724 0.93103448 0.97178683 0.98427673 0.95597484\n",
      " 0.94654088 0.95283019 0.95611285 0.96865204 0.96238245 0.95611285\n",
      " 0.95924765 0.94357367 0.96855346 0.97798742 0.96226415 0.94968553\n",
      " 0.97178683 0.96238245 0.95611285 0.94357367 0.97805643 0.95924765\n",
      " 0.9591195  0.96540881 0.94654088 0.9591195  0.95924765 0.94984326\n",
      " 0.94984326 0.96865204 0.95297806 0.96865204 0.96226415 0.95283019\n",
      " 0.96226415 0.96540881 0.96238245 0.95297806 0.96238245 0.94670846\n",
      " 0.96238245 0.95924765 0.95597484 0.97169811 0.9591195  0.96226415\n",
      " 0.95297806 0.96238245 0.94357367 0.97178683 0.95611285 0.95611285\n",
      " 0.9591195  0.96855346 0.96855346 0.95597484 0.94984326 0.96865204\n",
      " 0.94357367 0.96865204 0.96551724 0.94984326 0.96540881 0.95283019\n",
      " 0.96540881 0.96540881 0.96238245 0.95611285 0.96551724 0.97178683\n",
      " 0.95297806 0.95611285 0.94654088 0.9591195  0.96855346 0.95283019\n",
      " 0.95297806 0.95297806 0.96865204 0.95297806 0.96551724 0.98746082\n",
      " 0.94339623 0.95283019 0.95597484 0.96226415]\n",
      "Accuracy: 95.95% (0.98%)\n",
      "Execution Time: 13.88 seconds\n",
      "------------------------------\n",
      "--------- XGBoost on DNA Dataset ---------\n",
      "[0.96865204 0.96238245 0.95297806 0.97805643 0.96238245 0.96551724\n",
      " 0.97484277 0.98113208 0.94339623 0.96540881 0.96238245 0.97178683\n",
      " 0.96238245 0.97178683 0.93416928 0.96865204 0.98742138 0.96540881\n",
      " 0.95283019 0.96540881 0.96865204 0.96865204 0.95924765 0.96238245\n",
      " 0.95924765 0.95297806 0.96226415 0.98113208 0.97169811 0.96540881\n",
      " 0.96551724 0.95611285 0.97178683 0.95297806 0.98746082 0.96238245\n",
      " 0.95283019 0.97484277 0.95283019 0.96540881 0.96238245 0.95924765\n",
      " 0.96551724 0.98432602 0.96865204 0.96551724 0.96855346 0.95283019\n",
      " 0.96226415 0.95597484 0.97178683 0.95611285 0.96551724 0.94984326\n",
      " 0.96551724 0.96865204 0.96855346 0.97169811 0.9591195  0.97484277\n",
      " 0.96238245 0.96551724 0.94984326 0.97492163 0.95297806 0.97492163\n",
      " 0.96226415 0.97169811 0.97484277 0.96540881 0.97178683 0.96551724\n",
      " 0.95924765 0.97492163 0.97178683 0.96238245 0.96855346 0.95597484\n",
      " 0.96540881 0.96855346 0.96865204 0.95611285 0.96238245 0.97805643\n",
      " 0.95924765 0.95924765 0.9591195  0.96540881 0.97798742 0.96226415\n",
      " 0.96238245 0.95924765 0.96551724 0.95924765 0.96865204 0.98746082\n",
      " 0.94968553 0.97798742 0.96226415 0.96540881]\n",
      "Accuracy: 96.51% (0.92%)\n",
      "Execution Time: 490.30 seconds\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "dna_scores = []\n",
    "dna_scores_mean = []\n",
    "dna_scores_std = []\n",
    "model_names = []\n",
    "execution_times = []\n",
    "\n",
    "for algorithm_name in names:\n",
    "    if algorithm_name == 'AdaBoost':\n",
    "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
    "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
    "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
    "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
    "\n",
    "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
    "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
    "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                random_state=42)    \n",
    "\n",
    "    if algorithm_name == 'GradBoost':\n",
    "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
    "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
    "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
    "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
    "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
    "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
    "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
    "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
    "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
    "                                        random_state=42)\n",
    "         \n",
    "    if algorithm_name == 'CatBoost':\n",
    "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
    "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
    "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
    "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                                silent=True,\n",
    "                                random_state=42)                        \n",
    "        \n",
    "    if algorithm_name == 'LightGBM':\n",
    "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
    "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
    "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
    "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
    "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
    "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
    "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                            verbosity=-1,\n",
    "                            random_state=42)\n",
    "               \n",
    "    if algorithm_name == 'XGBoost':\n",
    "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
    "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
    "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
    "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
    "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
    "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
    "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
    "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
    "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                            verbosity=0,\n",
    "                            random_state=42)\n",
    "        \n",
    "    start_time = time.time()    \n",
    "    results = cross_val_score(clf, X, y, cv=rskf)\n",
    "    end_time = time.time()\n",
    "    dna_scores.append(results)\n",
    "    dna_scores_mean.append(results.mean()*100)\n",
    "    dna_scores_std.append(results.std()*100)\n",
    "    model_names.append(algorithm_name)\n",
    "    execution_time = end_time - start_time  \n",
    "    execution_times.append(execution_time)\n",
    "\n",
    "    print(f'--------- {algorithm_name} on DNA Dataset ---------')\n",
    "    print(results)\n",
    "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
    "    print(f'Execution Time: {execution_time:.2f} seconds')\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# algorithm comparison\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison between different DNA scores')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ylim(0.3, 1)\n",
    "plt.boxplot(dna_scores, showmeans=True)\n",
    "ax.set_xticklabels(model_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_results = pd.DataFrame()\n",
    "Algo_ult_results['Names'] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_results['DNA'] = dna_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>DNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>96.224256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>96.079878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>95.991808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>95.954289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>96.512943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Names        DNA\n",
       "0   AdaBoost  96.224256\n",
       "1  GradBoost  96.079878\n",
       "2   CatBoost  95.991808\n",
       "3   LightGBM  95.954289\n",
       "4    XGBoost  96.512943"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Algo_ult_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_time_results = pd.DataFrame()\n",
    "Algo_ult_time_results['Names'] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_time_results['Wine'] = pd.Series(execution_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>877.854318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>2370.683348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>584.760997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>13.880130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>490.302212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Names         Wine\n",
       "0   AdaBoost   877.854318\n",
       "1  GradBoost  2370.683348\n",
       "2   CatBoost   584.760997\n",
       "3   LightGBM    13.880130\n",
       "4    XGBoost   490.302212"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Algo_ult_time_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tic-Tac-Toe Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tictactoe_df = pd.read_csv('E:\\Cursos\\MestradoCienciaComputação\\Seminario\\Datasets\\TicTacToe\\TicTacToe.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8         9\n",
       "0  x  x  x  x  o  o  x  o  o  positive\n",
       "1  x  x  x  x  o  o  o  x  o  positive\n",
       "2  x  x  x  x  o  o  o  o  x  positive\n",
       "3  x  x  x  x  o  o  o  b  b  positive\n",
       "4  x  x  x  x  o  o  b  o  b  positive"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tictactoe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies = {\n",
    "#             'x': 0,\n",
    "#             'o': 1,\n",
    "#             'b': 2,\n",
    "#           }\n",
    "# tictactoe_df = tictactoe_df.iloc[:, 0: 9].replace(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tictactoe_df.iloc[:, :-1]\n",
    "y = tictactoe_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since version 1.3.2 XGBoost needs target columns to start with 0 value\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:08<00:00,  1.38s/trial, best loss: -0.8125]            \n",
      "Best hyperparameters for AdaBoost:\n",
      "{'n_estimators': 1200.0, 'learning_rate': 0.06916005440000361, 'max_depth': 2.0, 'max_features': None, 'min_samples_leaf': 4.0, 'min_samples_split': 4.0, 'random_state': 42}\n",
      "100%|██████████| 50/50 [01:11<00:00,  1.43s/trial, best loss: -0.8177083333333334]\n",
      "Best hyperparameters for GradBoost:\n",
      "{'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 850, 'learning_rate': 0.09835742587463962, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
      "100%|██████████| 50/50 [00:37<00:00,  1.34trial/s, best loss: -0.71875]           \n",
      "Best hyperparameters for CatBoost:\n",
      "{'n_estimators': 1350, 'learning_rate': 0.052871577465477125, 'min_child_samples': 9, 'max_depth': 1, 'reg_lambda': 3.1381917920726017, 'silent': True, 'random_state': 42}\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.07trial/s, best loss: -0.6197916666666666]\n",
      "Best hyperparameters for LightGBM:\n",
      "{'class_weight': 'balanced', 'boosting_type': 'gbdt', 'num_leaves': 85, 'learning_rate': 0.08722980007927972, 'min_child_samples': 50, 'reg_alpha': 1.2108510802433148, 'reg_lambda': 0.47150609574550806, 'colsample_by_tree': 0.6838724853092855, 'verbosity': -1, 'random_state': 42}\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.25trial/s, best loss: -0.6458333333333334]\n",
      "Best hyperparameters for XGBoost:\n",
      "{'booster': 'gbtree', 'learning_rate': 0.0842954898912899, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.8901045127889909, 'colsample_bylevel': 0.3718676252172074, 'colsample_bynode': 0.8158357971054165, 'reg_alpha': 1.8194669780226551, 'reg_lambda': 2.2864326222504214, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt.pyll import scope\n",
    "import warnings\n",
    "\n",
    "# Filter out the FutureWarning related to is_sparse\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
    "\n",
    "best_hyperparams = {\n",
    "    'AdaBoost': {},\n",
    "    'GradBoost': {},\n",
    "    'CatBoost': {},\n",
    "    'LightGBM': {},\n",
    "    'XGBoost': {}\n",
    "}\n",
    "\n",
    "# Define the hyperparameter search space for each algorithm\n",
    "\n",
    "def optimize_adaboost(params):\n",
    "    estimator_params = params['estimator']\n",
    "    estimator = DecisionTreeClassifier(**estimator_params)\n",
    "\n",
    "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_gradientboost(params):\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_catboost(params):\n",
    "    clf = CatBoostClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_lightgbm(params):\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_xgboost(params):\n",
    "    clf = XGBClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Define the hyperparameter search space for each algorithm\n",
    "\n",
    "max_features_choices = [None, 'sqrt', 'log2']\n",
    "space_adaboost = {\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'estimator': {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
    "        'max_features': hp.choice('max_features', max_features_choices),\n",
    "    },\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "criterion_choices = ['friedman_mse', 'squared_error']\n",
    "max_features_choices = [None, 'sqrt', 'log2']\n",
    "space_gradientboost = {\n",
    "    'criterion': hp.choice('criterion', criterion_choices),\n",
    "    'max_features': hp.choice('max_features', max_features_choices),\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
    "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
    "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
    "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "space_catboost = {\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'silent': True\n",
    "}\n",
    "\n",
    "class_weight_choices = ['balanced']\n",
    "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
    "space_lightgbm = {\n",
    "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
    "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
    "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "booster_choices = ['gbtree', 'dart']\n",
    "space_xgboost = {\n",
    "    'booster': hp.choice('booster', booster_choices),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
    "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'verbosity': 0,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Define optimization functions and algorithm names\n",
    "optimizers = [\n",
    "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
    "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
    "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
    "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
    "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
    "]\n",
    "\n",
    "\n",
    "# Performing hyperparameter tuning for each algorithm\n",
    "\n",
    "rstate=np.random.default_rng(42)\n",
    "\n",
    "for optimize_fn, space, algorithm_name in optimizers:\n",
    "    if algorithm_name == 'AdaBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        max_features_label = max_features_choices[best['max_features']]\n",
    "\n",
    "        # Store the best AdaBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'n_estimators': best['n_estimators'],\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'max_depth': best['max_depth'],\n",
    "            'max_features': max_features_label,\n",
    "            'min_samples_leaf': best['min_samples_leaf'],\n",
    "            'min_samples_split': best['min_samples_split'],\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'GradBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "\n",
    "\n",
    "        # Map the choice labels        \n",
    "        criterion_label = criterion_choices[best['criterion']]\n",
    "        max_features_label = max_features_choices[best['max_features']]\n",
    "\n",
    "        # Store the best GradBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'criterion': criterion_label,\n",
    "            'max_features': max_features_label,\n",
    "            'n_estimators': int(best['n_estimators']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'min_samples_split': int(best['min_samples_split']),\n",
    "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
    "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
    "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
    "            'ccp_alpha': best['ccp_alpha'],\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])           \n",
    "    \n",
    "    if algorithm_name == 'CatBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Store the best CatBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'n_estimators': int(best['n_estimators']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'min_child_samples': int(best['min_child_samples']),\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'silent': True,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'LightGBM':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        class_weight_label = class_weight_choices[best['class_weight']]\n",
    "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
    "\n",
    "        # Store the best LightGBM hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'class_weight': class_weight_label,\n",
    "            'boosting_type': boosting_type_label,\n",
    "            'num_leaves': int(best['num_leaves']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'min_child_samples': int(best['min_child_samples']),\n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'colsample_by_tree': best['colsample_by_tree'],\n",
    "            'verbosity': -1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'XGBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        booster_label = booster_choices[best['booster']]        \n",
    " \n",
    "        # Store the best XGBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'booster': booster_label,\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'gamma': int(best['gamma']),\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'min_child_weight': int(best['min_child_weight']),\n",
    "            'colsample_bytree': best['colsample_bytree'],\n",
    "            'colsample_bylevel': best['colsample_bylevel'],\n",
    "            'colsample_bynode': best['colsample_bynode'],            \n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],            \n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- AdaBoost on TicTacToe Dataset ---------\n",
      "[0.875      0.88541667 0.77083333 0.82291667 0.875      0.73958333\n",
      " 0.84375    0.79166667 0.84210526 0.78947368 0.79166667 0.8125\n",
      " 0.76041667 0.84375    0.78125    0.8125     0.8125     0.85416667\n",
      " 0.78947368 0.82105263 0.83333333 0.78125    0.75       0.85416667\n",
      " 0.90625    0.80208333 0.89583333 0.79166667 0.83157895 0.8\n",
      " 0.80208333 0.84375    0.85416667 0.84375    0.76041667 0.77083333\n",
      " 0.79166667 0.77083333 0.87368421 0.77894737 0.80208333 0.79166667\n",
      " 0.76041667 0.73958333 0.75       0.78125    0.875      0.83333333\n",
      " 0.83157895 0.86315789 0.80208333 0.80208333 0.80208333 0.80208333\n",
      " 0.8125     0.80208333 0.82291667 0.82291667 0.78947368 0.81052632\n",
      " 0.85416667 0.80208333 0.83333333 0.75       0.80208333 0.88541667\n",
      " 0.77083333 0.78125    0.78947368 0.78947368 0.80208333 0.80208333\n",
      " 0.73958333 0.79166667 0.85416667 0.84375    0.84375    0.75\n",
      " 0.8        0.85263158 0.72916667 0.84375    0.79166667 0.84375\n",
      " 0.8125     0.92708333 0.82291667 0.78125    0.72631579 0.81052632\n",
      " 0.8125     0.70833333 0.80208333 0.86458333 0.83333333 0.86458333\n",
      " 0.75       0.83333333 0.8        0.81052632]\n",
      "Accuracy: 81.05% (4.18%)\n",
      "Execution Time: 180.59 seconds\n",
      "------------------------------\n",
      "--------- GradBoost on TicTacToe Dataset ---------\n",
      "[0.875      0.83333333 0.79166667 0.82291667 0.8125     0.77083333\n",
      " 0.89583333 0.79166667 0.78947368 0.78947368 0.8125     0.79166667\n",
      " 0.80208333 0.84375    0.82291667 0.83333333 0.82291667 0.84375\n",
      " 0.83157895 0.84210526 0.86458333 0.82291667 0.78125    0.8125\n",
      " 0.875      0.79166667 0.88541667 0.78125    0.84210526 0.84210526\n",
      " 0.84375    0.84375    0.82291667 0.85416667 0.79166667 0.875\n",
      " 0.8125     0.77083333 0.86315789 0.85263158 0.85416667 0.83333333\n",
      " 0.82291667 0.79166667 0.78125    0.77083333 0.86458333 0.82291667\n",
      " 0.84210526 0.87368421 0.84375    0.80208333 0.83333333 0.79166667\n",
      " 0.80208333 0.79166667 0.8125     0.8125     0.78947368 0.86315789\n",
      " 0.8125     0.83333333 0.83333333 0.79166667 0.76041667 0.83333333\n",
      " 0.76041667 0.85416667 0.77894737 0.81052632 0.8125     0.80208333\n",
      " 0.83333333 0.83333333 0.86458333 0.82291667 0.84375    0.76041667\n",
      " 0.83157895 0.82105263 0.76041667 0.84375    0.83333333 0.80208333\n",
      " 0.8125     0.86458333 0.85416667 0.83333333 0.8        0.81052632\n",
      " 0.85416667 0.79166667 0.84375    0.86458333 0.84375    0.80208333\n",
      " 0.78125    0.83333333 0.83157895 0.82105263]\n",
      "Accuracy: 82.22% (3.08%)\n",
      "Execution Time: 218.21 seconds\n",
      "------------------------------\n",
      "--------- CatBoost on TicTacToe Dataset ---------\n",
      "[0.77083333 0.73958333 0.71875    0.71875    0.69791667 0.72916667\n",
      " 0.72916667 0.71875    0.69473684 0.72631579 0.75       0.73958333\n",
      " 0.71875    0.6875     0.71875    0.72916667 0.66666667 0.73958333\n",
      " 0.75789474 0.71578947 0.77083333 0.70833333 0.67708333 0.71875\n",
      " 0.71875    0.71875    0.71875    0.6875     0.74736842 0.72631579\n",
      " 0.78125    0.72916667 0.75       0.72916667 0.6875     0.72916667\n",
      " 0.69791667 0.70833333 0.75789474 0.70526316 0.6875     0.71875\n",
      " 0.75       0.73958333 0.6875     0.72916667 0.71875    0.72916667\n",
      " 0.72631579 0.74736842 0.72916667 0.75       0.67708333 0.75\n",
      " 0.73958333 0.67708333 0.70833333 0.75       0.74736842 0.72631579\n",
      " 0.71875    0.69791667 0.76041667 0.73958333 0.70833333 0.72916667\n",
      " 0.70833333 0.6875     0.72631579 0.72631579 0.73958333 0.71875\n",
      " 0.70833333 0.72916667 0.67708333 0.72916667 0.71875    0.77083333\n",
      " 0.72631579 0.73684211 0.69791667 0.72916667 0.70833333 0.73958333\n",
      " 0.69791667 0.73958333 0.72916667 0.73958333 0.71578947 0.69473684\n",
      " 0.69791667 0.69791667 0.75       0.69791667 0.73958333 0.70833333\n",
      " 0.73958333 0.76041667 0.70526316 0.74736842]\n",
      "Accuracy: 72.32% (2.36%)\n",
      "Execution Time: 66.16 seconds\n",
      "------------------------------\n",
      "--------- LightGBM on TicTacToe Dataset ---------\n",
      "[0.72916667 0.70833333 0.65625    0.57291667 0.67708333 0.52083333\n",
      " 0.64583333 0.64583333 0.61052632 0.61052632 0.58333333 0.61458333\n",
      " 0.59375    0.63541667 0.57291667 0.6875     0.57291667 0.60416667\n",
      " 0.62105263 0.63157895 0.6875     0.60416667 0.55208333 0.66666667\n",
      " 0.61458333 0.57291667 0.72916667 0.57291667 0.68421053 0.56842105\n",
      " 0.63541667 0.59375    0.64583333 0.625      0.61458333 0.61458333\n",
      " 0.54166667 0.60416667 0.6        0.57894737 0.61458333 0.625\n",
      " 0.63541667 0.61458333 0.67708333 0.53125    0.65625    0.60416667\n",
      " 0.64210526 0.66315789 0.67708333 0.64583333 0.63541667 0.61458333\n",
      " 0.61458333 0.60416667 0.65625    0.61458333 0.61052632 0.6\n",
      " 0.61458333 0.61458333 0.63541667 0.63541667 0.57291667 0.73958333\n",
      " 0.51041667 0.52083333 0.63157895 0.65263158 0.63541667 0.59375\n",
      " 0.58333333 0.61458333 0.63541667 0.65625    0.58333333 0.57291667\n",
      " 0.56842105 0.58947368 0.5625     0.63541667 0.55208333 0.65625\n",
      " 0.63541667 0.6875     0.64583333 0.58333333 0.55789474 0.57894737\n",
      " 0.61458333 0.60416667 0.66666667 0.60416667 0.66666667 0.61458333\n",
      " 0.59375    0.66666667 0.55789474 0.63157895]\n",
      "Accuracy: 61.81% (4.48%)\n",
      "Execution Time: 5.70 seconds\n",
      "------------------------------\n",
      "--------- XGBoost on TicTacToe Dataset ---------\n",
      "[0.70833333 0.64583333 0.67708333 0.58333333 0.67708333 0.63541667\n",
      " 0.66666667 0.61458333 0.64210526 0.65263158 0.72916667 0.67708333\n",
      " 0.5625     0.65625    0.63541667 0.6875     0.67708333 0.625\n",
      " 0.66315789 0.66315789 0.72916667 0.65625    0.61458333 0.64583333\n",
      " 0.6875     0.625      0.65625    0.65625    0.68421053 0.64210526\n",
      " 0.73958333 0.67708333 0.69791667 0.625      0.64583333 0.61458333\n",
      " 0.625      0.64583333 0.69473684 0.69473684 0.65625    0.60416667\n",
      " 0.70833333 0.63541667 0.66666667 0.625      0.66666667 0.67708333\n",
      " 0.69473684 0.70526316 0.625      0.67708333 0.63541667 0.6875\n",
      " 0.59375    0.63541667 0.65625    0.6875     0.64210526 0.68421053\n",
      " 0.63541667 0.64583333 0.70833333 0.64583333 0.64583333 0.6875\n",
      " 0.65625    0.61458333 0.61052632 0.68421053 0.70833333 0.63541667\n",
      " 0.625      0.69791667 0.61458333 0.6875     0.61458333 0.71875\n",
      " 0.64210526 0.69473684 0.59375    0.65625    0.63541667 0.65625\n",
      " 0.67708333 0.69791667 0.65625    0.66666667 0.63157895 0.62105263\n",
      " 0.65625    0.64583333 0.69791667 0.60416667 0.70833333 0.63541667\n",
      " 0.66666667 0.66666667 0.64210526 0.63157895]\n",
      "Accuracy: 65.72% (3.43%)\n",
      "Execution Time: 5.93 seconds\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "tictactoe_scores = []\n",
    "tictactoe_mean = []\n",
    "tictactoe_std = []\n",
    "model_names = []\n",
    "execution_times = []\n",
    "\n",
    "for algorithm_name in names:\n",
    "    if algorithm_name == 'AdaBoost':\n",
    "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
    "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
    "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
    "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
    "\n",
    "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
    "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
    "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                random_state=42)    \n",
    "\n",
    "    if algorithm_name == 'GradBoost':\n",
    "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
    "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
    "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
    "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
    "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
    "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
    "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
    "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
    "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
    "                                        random_state=42)\n",
    "         \n",
    "    if algorithm_name == 'CatBoost':\n",
    "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
    "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
    "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
    "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                                silent=True,\n",
    "                                random_state=42)                        \n",
    "        \n",
    "    if algorithm_name == 'LightGBM':\n",
    "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
    "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
    "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
    "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
    "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
    "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
    "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                            verbosity=-1,\n",
    "                            random_state=42)\n",
    "               \n",
    "    if algorithm_name == 'XGBoost':\n",
    "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
    "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
    "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
    "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
    "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
    "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
    "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
    "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
    "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                            verbosity=0,\n",
    "                            random_state=42)\n",
    "\n",
    "    start_time = time.time()    \n",
    "    results = cross_val_score(clf, X, y, cv=rskf)\n",
    "    end_time = time.time()\n",
    "    tictactoe_scores.append(results)\n",
    "    tictactoe_mean.append(results.mean()*100)\n",
    "    tictactoe_std.append(results.std()*100)\n",
    "    model_names.append(algorithm_name)\n",
    "    execution_time = end_time - start_time  \n",
    "    execution_times.append(execution_time)\n",
    "    print(f'--------- {algorithm_name} on TicTacToe Dataset ---------')\n",
    "    print(results)\n",
    "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
    "    print(f'Execution Time: {execution_time:.2f} seconds')\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# algorithm comparison\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison between different TicTacToe scores')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ylim(0.3, 1)\n",
    "plt.boxplot(tictactoe_scores, showmeans=True)\n",
    "ax.set_xticklabels(model_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_results['TicTacToe'] = tictactoe_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Wine</th>\n",
       "      <th>Breast_Cancer</th>\n",
       "      <th>Sonar</th>\n",
       "      <th>Ionosphere</th>\n",
       "      <th>TicTacToe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>96.552288</td>\n",
       "      <td>97.159847</td>\n",
       "      <td>86.347619</td>\n",
       "      <td>93.815873</td>\n",
       "      <td>81.054167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>98.075163</td>\n",
       "      <td>96.646633</td>\n",
       "      <td>78.145238</td>\n",
       "      <td>90.854762</td>\n",
       "      <td>82.224232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>97.967320</td>\n",
       "      <td>97.378303</td>\n",
       "      <td>87.076190</td>\n",
       "      <td>93.815079</td>\n",
       "      <td>72.318311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>97.120915</td>\n",
       "      <td>97.334612</td>\n",
       "      <td>82.361905</td>\n",
       "      <td>92.849206</td>\n",
       "      <td>61.814474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>97.797386</td>\n",
       "      <td>96.792626</td>\n",
       "      <td>83.802381</td>\n",
       "      <td>92.960317</td>\n",
       "      <td>65.721053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Names       Wine  Breast_Cancer      Sonar  Ionosphere  TicTacToe\n",
       "0   AdaBoost  96.552288      97.159847  86.347619   93.815873  81.054167\n",
       "1  GradBoost  98.075163      96.646633  78.145238   90.854762  82.224232\n",
       "2   CatBoost  97.967320      97.378303  87.076190   93.815079  72.318311\n",
       "3   LightGBM  97.120915      97.334612  82.361905   92.849206  61.814474\n",
       "4    XGBoost  97.797386      96.792626  83.802381   92.960317  65.721053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Algo_ult_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_time_results['TicTacToe'] = pd.Series(execution_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Moon Dataset (Data with Irregular Boundaries)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "moons_df = make_moons(n_samples=5000, shuffle=True, noise=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = moons_df[0]\n",
    "y = moons_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:47<00:00,  4.55s/trial, best loss: -0.972]\n",
      "Best hyperparameters for AdaBoost:\n",
      "{'n_estimators': 450.0, 'learning_rate': 0.01199453123793802, 'max_depth': 4.0, 'max_features': 'log2', 'min_samples_leaf': 4.0, 'min_samples_split': 6.0, 'random_state': 42}\n",
      "100%|██████████| 50/50 [02:18<00:00,  2.77s/trial, best loss: -0.97] \n",
      "Best hyperparameters for GradBoost:\n",
      "{'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 850, 'learning_rate': 0.053611707225416305, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'random_state': 42}\n",
      "100%|██████████| 50/50 [01:11<00:00,  1.43s/trial, best loss: -0.972]\n",
      "Best hyperparameters for CatBoost:\n",
      "{'n_estimators': 100, 'learning_rate': 0.055410579441262556, 'min_child_samples': 6, 'max_depth': 3, 'reg_lambda': 2.9581987876632354, 'silent': True, 'random_state': 42}\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.57trial/s, best loss: -0.971]\n",
      "Best hyperparameters for LightGBM:\n",
      "{'class_weight': 'balanced', 'boosting_type': 'gbdt', 'num_leaves': 40, 'learning_rate': 0.09467131951485339, 'min_child_samples': 160, 'reg_alpha': 1.9742666777106577, 'reg_lambda': 1.5728212782504363, 'colsample_by_tree': 0.5358931297659283, 'verbosity': -1, 'random_state': 42}\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.65trial/s, best loss: -0.971]\n",
      "Best hyperparameters for XGBoost:\n",
      "{'booster': 'gbtree', 'learning_rate': 0.05281128163953738, 'gamma': 9, 'max_depth': 4, 'min_child_weight': 0, 'colsample_bytree': 0.7139583713119172, 'colsample_bylevel': 0.2526245249075969, 'colsample_bynode': 0.21207083034314722, 'reg_alpha': 0.07455985415647337, 'reg_lambda': 1.137238476588582, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt.pyll import scope\n",
    "import warnings\n",
    "\n",
    "# Filter out the FutureWarning related to is_sparse\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
    "\n",
    "best_hyperparams = {\n",
    "    'AdaBoost': {},\n",
    "    'GradBoost': {},\n",
    "    'CatBoost': {},\n",
    "    'LightGBM': {},\n",
    "    'XGBoost': {}\n",
    "}\n",
    "\n",
    "# Define the hyperparameter search space for each algorithm\n",
    "\n",
    "def optimize_adaboost(params):\n",
    "    estimator_params = params['estimator']\n",
    "    estimator = DecisionTreeClassifier(**estimator_params)\n",
    "\n",
    "    clf = AdaBoostClassifier(estimator=estimator, n_estimators=params['n_estimators'], learning_rate=params['learning_rate'], random_state=params['random_state'])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_gradientboost(params):\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_catboost(params):\n",
    "    clf = CatBoostClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_lightgbm(params):\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "def optimize_xgboost(params):\n",
    "    clf = XGBClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return -accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Define the hyperparameter search space for each algorithm\n",
    "\n",
    "max_features_choices = [None, 'sqrt', 'log2']\n",
    "space_adaboost = {\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'estimator': {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),  # Decision tree depth\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 8, 2)),  # Min samples required to split\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),  # Min samples required in a leaf node\n",
    "        'max_features': hp.choice('max_features', max_features_choices),\n",
    "    },\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "criterion_choices = ['friedman_mse', 'squared_error']\n",
    "max_features_choices = [None, 'sqrt', 'log2']\n",
    "space_gradientboost = {\n",
    "    'criterion': hp.choice('criterion', criterion_choices),\n",
    "    'max_features': hp.choice('max_features', max_features_choices),\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
    "    'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', 0.0, 0.5, 0.1),\n",
    "    'min_impurity_decrease': hp.quniform('min_impurity_decrease', 0.0, 5, 1),\n",
    "    'ccp_alpha': hp.quniform('ccp_alpha', 0.0, 5, 1),\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "space_catboost = {\n",
    "    'n_estimators': 1 + scope.int(hp.quniform('n_estimators', 5, 1500, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 1, 10, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'silent': True\n",
    "}\n",
    "\n",
    "class_weight_choices = ['balanced']\n",
    "boosting_type_choices = ['gbdt', 'dart', 'goss']\n",
    "space_lightgbm = {\n",
    "    'class_weight': hp.choice('class_weight', class_weight_choices),                                              \n",
    "    'boosting_type': hp.choice('boosting_type', boosting_type_choices),\n",
    "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 100, 5)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 200, 10)),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.1, 1.0),\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "booster_choices = ['gbtree', 'dart']\n",
    "space_xgboost = {\n",
    "    'booster': hp.choice('booster', booster_choices),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.1)),\n",
    "    'gamma': scope.int(hp.quniform('gamma', 0, 10, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
    "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 0, 6, 1)),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.1, 1.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5.0),\n",
    "    'verbosity': 0,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Define optimization functions and algorithm names\n",
    "optimizers = [\n",
    "    (optimize_adaboost, space_adaboost, 'AdaBoost'),\n",
    "    (optimize_gradientboost, space_gradientboost, 'GradBoost'),\n",
    "    (optimize_catboost, space_catboost, 'CatBoost'),\n",
    "    (optimize_lightgbm, space_lightgbm, 'LightGBM'),\n",
    "    (optimize_xgboost, space_xgboost, 'XGBoost')\n",
    "]\n",
    "\n",
    "\n",
    "# Performing hyperparameter tuning for each algorithm\n",
    "\n",
    "rstate=np.random.default_rng(42)\n",
    "\n",
    "for optimize_fn, space, algorithm_name in optimizers:\n",
    "    if algorithm_name == 'AdaBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        max_features_label = max_features_choices[best['max_features']]\n",
    "\n",
    "        # Store the best AdaBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'n_estimators': best['n_estimators'],\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'max_depth': best['max_depth'],\n",
    "            'max_features': max_features_label,\n",
    "            'min_samples_leaf': best['min_samples_leaf'],\n",
    "            'min_samples_split': best['min_samples_split'],\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'GradBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "\n",
    "\n",
    "        # Map the choice labels        \n",
    "        criterion_label = criterion_choices[best['criterion']]\n",
    "        max_features_label = max_features_choices[best['max_features']]\n",
    "\n",
    "        # Store the best GradBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'criterion': criterion_label,\n",
    "            'max_features': max_features_label,\n",
    "            'n_estimators': int(best['n_estimators']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'min_samples_split': int(best['min_samples_split']),\n",
    "            'min_samples_leaf': int(best['min_samples_leaf']),\n",
    "            'min_weight_fraction_leaf': best['min_weight_fraction_leaf'],\n",
    "            'min_impurity_decrease': best['min_impurity_decrease'],\n",
    "            'ccp_alpha': best['ccp_alpha'],\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])           \n",
    "    \n",
    "    if algorithm_name == 'CatBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Store the best CatBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'n_estimators': int(best['n_estimators']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'min_child_samples': int(best['min_child_samples']),\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'silent': True,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'LightGBM':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        class_weight_label = class_weight_choices[best['class_weight']]\n",
    "        boosting_type_label = boosting_type_choices[best['boosting_type']]\n",
    "\n",
    "        # Store the best LightGBM hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'class_weight': class_weight_label,\n",
    "            'boosting_type': boosting_type_label,\n",
    "            'num_leaves': int(best['num_leaves']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'min_child_samples': int(best['min_child_samples']),\n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'colsample_by_tree': best['colsample_by_tree'],\n",
    "            'verbosity': -1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])\n",
    "\n",
    "    if algorithm_name == 'XGBoost':\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=optimize_fn, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=rstate)\n",
    "        \n",
    "        # Map the choice labels\n",
    "        booster_label = booster_choices[best['booster']]        \n",
    " \n",
    "        # Store the best XGBoost hyperparameters\n",
    "        best_hyperparams[algorithm_name] = {\n",
    "            'booster': booster_label,\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'gamma': int(best['gamma']),\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'min_child_weight': int(best['min_child_weight']),\n",
    "            'colsample_bytree': best['colsample_bytree'],\n",
    "            'colsample_bylevel': best['colsample_bylevel'],\n",
    "            'colsample_bynode': best['colsample_bynode'],            \n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],            \n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        print(f\"Best hyperparameters for {algorithm_name}:\")\n",
    "        print(best_hyperparams[algorithm_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['AdaBoost', 'GradBoost', 'CatBoost', 'LightGBM', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- AdaBoost on Moon Dataset ---------\n",
      "[0.964 0.964 0.97  0.964 0.97  0.974 0.974 0.972 0.962 0.97  0.974 0.97\n",
      " 0.966 0.966 0.976 0.962 0.976 0.954 0.97  0.964 0.97  0.968 0.962 0.974\n",
      " 0.976 0.972 0.968 0.976 0.966 0.966 0.952 0.96  0.976 0.966 0.98  0.98\n",
      " 0.97  0.982 0.952 0.974 0.972 0.964 0.958 0.958 0.978 0.98  0.972 0.976\n",
      " 0.976 0.982 0.968 0.974 0.97  0.974 0.964 0.964 0.978 0.956 0.97  0.976\n",
      " 0.966 0.968 0.968 0.984 0.958 0.978 0.978 0.962 0.97  0.978 0.97  0.966\n",
      " 0.97  0.968 0.978 0.964 0.97  0.974 0.962 0.976 0.984 0.966 0.962 0.96\n",
      " 0.964 0.974 0.97  0.968 0.972 0.96  0.98  0.966 0.976 0.966 0.964 0.962\n",
      " 0.974 0.974 0.968 0.968]\n",
      "Accuracy: 96.95% (0.69%)\n",
      "Execution Time: 304.63 seconds\n",
      "------------------------------\n",
      "--------- GradBoost on Moon Dataset ---------\n",
      "[0.966 0.966 0.976 0.962 0.966 0.968 0.972 0.978 0.97  0.97  0.97  0.976\n",
      " 0.97  0.972 0.98  0.964 0.972 0.96  0.97  0.966 0.97  0.968 0.958 0.976\n",
      " 0.976 0.976 0.978 0.976 0.966 0.966 0.964 0.96  0.972 0.962 0.972 0.976\n",
      " 0.974 0.97  0.952 0.974 0.978 0.966 0.966 0.966 0.966 0.968 0.972 0.974\n",
      " 0.972 0.978 0.964 0.972 0.968 0.976 0.966 0.97  0.98  0.962 0.968 0.986\n",
      " 0.968 0.964 0.972 0.978 0.956 0.98  0.976 0.96  0.972 0.97  0.97  0.974\n",
      " 0.98  0.97  0.976 0.958 0.976 0.98  0.968 0.968 0.984 0.966 0.968 0.962\n",
      " 0.97  0.972 0.982 0.966 0.972 0.962 0.978 0.964 0.976 0.968 0.96  0.964\n",
      " 0.978 0.976 0.964 0.978]\n",
      "Accuracy: 97.02% (0.65%)\n",
      "Execution Time: 572.57 seconds\n",
      "------------------------------\n",
      "--------- CatBoost on Moon Dataset ---------\n",
      "[0.974 0.956 0.978 0.964 0.97  0.97  0.98  0.976 0.97  0.972 0.97  0.98\n",
      " 0.974 0.978 0.984 0.968 0.972 0.956 0.966 0.96  0.966 0.976 0.96  0.972\n",
      " 0.976 0.97  0.972 0.974 0.97  0.968 0.964 0.964 0.974 0.968 0.978 0.98\n",
      " 0.976 0.978 0.956 0.97  0.976 0.96  0.968 0.962 0.972 0.972 0.972 0.966\n",
      " 0.972 0.986 0.956 0.97  0.966 0.978 0.966 0.966 0.986 0.964 0.968 0.978\n",
      " 0.966 0.958 0.976 0.976 0.964 0.978 0.974 0.966 0.972 0.98  0.976 0.972\n",
      " 0.982 0.97  0.97  0.96  0.97  0.982 0.962 0.976 0.982 0.964 0.974 0.956\n",
      " 0.97  0.974 0.98  0.96  0.976 0.962 0.982 0.97  0.98  0.968 0.972 0.956\n",
      " 0.964 0.972 0.96  0.976]\n",
      "Accuracy: 97.06% (0.73%)\n",
      "Execution Time: 19.94 seconds\n",
      "------------------------------\n",
      "--------- LightGBM on Moon Dataset ---------\n",
      "[0.974 0.966 0.974 0.964 0.966 0.976 0.98  0.976 0.964 0.974 0.97  0.976\n",
      " 0.974 0.978 0.976 0.972 0.978 0.96  0.97  0.964 0.972 0.968 0.956 0.978\n",
      " 0.978 0.972 0.974 0.976 0.968 0.972 0.972 0.956 0.978 0.974 0.974 0.984\n",
      " 0.968 0.972 0.956 0.976 0.978 0.97  0.966 0.964 0.972 0.968 0.974 0.974\n",
      " 0.97  0.978 0.966 0.97  0.97  0.97  0.968 0.966 0.98  0.97  0.968 0.986\n",
      " 0.976 0.966 0.974 0.978 0.966 0.978 0.98  0.968 0.97  0.978 0.968 0.974\n",
      " 0.978 0.972 0.972 0.96  0.972 0.982 0.97  0.968 0.982 0.968 0.97  0.958\n",
      " 0.964 0.98  0.978 0.966 0.974 0.964 0.98  0.966 0.972 0.97  0.966 0.964\n",
      " 0.98  0.974 0.964 0.986]\n",
      "Accuracy: 97.16% (0.63%)\n",
      "Execution Time: 4.12 seconds\n",
      "------------------------------\n",
      "--------- XGBoost on Moon Dataset ---------\n",
      "[0.96  0.946 0.974 0.972 0.96  0.972 0.96  0.972 0.968 0.97  0.968 0.972\n",
      " 0.972 0.96  0.966 0.956 0.968 0.948 0.962 0.962 0.962 0.966 0.958 0.97\n",
      " 0.974 0.974 0.972 0.962 0.968 0.956 0.96  0.948 0.966 0.958 0.974 0.976\n",
      " 0.968 0.974 0.958 0.966 0.972 0.956 0.956 0.964 0.962 0.968 0.972 0.966\n",
      " 0.968 0.968 0.952 0.96  0.968 0.97  0.956 0.964 0.984 0.956 0.962 0.974\n",
      " 0.966 0.958 0.964 0.97  0.95  0.964 0.972 0.96  0.964 0.974 0.966 0.966\n",
      " 0.966 0.966 0.964 0.958 0.966 0.984 0.964 0.968 0.972 0.972 0.97  0.952\n",
      " 0.964 0.97  0.966 0.962 0.968 0.96  0.976 0.962 0.97  0.966 0.97  0.958\n",
      " 0.962 0.96  0.95  0.972]\n",
      "Accuracy: 96.51% (0.72%)\n",
      "Execution Time: 10.22 seconds\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "moon_scores = []\n",
    "moon_mean = []\n",
    "moon_std = []\n",
    "model_names = []\n",
    "execution_times = []\n",
    "\n",
    "for algorithm_name in names:\n",
    "    if algorithm_name == 'AdaBoost':\n",
    "        base_estimator = DecisionTreeClassifier(max_depth=int(best_hyperparams[algorithm_name]['max_depth']),\n",
    "                                                max_features=best_hyperparams[algorithm_name]['max_features'],\n",
    "                                                min_samples_leaf=int(best_hyperparams[algorithm_name]['min_samples_leaf']),\n",
    "                                                min_samples_split=int(best_hyperparams[algorithm_name]['min_samples_split']))\n",
    "\n",
    "        clf = AdaBoostClassifier(estimator=base_estimator, \n",
    "                                n_estimators=int(best_hyperparams[algorithm_name]['n_estimators']), \n",
    "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                random_state=42)    \n",
    "\n",
    "    if algorithm_name == 'GradBoost':\n",
    "        clf = GradientBoostingClassifier(criterion=best_hyperparams[algorithm_name]['criterion'], \n",
    "                                        max_features=best_hyperparams[algorithm_name]['max_features'], \n",
    "                                        n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
    "                                        learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                        max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
    "                                        min_samples_split=best_hyperparams[algorithm_name]['min_samples_split'],\n",
    "                                        min_samples_leaf=best_hyperparams[algorithm_name]['min_samples_leaf'],\n",
    "                                        min_weight_fraction_leaf=best_hyperparams[algorithm_name]['min_weight_fraction_leaf'],\n",
    "                                        min_impurity_decrease=best_hyperparams[algorithm_name]['min_impurity_decrease'],\n",
    "                                        ccp_alpha=best_hyperparams[algorithm_name]['ccp_alpha'],\n",
    "                                        random_state=42)\n",
    "         \n",
    "    if algorithm_name == 'CatBoost':\n",
    "        clf = CatBoostClassifier(n_estimators=best_hyperparams[algorithm_name]['n_estimators'],\n",
    "                                learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                                min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
    "                                max_depth=best_hyperparams[algorithm_name]['max_depth'],\n",
    "                                reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                                silent=True,\n",
    "                                random_state=42)                        \n",
    "        \n",
    "    if algorithm_name == 'LightGBM':\n",
    "        clf = LGBMClassifier(boosting_type=best_hyperparams[algorithm_name]['boosting_type'], \n",
    "                            class_weight=best_hyperparams[algorithm_name]['class_weight'], \n",
    "                            colsample_by_tree=best_hyperparams[algorithm_name]['colsample_by_tree'],\n",
    "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                            min_child_samples=best_hyperparams[algorithm_name]['min_child_samples'],\n",
    "                            num_leaves=best_hyperparams[algorithm_name]['num_leaves'],\n",
    "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
    "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                            verbosity=-1,\n",
    "                            random_state=42)\n",
    "               \n",
    "    if algorithm_name == 'XGBoost':\n",
    "        clf = XGBClassifier(booster=best_hyperparams[algorithm_name]['booster'], \n",
    "                            learning_rate=best_hyperparams[algorithm_name]['learning_rate'],\n",
    "                            gamma=best_hyperparams[algorithm_name]['gamma'], \n",
    "                            max_depth=best_hyperparams[algorithm_name]['max_depth'], \n",
    "                            min_child_weight=best_hyperparams[algorithm_name]['min_child_weight'],\n",
    "                            colsample_bytree=best_hyperparams[algorithm_name]['colsample_bytree'],\n",
    "                            colsample_bylevel=best_hyperparams[algorithm_name]['colsample_bylevel'],\n",
    "                            colsample_bynode=best_hyperparams[algorithm_name]['colsample_bynode'],                            \n",
    "                            reg_alpha=best_hyperparams[algorithm_name]['reg_alpha'],\n",
    "                            reg_lambda=best_hyperparams[algorithm_name]['reg_lambda'],\n",
    "                            verbosity=0,\n",
    "                            random_state=42)\n",
    "\n",
    "    start_time = time.time()    \n",
    "    results = cross_val_score(clf, X, y, cv=rskf)\n",
    "    end_time = time.time()\n",
    "    moon_scores.append(results)\n",
    "    moon_mean.append(results.mean()*100)\n",
    "    moon_std.append(results.std()*100)\n",
    "    model_names.append(algorithm_name)\n",
    "    execution_time = end_time - start_time  \n",
    "    execution_times.append(execution_time)\n",
    "    print(f'--------- {algorithm_name} on Moon Dataset ---------')\n",
    "    print(results)\n",
    "    print('Accuracy: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
    "    print(f'Execution Time: {execution_time:.2f} seconds')\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHNCAYAAADMjHveAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABRTklEQVR4nO3deVxU5f4H8M8MMjNsAyrIJoGAC2iConKRa2phmMttl5sViEtpXpeoTFvcjbxeDW9qarmUS3rd2lRa0H6aUpiKmiJu4JKASwqCC8p8f394OdcREIYGD+jn/XrNS+c5zznnOeeZOedztkEjIgIiIiIilWjVbgARERHd3xhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRqhW02g0GD9+vNrNKJefnx969eqldjPuCV26dEGXLl2U99nZ2dBoNFi8eLFZveTkZISGhsJgMECj0eDixYsAgCVLlqBFixawtbWFi4vLXWs3EVkHw0gtd/ToUbz88svw9/eHwWCA0WhEZGQkZs6ciStXrqjdPLKiy5cvY/z48fjxxx/VbkqtdP78efTp0wd2dnaYPXs2lixZAgcHBxw8eBD9+vVDQEAAPv74Y8yfP1/tplbowIEDGD9+PLKzs6tUf/z48dBoNNBqtTh58mSZ4QUFBbCzs4NGo8E//vEPK7eW6O6pp3YDqGLr16/Hs88+C71ej9jYWLRq1QrFxcX46aef8MYbb2D//v21esNrDVeuXEG9evfHx/Ty5cuYMGECAJidJbgf+fr64sqVK7C1tVXKduzYgUuXLmHSpEmIiopSyn/88UeYTCbMnDkTgYGBajS3yg4cOIAJEyagS5cu8PPzq/J4er0en3/+OUaNGmVWvnbtWiu3kEgd98dWvg7KysrC3//+d/j6+mLTpk3w9PRUhg0dOhRHjhzB+vXrVWxhzTGZTCguLobBYIDBYFC7OaQCjUZTpu/PnDkDAGUuw1RU/mcUFRXBwcHBatP7s3r06FFuGFm+fDl69uyJNWvWqNSyuuPq1avQ6XTQanlBoFYSqpUGDx4sAGTbtm1Vqn/9+nWZOHGi+Pv7i06nE19fXxkzZoxcvXrVrJ6vr6/07NlTNm/eLGFhYWIwGKRVq1ayefNmERFZs2aNtGrVSvR6vbRt21Z27dplNn5cXJw4ODjI0aNH5dFHHxV7e3vx9PSUCRMmiMlkMqs7bdo0iYiIkAYNGojBYJC2bdvKqlWryrQdgAwdOlSWLl0qwcHBUq9ePVm3bp0ybNy4cUrdgoICGTFihPj6+opOpxM3NzeJioqSnTt3mk3zP//5j7Rt21YMBoM0bNhQnn/+eTl16lS5y3Lq1Cl5/PHHxcHBQVxdXeW1116TGzduVLrOS9flt99+KyEhIaLX6yUoKEjWrFlTpu6FCxdkxIgR0rhxY9HpdBIQECDvv/++lJSUiIhIVlaWACjzGjdunHz55ZcCQPbs2aNMb/Xq1QJAnnzySbP5tGjRQvr06WNWtmTJEmVd1K9fX2JiYuTEiRNl2vjzzz9LdHS0GI1GsbOzk4ceekh++uknszrjxo0TAHL48GGJi4sTZ2dnMRqN0q9fPykqKqp0nYmIzJs3T/z9/cVgMEj79u1ly5Yt0rlzZ+ncubNSp3R9LFq0SEREOnfuXGbdxMXFia+vb7nrrNSGDRvkr3/9q9jb24ujo6P06NFDfvvtN7P2lH4Ojhw5Io899pg4OjrK448/LiIiJSUl8sEHH0hwcLDo9Xpp1KiRvPTSS/LHH3+YTaP0s7B161Zp37696PV6adKkiXz66adKnUWLFpXbx6XfvfKUru/S/s7IyFCG5eTkiI2NjaxZs0b5Dt0qLy9P+vfvL40aNRK9Xi+tW7eWxYsXl5lHYWGhJCQkKJ/NZs2aybRp08p8n0vnsW7dOmnZsqXodDoJDg6WjRs3Vtj+W/373/+W4OBgsbOzExcXFwkLC5Nly5aZ1Tl16pT0799fPD09RafTiZ+fnwwePFiuXbum1Dl69Kg888wzUr9+fbGzs5Pw8HD55ptvzKazefNmASCff/65vP322+Ll5SUajUYuXLggIlX7rFd1W0PWwTBSS3l7e4u/v3+V68fFxQkAeeaZZ2T27NkSGxsrAOSJJ54wq+fr6yvNmzcXT09PGT9+vHzwwQfi7e0tjo6OsnTpUnnggQfk/fffl/fff1+cnZ0lMDBQ2WGWzsdgMEjTpk3lxRdflFmzZkmvXr0EgLz77rtm82rcuLG88sorMmvWLJkxY4Z06NBBAJTZcACQoKAgcXNzkwkTJsjs2bNl9+7dyrBbdy59+/YVnU4nCQkJ8sknn8jUqVOld+/esnTpUqVO6Ua/ffv28sEHH8jo0aPFzs5O/Pz8lI3RrcvSsmVL6d+/v3z00Ufy9NNPCwCZM2dOpevc19dXmjVrJi4uLjJ69GiZMWOGPPjgg6LVauW7775T6hUVFUnr1q2lYcOG8tZbb8ncuXMlNjZWNBqNjBgxQkRu7hA++ugjJWAsWbJElixZInv27JHz58+LRqORDz/8UJnmiBEjRKvVipubm1J25swZASCzZs1SyiZPniwajUZiYmJkzpw5MmHCBHF1dS2zLlJSUkSn00lERIRMnz5dPvjgA2ndurXodDr55ZdflHqlO8c2bdrIU089JXPmzJGBAwcKABk1alSl6+yTTz4RANKxY0f597//LSNHjhQXFxfx9/e/Yxj57rvv5KWXXhIAMnHiRFmyZIls375d1q1bJ08++aQAkI8++khZZyIin332mWg0Gunevbt8+OGHMnXqVPHz8xMXFxfJyspS5hUXFyd6vV4CAgIkLi5O5s6dK5999pmIiAwcOFDq1asngwYNkrlz58qbb74pDg4O0r59eykuLjb7LDRv3lzc3d3lrbfeklmzZknbtm1Fo9Eo4efo0aMyfPhwASBvvfWW0se5ubkVrq/S9X3mzBlp3Lix2XcsKSlJnJ2d5erVq2XCyOXLlyUoKEhsbW3l1VdflX//+9/SqVMnASBJSUlKPZPJJA8//LBoNBoZOHCgzJo1S3r37i0AZOTIkWZtASAhISHi6ekpkyZNkqSkJPH39xd7e3s5d+7cHft9/vz5yvZp3rx5MnPmTBkwYIAMHz5cqfP777+Ll5eX2Nvby8iRI2Xu3Lny7rvvSlBQkPJZzc3NFXd3d3FycpK3335bZsyYISEhIaLVamXt2rXKtErDSHBwsISGhsqMGTMkMTFRioqKqvxZr8q2hqyHYaQWys/PFwDK0Vll0tPTBYAMHDjQrPz1118XALJp0yalrPRIcvv27UrZt99+KwDEzs5Ojh8/rpTPmzevzJFbaegZNmyYUmYymaRnz56i0+nk7NmzSvnly5fN2lNcXCytWrWShx9+2KwcgGi1Wtm/f3+ZZbs9jDg7O5c5Arx9Ho0aNZJWrVrJlStXlPJvvvlGAMjYsWPLLMvEiRPNptGmTRsJCwurcB6lStflrWdC8vPzxdPTU9q0aaOUTZo0SRwcHOTQoUNm448ePVpsbGyUsxRnz54ts7ylWrZsaXbGo23btvLss8+aHS2vXbvW7AxKdna22NjYyJQpU8ymtW/fPqlXr55SbjKZpGnTphIdHW12NHz58mVp0qSJdOvWTSkr3Tn279/fbJpPPvmkNGzY8I7rq7RvQkNDzY50S3dUdwojIv8LmTt27DCbbmmbbv3sXbp0SVxcXGTQoEFmdXNzc8XZ2dmsvPRzMHr0aLO6W7duFQBljt6Tk5PLlJd+FrZs2aKUnTlzRvR6vbz22mtK2apVqyo9G1LRsr3++usSGBioDGvfvr3Ex8eLiJQJI0lJSQLAbMdZXFwsERER4ujoKAUFBSIi8sUXXwgAmTx5stl8n3nmGdFoNHLkyBGlDIDodDqzsj179ggAs6Bcnscff1xatmx5xzqxsbGi1WrL9K+IKJ/LkSNHCgDZunWrMuzSpUvSpEkT8fPzUw6cSsOIv7+/2XbIks96Zdsasi5ePKuFCgoKAABOTk5Vqr9hwwYAQEJCgln5a6+9BgBl7i0JDg5GRESE8j48PBwA8PDDD+OBBx4oU37s2LEy87z1zv3SO/mLi4vxww8/KOV2dnbK/y9cuID8/Hx06tQJu3btKjO9zp07Izg4uJIlvXlfwC+//ILTp0+XO/zXX3/FmTNn8Morr5jdc9CzZ0+0aNGi3PtsBg8ebPa+U6dO5S5zeby8vPDkk08q741GI2JjY7F7927k5uYCAFatWoVOnTqhfv36OHfunPKKiopCSUkJtmzZUul8OnXqhK1btwIALl26hD179uCll16Cq6urUr5161a4uLigVatWAG7e3GgymdCnTx+z+Xp4eKBp06bYvHkzACA9PR2HDx9G3759cf78eaVeUVERHnnkEWzZsgUmk6nSdXb+/Hnls1ue0r4ZPHgwdDqdUt6vXz84OztXug4s8f333+PixYt47rnnzJbdxsYG4eHhyrLfasiQIWbvV61aBWdnZ3Tr1s1sGmFhYXB0dCwzjeDgYHTq1El57+bmhubNm1f5s1SZvn374siRI9ixY4fyb9++fcutu2HDBnh4eOC5555TymxtbTF8+HAUFhbi//7v/5R6NjY2GD58uNn4r732GkQEGzduNCuPiopCQECA8r5169YwGo2VLqOLiwtOnTqFHTt2lDvcZDLhiy++QO/evdGuXbsywzUajdLeDh064K9//asyzNHRES+99BKys7Nx4MABs/Hi4uLMtkOWfNYr29aQdfEG1lrIaDQCuLnTqYrjx49Dq9WWeZLAw8MDLi4uOH78uFn5rYEDgLIj8PHxKbf8woULZuVarRb+/v5mZc2aNQMAs0cWv/nmG0yePBnp6em4du2aUl66YblVkyZNKly+W/3zn/9EXFwcfHx8EBYWhh49eiA2NlZpT+myNm/evMy4LVq0wE8//WRWZjAY4ObmZlZWv379MstckcDAwDLLc+u68PDwwOHDh7F3794y8ylVegPmnXTq1Alz587FkSNHcPToUWg0GkRERCghZdCgQdi6dSsiIyOVG/QOHz4MEUHTpk3LnWbpkyqHDx8GcHPDXZH8/HzUr19feX/7Z6h02IULF5TP7+1K++b29tja2pb5PP1Zpcv08MMPlzv89jbWq1cPjRs3LjON/Px8NGrUqNxp3N5vt68TwLLPUmXatGmDFi1aYPny5XBxcYGHh0eFy3f8+HE0bdq0zM2aQUFByvDSf728vMoc+Nxer1R1l/HNN9/EDz/8gA4dOiAwMBCPPvoo+vbti8jISADA2bNnUVBQoATpihw/flw5SKqovbdO4/btiiWf9cq2NWRdDCO1kNFohJeXF3777TeLxitvJ18eGxsbi8pFxKJ2ADeP0v/2t7/hoYcewpw5c+Dp6QlbW1ssWrQIy5cvL1P/1qOXO+nTpw86deqEdevW4bvvvsO0adMwdepUrF27Fo899pjF7axoma3JZDKhW7duZZ6EKFUaXu6k9Ehwy5YtOHbsGNq2bQsHBwd06tQJ//73v1FYWIjdu3djypQpZvPVaDTYuHFjucvp6Oio1AOAadOmITQ0tNz5l9YtZc3PSk0oXaYlS5bAw8OjzPDbHxfX6/VldtwmkwmNGjXCsmXLyp3H7eHybqyTvn374qOPPoKTkxNiYmLu+pMh1V3GoKAgZGZm4ptvvkFycjLWrFmDOXPmYOzYscrj7DXh9u2KJZ91a29r6M4YRmqpXr16Yf78+UhNTTW7pFIeX19fmEwmHD58WDlCAIC8vDxcvHgRvr6+Vm2byWTCsWPHzHaihw4dAgDltxPWrFkDg8GAb7/9Fnq9Xqm3aNGiPz1/T09PvPLKK3jllVdw5swZtG3bFlOmTMFjjz2mLGtmZmaZo8bMzEyrr4sjR45ARMyC4O3rIiAgAIWFhWa/jVGeO4XJBx54AA888AC2bt2KY8eOKZcDHnroISQkJGDVqlUoKSnBQw89pIwTEBAAEUGTJk3uGHhKT7sbjcZK2/hnlK77w4cPm/XN9evXkZWVhZCQEKvNq3SZGjVqVO1lCggIwA8//IDIyMgqh+XKVPWAoSJ9+/bF2LFjkZOTgyVLllRYz9fXF3v37oXJZDILLAcPHlSGl/77ww8/4NKlS2ZnR26vZw0ODg6IiYlBTEwMiouL8dRTT2HKlCkYM2YM3NzcYDQaKz0A8/X1RWZmZpnyqrbX0s/6nbY1ZF28Z6SWGjVqFBwcHDBw4EDk5eWVGX706FHMnDkTwM3fIACApKQkszozZswAcPN+CWubNWuW8n8RwaxZs2Bra4tHHnkEwM0jKI1Gg5KSEqVednY2vvjii2rPs6SkBPn5+WZljRo1gpeXl3IZqF27dmjUqBHmzp1rdmlo48aNyMjIsPq6OH36NNatW6e8LygowGeffYbQ0FDliLxPnz5ITU3Ft99+W2b8ixcv4saNGwAAe3t7paw8nTp1wqZNm5CWlqaEkdDQUDg5OeH999+HnZ0dwsLClPpPPfUUbGxsMGHChDJHriKC8+fPAwDCwsIQEBCAf/3rXygsLCwz37Nnz1Z1ddxRu3bt4Obmhrlz56K4uFgpX7x4cYXLXF3R0dEwGo147733cP369TLDq7JMffr0QUlJCSZNmlRm2I0bN6rV5tLfLqnu8gYEBCApKQmJiYno0KFDhfV69OiB3NxcrFy5Uim7ceMGPvzwQzg6OqJz585KvZKSErPvMwB88MEH0Gg0Vtvpln7WSul0OgQHB0NEcP36dWi1WjzxxBP4+uuv8euvv5YZv/Tz26NHD6SlpSE1NVUZVlRUhPnz58PPz6/S+86q+lmvyraGrItnRmqpgIAALF++HDExMQgKCjL7Bdbt27dj1apV6NevHwAgJCQEcXFxmD9/Pi5evIjOnTsjLS0Nn376KZ544gl07drVqm0zGAxITk5GXFwcwsPDsXHjRqxfvx5vvfWWcuq6Z8+emDFjBrp3746+ffvizJkzmD17NgIDA7F3795qzffSpUto3LgxnnnmGYSEhMDR0RE//PADduzYgenTpwO4ef/B1KlTER8fj86dO+O5555DXl4eZs6cCT8/P7z66qtWWw/AzUssAwYMwI4dO+Du7o6FCxciLy/P7AzQG2+8ga+++gq9evVCv379EBYWhqKiIuzbtw+rV69GdnY2XF1dYWdnh+DgYKxcuRLNmjVDgwYN0KpVK+UaeKdOnbBs2TJoNBrlso2NjQ06duyIb7/9Fl26dDG7MTQgIACTJ0/GmDFjkJ2djSeeeAJOTk7IysrCunXr8NJLL+H111+HVqvFJ598gsceewwtW7ZEfHw8vL298fvvv2Pz5s0wGo34+uuv//S6srW1xeTJk/Hyyy/j4YcfRkxMDLKysrBo0SKrX4c3Go346KOP8OKLL6Jt27b4+9//Djc3N5w4cQLr169HZGRkmR3w7Tp37oyXX34ZiYmJSE9Px6OPPgpbW1scPnwYq1atwsyZM/HMM89Y1K7Q0FDY2Nhg6tSpyM/Ph16vx8MPP1zhfSnlGTFiRKV1XnrpJcybNw/9+vXDzp074efnh9WrV2Pbtm1ISkpSzoL07t0bXbt2xdtvv43s7GyEhITgu+++w5dffomRI0ea3az6Zzz66KPw8PBAZGQk3N3dkZGRgVmzZqFnz55KW9577z1899136Ny5M1566SUEBQUhJycHq1atwk8//QQXFxeMHj0an3/+OR577DEMHz4cDRo0wKeffoqsrCysWbOm0stWVf2sV2VbQ1amyjM8VGWHDh2SQYMGiZ+fn+h0OnFycpLIyEj58MMPzX7Q7Pr16zJhwgRp0qSJ2Nraio+Pzx1/9Ox2KOdHk0ofr5w2bZpSVt6Pnrm7u8u4cePMfo9ERGTBggXStGlT0ev10qJFC1m0aJHyqGJl8751WOmjrteuXZM33nhDQkJCxMnJSRwcHCQkJKTc3wRZuXKltGnTRvR6vTRo0OCOP3p2u/LaWJ5bf/SsdevWynKW98Nuly5dkjFjxkhgYKDodDpxdXWVjh07yr/+9S+z36vYvn27hIWFiU6nK/OY7/79+5XfZLnV5MmTy/2dl1Jr1qyRv/71r+Lg4CAODg7SokULGTp0qGRmZprV2717tzz11FPSsGFD0ev14uvrK3369JGUlJQy6+bWx2hF/vfY7a2/31GROXPmSJMmTUSv10u7du2q9KNnt86jKo/2ltq8ebNER0eLs7OzGAwGCQgIkH79+smvv/6q1Knoc1Bq/vz5EhYWJnZ2duLk5CQPPvigjBo1Sk6fPq3Uqeh7dftyiYh8/PHH4u/vLzY2NlX+0bPylu1W5X2H8vLyJD4+XlxdXUWn08mDDz5otj5LXbp0SV599VXx8vISW1tbadq06R1/9Ox2vr6+EhcXd8f2zZs3Tx566CHlsxUQECBvvPGG5Ofnm9U7fvy4xMbGipubm+j1evH395ehQ4eW+6NnLi4uYjAYpEOHDhX+6Fl530WRyj/rlmxryDo0IrXkjjOqE/r164fVq1eXe4qTiIioOnjPCBEREamKYYSIiIhUxTBCREREquI9I0RERKQqnhkhIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqsjiMbNmyBb1794aXlxc0Gg2++OKLSsf58ccf0bZtW+j1egQGBmLx4sXVaCoRERHdiywOI0VFRQgJCcHs2bOrVD8rKws9e/ZE165dkZ6ejpEjR2LgwIH49ttvLW4sERER3Xs0IiLVHlmjwbp16/DEE09UWOfNN9/E+vXr8dtvvyllf//733Hx4kUkJydXd9ZERER0j6jxe0ZSU1MRFRVlVhYdHY3U1NSanjURERHVAfVqega5ublwd3c3K3N3d0dBQQGuXLkCOzu7MuNcu3YN165dU96bTCb88ccfaNiwITQaTU03mYiIiKxARHDp0iV4eXlBq634/EeNh5HqSExMxIQJE9RuBhEREVnByZMn0bhx4wqH13gY8fDwQF5enllZXl4ejEZjuWdFAGDMmDFISEhQ3ufn5+OBBx7AyZMnYTQaa7S9REREZB0FBQXw8fGBk5PTHevVeBiJiIjAhg0bzMq+//57REREVDiOXq+HXq8vU240GhlGiIiI6pjKbrGw+AbWwsJCpKenIz09HcDNR3fT09Nx4sQJADfPasTGxir1Bw8ejGPHjmHUqFE4ePAg5syZg//85z949dVXLZ01ERER3YMsDiO//vor2rRpgzZt2gAAEhIS0KZNG4wdOxYAkJOTowQTAGjSpAnWr1+P77//HiEhIZg+fTo++eQTREdHW2kRiIiIqC77U78zcrcUFBTA2dkZ+fn5vExDRERUR1R1/10rn6YhssTly5dx8OBBi8a5cuUKsrOz4efnV+GN1OVp0aIF7O3tLW3ifYN9UbtY2h/sC1ILw0g13a0vOcAvemUOHjyIsLCwuzKvnTt3om3btndlXnUR+6J2uVv9wb6oHPcZd8YwUk3c6NYeLVq0wM6dOy0aJyMjAy+88AKWLl2KoKAgi+ZFFWNf1C6W9gf7ouZwn3FnDCPVdLe+5KXzoorZ29tX+4sXFBRU5760tRn7onapbn+wL6yP+4w7YxipJn7JiYioqrjPuDOGEaqVDh8+jEuXLtXY9Dfu34jAKYHYuH9jjc3DyckJTZs2rbHp3y33Ql8A90Z/sC/oXsUwcoua/KLzS151hw8fRrNmzWp0Hv5j/WHvb4+FRxbindh3amw+hw4dqtP9cS/1BVC3+4N9QfcyhpH/qukvOr/kVVcaCKtzrbQq9l3ah39l/wsAYO9vj8U/LsaDTg9adR6l13tr8ij2brgX+gK4N/qj8MJZtPHQYvLkyWjSpInVp59+5SjeO7cCwM2+WP7NZITaBVh9PllZWXjnnXdQeOEsgLq7nSLrYhj5r5rc6HKDWz01ca1URPDP9f+EVqOFSUzQarTYeGkjYh+KrfRvJ9yPNDeuoo2HFm09bRDkYfEPNt+RiOCfx9dACy1MMEELLTb+sQaxga2t3hd2F23QxkMLzY2rVp3u3WQoPIFdLzsCJ98HTlp32gJggpc7tDodTBoNtCL48vdP8ffTebD2tyIIQI+XHZFReAJARytP/d6xv3A/AqcEYn/hfrQF7xm5b9TURpcbXMuV9oXdxUPAaevuALef24v95/cr701iwv7z+7F93xJEura22nzsLh66J/pC2QFueRnYYt1pb7czYL9HI+W9CSbsL8jC9qXdEXnFuustCMCuOr4DvOr4ANrOK8SyZcsQZOWnJbaf24v9u6cp700aDfbr9dj+1IdW/V4AQMbBg3j++eexoMcDVp3u3VaTl/VFBJ9lfQaDtwGfZX2GYIfgGjtYqi2X9hlG/qumNrrc4FqupvpCAHx4y9FfKa0IPvx5Mjpa8SjwXumLmtoBigg+TBsHbcFxmGBSyrXQ4sNm4ejYYYJVN773wg6wqNiE3bkmbDtWiCsupspHqCIRwdSjq5UDplJaaDH14GqMC2hp3b7IKcHuXBOknsFq07zbavqyvmMrR/i97gcAyEUuuvTrgsLfCmtsfrXh0j7DyH/VxEaXG9zquWDjirbzCvHuu+9a9Xn59CtHsf+/18RvVXoUuKL9KKtdIy+9Ll7X+6KmdoD7Lu3D/oKsMuWlYf2zI3uteinzXtgBlv5656BBg6w63Vt3fLcywYSsK1k1tiN0cnKy+jTvlpq8f0dE8FbeImRdz4UJAi00eGRMBN5zj7f62ZHadP8Ow8h/1cRGlxvc6jlwOBu7c014augEq07Xf6w/7PzsoNGW/UKLSfBO2kIcm3jMqvN0rO9m1endbTW1A6ysLyZummj1vgDq9g7wiSeeAGDdn/oWEUw4OgHZV7IhKPs3UzXQoOu7XTEuYJxVd4S15dJAddXk/Tvb7Aw4anY2XXD0eg4u/DqyRs6m15b7dxhG/qsmNrrc4FZPTWx0r5uuIyEzAQU3CsodrtFq4NnME8t3LIet1tYq86zrG1zg3ukLoO73h6urKwYOHGjVaRaXFKPgSEG5QQQABIICKcCDoQ9CZ6Oz6rzrMl6+tD6Gkf+y9kaXG9zqq4mNLgCsCVqDP67+AeBm+Hz++eexbNky5VJQA0MDeDh4WH2+dRn74t6ms9FhRa8VlfYFg4g5Xr60PoaR/6qJjS43uLWLh4OHsr6v2l3F1eNX4Wfnh+CGwSq37P7Dvqg92BeW4+VL62MYqUH8ktP9xtI/kw7c/H2cW/+tqrr4Z9LvNkv7g31RNbx8aX0MI0RkNX/mz6S/8MILFtWvi38m/W6rbn+wL+6Mly+tj2Gkmu7WEQdw/x11WIpH47WHpX8mHQCuXLmC7Oxs+Pn5wc7OzqJ50Z1Z2h/sC3Xdz2fTNSJS/m3UtUhBQQGcnZ2Rn58Po9GodnMAALt27ar2EaCl7rejDkuxL4joXlO6Xavr25yq7r95ZqSa7tYRR+m8qGI8GiciqtsYRqrJ3t7e4rQaGRlZQ625v1WnLwD2BxHdPby0f2cMI0RERDXsbt1MDNTNy8kMI0RERDWMl/bvjDewEhERUY2o6v5bexfbRERERFQGwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUlW1wsjs2bPh5+cHg8GA8PBwpKWlVVj3+vXrmDhxIgICAmAwGBASEoLk5ORqN5iIiIjuLRaHkZUrVyIhIQHjxo3Drl27EBISgujoaJw5c6bc+u+88w7mzZuHDz/8EAcOHMDgwYPx5JNPYvfu3X+68URERFT3aURELBkhPDwc7du3x6xZswAAJpMJPj4+GDZsGEaPHl2mvpeXF95++20MHTpUKXv66adhZ2eHpUuXVmmeBQUFcHZ2Rn5+PoxGoyXNJSIiIpVUdf9t0ZmR4uJi7Ny5E1FRUf+bgFaLqKgopKamljvOtWvXYDAYzMrs7Ozw008/VTifa9euoaCgwOxFRERE9yaLwsi5c+dQUlICd3d3s3J3d3fk5uaWO050dDRmzJiBw4cPw2Qy4fvvv8fatWuRk5NT4XwSExPh7OysvHx8fCxpJhEREdUhNf40zcyZM9G0aVO0aNECOp0O//jHPxAfHw+ttuJZjxkzBvn5+crr5MmTNd1MIiIiUolFYcTV1RU2NjbIy8szK8/Ly4OHh0e547i5ueGLL75AUVERjh8/joMHD8LR0RH+/v4Vzkev18NoNJq9iIiI6N5kURjR6XQICwtDSkqKUmYymZCSkoKIiIg7jmswGODt7Y0bN25gzZo1ePzxx6vXYiIiIrqn1LN0hISEBMTFxaFdu3bo0KEDkpKSUFRUhPj4eABAbGwsvL29kZiYCAD45Zdf8PvvvyM0NBS///47xo8fD5PJhFGjRll3SYiIiKhOsjiMxMTE4OzZsxg7dixyc3MRGhqK5ORk5abWEydOmN0PcvXqVbzzzjs4duwYHB0d0aNHDyxZsgQuLi5WWwgiIiKquyz+nRE18HdGiIiI6p4a+Z0RIiIiImtjGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlVVK4zMnj0bfn5+MBgMCA8PR1pa2h3rJyUloXnz5rCzs4OPjw9effVVXL16tVoNJiIionuLxWFk5cqVSEhIwLhx47Br1y6EhIQgOjoaZ86cKbf+8uXLMXr0aIwbNw4ZGRlYsGABVq5cibfeeutPN56IiIjqPovDyIwZMzBo0CDEx8cjODgYc+fOhb29PRYuXFhu/e3btyMyMhJ9+/aFn58fHn30UTz33HOVnk0hIiKi+4NFYaS4uBg7d+5EVFTU/yag1SIqKgqpqanljtOxY0fs3LlTCR/Hjh3Dhg0b0KNHjwrnc+3aNRQUFJi9iIiI6N5Uz5LK586dQ0lJCdzd3c3K3d3dcfDgwXLH6du3L86dO4e//vWvEBHcuHEDgwcPvuNlmsTEREyYMMGSphEREVEdVeNP0/z444947733MGfOHOzatQtr167F+vXrMWnSpArHGTNmDPLz85XXyZMna7qZREREpBKLzoy4urrCxsYGeXl5ZuV5eXnw8PAod5x3330XL774IgYOHAgAePDBB1FUVISXXnoJb7/9NrTasnlIr9dDr9db0jQiIiKqoyw6M6LT6RAWFoaUlBSlzGQyISUlBREREeWOc/ny5TKBw8bGBgAgIpa2l4iIiO4xFp0ZAYCEhATExcWhXbt26NChA5KSklBUVIT4+HgAQGxsLLy9vZGYmAgA6N27N2bMmIE2bdogPDwcR44cwbvvvovevXsroYSIiIjuXxaHkZiYGJw9exZjx45Fbm4uQkNDkZycrNzUeuLECbMzIe+88w40Gg3eeecd/P7773Bzc0Pv3r0xZcoU6y0FERER1VkaqQPXSgoKCuDs7Iz8/HwYjUa1m0NERERVUNX9N/82DREREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFRVrTAye/Zs+Pn5wWAwIDw8HGlpaRXW7dKlCzQaTZlXz549q91oIiIiundYHEZWrlyJhIQEjBs3Drt27UJISAiio6Nx5syZcuuvXbsWOTk5yuu3336DjY0Nnn322T/deCIiIqr7LA4jM2bMwKBBgxAfH4/g4GDMnTsX9vb2WLhwYbn1GzRoAA8PD+X1/fffw97enmGEiIiIAFgYRoqLi7Fz505ERUX9bwJaLaKiopCamlqlaSxYsAB///vf4eDgUGGda9euoaCgwOxFRERE9yaLwsi5c+dQUlICd3d3s3J3d3fk5uZWOn5aWhp+++03DBw48I71EhMT4ezsrLx8fHwsaSYRERHVIXf1aZoFCxbgwQcfRIcOHe5Yb8yYMcjPz1deJ0+evEstJCIiorutniWVXV1dYWNjg7y8PLPyvLw8eHh43HHcoqIirFixAhMnTqx0Pnq9Hnq93pKmERERUR1l0ZkRnU6HsLAwpKSkKGUmkwkpKSmIiIi447irVq3CtWvX8MILL1SvpURERHRPsujMCAAkJCQgLi4O7dq1Q4cOHZCUlISioiLEx8cDAGJjY+Ht7Y3ExESz8RYsWIAnnngCDRs2tE7LiYiI6J5gcRiJiYnB2bNnMXbsWOTm5iI0NBTJycnKTa0nTpyAVmt+wiUzMxM//fQTvvvuO+u0moiIiO4ZGhERtRtRmYKCAjg7OyM/Px9Go1Ht5hAREVEVVHX/zb9NQ0RERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlVVK4zMnj0bfn5+MBgMCA8PR1pa2h3rX7x4EUOHDoWnpyf0ej2aNWuGDRs2VKvBREREdG+pZ+kIK1euREJCAubOnYvw8HAkJSUhOjoamZmZaNSoUZn6xcXF6NatGxo1aoTVq1fD29sbx48fh4uLizXaT0RERHWcRkTEkhHCw8PRvn17zJo1CwBgMpng4+ODYcOGYfTo0WXqz507F9OmTcPBgwdha2tbrUYWFBTA2dkZ+fn5MBqN1ZoGERER3V1V3X9bdJmmuLgYO3fuRFRU1P8moNUiKioKqamp5Y7z1VdfISIiAkOHDoW7uztatWqF9957DyUlJRXO59q1aygoKDB7ERER0b3JojBy7tw5lJSUwN3d3azc3d0dubm55Y5z7NgxrF69GiUlJdiwYQPeffddTJ8+HZMnT65wPomJiXB2dlZePj4+ljSTiIiI6pAaf5rGZDKhUaNGmD9/PsLCwhATE4O3334bc+fOrXCcMWPGID8/X3mdPHmypptJREREKrHoBlZXV1fY2NggLy/PrDwvLw8eHh7ljuPp6QlbW1vY2NgoZUFBQcjNzUVxcTF0Ol2ZcfR6PfR6vSVNIyIiojrKojMjOp0OYWFhSElJUcpMJhNSUlIQERFR7jiRkZE4cuQITCaTUnbo0CF4enqWG0SIiIjo/mLxZZqEhAR8/PHH+PTTT5GRkYEhQ4agqKgI8fHxAIDY2FiMGTNGqT9kyBD88ccfGDFiBA4dOoT169fjvffew9ChQ623FERERFRnWfw7IzExMTh79izGjh2L3NxchIaGIjk5Wbmp9cSJE9Bq/5dxfHx88O233+LVV19F69at4e3tjREjRuDNN9+03lIQERFRnWXx74yogb8zQkREVPfUyO+MEBEREVkbwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUlW1wsjs2bPh5+cHg8GA8PBwpKWlVVh38eLF0Gg0Zi+DwVDtBhMREdG9xeIwsnLlSiQkJGDcuHHYtWsXQkJCEB0djTNnzlQ4jtFoRE5OjvI6fvz4n2o0ERER3TssDiMzZszAoEGDEB8fj+DgYMydOxf29vZYuHBhheNoNBp4eHgoL3d39z/VaCIiIrp3WBRGiouLsXPnTkRFRf1vAlotoqKikJqaWuF4hYWF8PX1hY+PDx5//HHs37+/+i0mIiKie4pFYeTcuXMoKSkpc2bD3d0dubm55Y7TvHlzLFy4EF9++SWWLl0Kk8mEjh074tSpUxXO59q1aygoKDB7ERER0b2pxp+miYiIQGxsLEJDQ9G5c2esXbsWbm5umDdvXoXjJCYmwtnZWXn5+PjUdDOJiIhIJRaFEVdXV9jY2CAvL8+sPC8vDx4eHlWahq2tLdq0aYMjR45UWGfMmDHIz89XXidPnrSkmURERFSHWBRGdDodwsLCkJKSopSZTCakpKQgIiKiStMoKSnBvn374OnpWWEdvV4Po9Fo9iIiIqJ7Uz1LR0hISEBcXBzatWuHDh06ICkpCUVFRYiPjwcAxMbGwtvbG4mJiQCAiRMn4i9/+QsCAwNx8eJFTJs2DcePH8fAgQOtuyRERERUJ1kcRmJiYnD27FmMHTsWubm5CA0NRXJysnJT64kTJ6DV/u+Ey4ULFzBo0CDk5uaifv36CAsLw/bt2xEcHGy9pSAiIqI6SyMionYjKlNQUABnZ2fk5+fzkg0REVEdUdX9N/82DREREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFRVrTAye/Zs+Pn5wWAwIDw8HGlpaVUab8WKFdBoNHjiiSeqM1siIiK6B1kcRlauXImEhASMGzcOu3btQkhICKKjo3HmzJk7jpednY3XX38dnTp1qnZjiYiI6N5jcRiZMWMGBg0ahPj4eAQHB2Pu3Lmwt7fHwoULKxynpKQEzz//PCZMmAB/f/8/1WAiIiK6t1gURoqLi7Fz505ERUX9bwJaLaKiopCamlrheBMnTkSjRo0wYMCAKs3n2rVrKCgoMHsRERHRvcmiMHLu3DmUlJTA3d3drNzd3R25ubnljvPTTz9hwYIF+Pjjj6s8n8TERDg7OysvHx8fS5pJREREdUiNPk1z6dIlvPjii/j444/h6upa5fHGjBmD/Px85XXy5MkabCURERGpqZ4llV1dXWFjY4O8vDyz8ry8PHh4eJSpf/ToUWRnZ6N3795KmclkujnjevWQmZmJgICAMuPp9Xro9XpLmkZERER1lEVnRnQ6HcLCwpCSkqKUmUwmpKSkICIiokz9Fi1aYN++fUhPT1def/vb39C1a1ekp6fz8gsRERFZdmYEABISEhAXF4d27dqhQ4cOSEpKQlFREeLj4wEAsbGx8Pb2RmJiIgwGA1q1amU2vouLCwCUKSciIqL7k8VhJCYmBmfPnsXYsWORm5uL0NBQJCcnKze1njhxAlotf9iViIiIqkYjIqJ2IypTUFAAZ2dn5Ofnw2g0qt0cIiIiqoKq7r95CoOIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqqlYYmT17Nvz8/GAwGBAeHo60tLQK665duxbt2rWDi4sLHBwcEBoaiiVLllS7wURERHRvsTiMrFy5EgkJCRg3bhx27dqFkJAQREdH48yZM+XWb9CgAd5++22kpqZi7969iI+PR3x8PL799ts/3XgiIiKq+zQiIpaMEB4ejvbt22PWrFkAAJPJBB8fHwwbNgyjR4+u0jTatm2Lnj17YtKkSVWqX1BQAGdnZ+Tn58NoNFrSXCIiIlJJVfff9SyZaHFxMXbu3IkxY8YoZVqtFlFRUUhNTa10fBHBpk2bkJmZialTp1ZY79q1a7h27ZryPj8/H8DNhSIiIqK6oXS/Xdl5D4vCyLlz51BSUgJ3d3ezcnd3dxw8eLDC8fLz8+Ht7Y1r167BxsYGc+bMQbdu3Sqsn5iYiAkTJpQp9/HxsaS5REREVAtcunQJzs7OFQ63KIxUl5OTE9LT01FYWIiUlBQkJCTA398fXbp0Kbf+mDFjkJCQoLw3mUz4448/0LBhQ2g0mrvRZKsrKCiAj48PTp48yUtNtQD7o/ZgX9Qe7Iva417pCxHBpUuX4OXldcd6FoURV1dX2NjYIC8vz6w8Ly8PHh4eFY6n1WoRGBgIAAgNDUVGRgYSExMrDCN6vR56vd6szMXFxZKm1lpGo7FOf7DuNeyP2oN9UXuwL2qPe6Ev7nRGpJRFT9PodDqEhYUhJSVFKTOZTEhJSUFERESVp2MymczuCSEiIqL7l8WXaRISEhAXF4d27dqhQ4cOSEpKQlFREeLj4wEAsbGx8Pb2RmJiIoCb93+0a9cOAQEBuHbtGjZs2IAlS5bgo48+su6SEBERUZ1kcRiJiYnB2bNnMXbsWOTm5iI0NBTJycnKTa0nTpyAVvu/Ey5FRUV45ZVXcOrUKdjZ2aFFixZYunQpYmJirLcUdYBer8e4cePKXH4idbA/ag/2Re3Bvqg97re+sPh3RoiIiIisiX+bhoiIiFTFMEJERESqYhghIiIiVTGMVGL8+PEIDQ1Vuxn0J/Tr1w9PPPGE2s0g+tM0Gg2++OKLKtf/8ccfodFocPHixRprE5E13JdhJDU1FTY2NujZs2eNTN/Pzw8ajQYajQY2Njbw8vLCgAEDcOHChRqZX3lq80YoNzcXI0aMQGBgIAwGA9zd3REZGYmPPvoIly9frvH59+vXT+kfjUaDhg0bonv37ti7d2+Nz/tWlu5Y7pbc3FwMGzYM/v7+0Ov18PHxQe/evc1+X+hOFi9eXO6PFHbp0sVsvbu7u+PZZ5/F8ePHrbwEFcvOzoZGo0F6evpdm6el7hSec3Jy8Nhjj1l1fnc64Nq9ezdiYmLg6ekJvV4PX19f9OrVC19//bXyt0ZK12npS6fTITAwEJMnTzb7eyTjx4+HRqNB9+7dy8xn2rRp0Gg0Ff4QZm1QUlKCjh074qmnnjIrz8/Ph4+PD95++22lbM2aNXj44YdRv3592NnZoXnz5ujfvz92796t1Fm8eLHZenN0dERYWBjWrl1715YJuPm9HDly5F2dZ3nuyzCyYMECDBs2DFu2bMHp06drZB4TJ05ETk4OTpw4gWXLlmHLli0YPnx4jcyrLjl27BjatGmD7777Du+99x52796N1NRUjBo1Ct988w1++OGHcse7fv26VdvRvXt35OTkICcnBykpKahXrx569epl1XnURdnZ2QgLC8OmTZswbdo07Nu3D8nJyejatSuGDh36p6c/aNAg5OTk4PTp0/jyyy9x8uRJvPDCC1Zo+f3Bw8Pjrj3q+eWXX+Ivf/kLCgsL8emnnyIjIwPJycl48skn8c477yh/wLTUDz/8gJycHBw+fBgTJkzAlClTsHDhQrM6np6e2Lx5M06dOmVWvnDhQjzwwAM1vkx/ho2NDRYvXozk5GQsW7ZMKR82bBgaNGiAcePGAQDefPNNxMTEIDQ0FF999RUyMzOxfPly+Pv7m/2RWeDmr6uWbod2796N6Oho9OnTB5mZmXd12WoFuc9cunRJHB0d5eDBgxITEyNTpkwxG56YmCiNGjUSR0dH6d+/v7z55psSEhKiDE9LS5OoqChp2LChGI1Geeihh2Tnzp1m0/D19ZUPPvjArGzSpEkSHBxsVrZ69WoJDg4WnU4nvr6+8q9//cts+B9//CEvvviiuLi4iJ2dnXTv3l0OHTqkDM/OzpZevXqJi4uL2NvbS3BwsKxfv16ysrIEgNkrLi6u+ivNiqKjo6Vx48ZSWFhY7nCTySQiIgBkzpw50rt3b7G3t5dx48bJjRs3pH///uLn5ycGg0GaNWsmSUlJZuPfuHFDXn31VXF2dpYGDRrIG2+8IbGxsfL4448rdeLi4szei4hs3bpVAMiZM2eUsr1790rXrl3FYDBIgwYNZNCgQXLp0iVleElJiUyYMEG8vb1Fp9NJSEiIbNy4URl+7do1GTp0qHh4eIher5cHHnhA3nvvPRG5+Rm5tX98fX2rszqt7rHHHhNvb+9y++fChQsiIjJ9+nRp1aqV2NvbS+PGjWXIkCHKetm8eXOZz964ceNERKRz584yYsQIs2kuWbJE7O3tzcp+/PFHad++veh0OvHw8JA333xTrl+/rgy/evWqDBs2TNzc3ESv10tkZKSkpaUpw//44w/p27evuLq6isFgkMDAQFm4cKGISJm2de7c+U+uMesr7/NZCoCsW7dOeb9t2zYJCQkRvV4vYWFhsm7dOgEgu3fvFpH/9ccPP/wgYWFhYmdnJxEREXLw4EEREVm0aFGZdbJo0SIpLCyUhg0bypNPPllhO0u/q6Xbm9J5lnrkkUfklVdeUd6PGzdOQkJCpFevXjJ58mSzZXB1dZUhQ4bUyv643cyZM6V+/fpy+vRp+eKLL8TW1lbS09NFRCQ1NVUAyMyZM8sdt3Sdidxc987OzmbDS0pKxNbWVv7zn/8oZZXtB0Qq35fMnj1bAgMDRa/XS6NGjeTpp58WkZuftdv7Pysrq7qr5k+578LIggULpF27diIi8vXXX0tAQIDyAVm5cqXo9Xr55JNP5ODBg/L222+Lk5OTWRhJSUmRJUuWSEZGhhw4cEAGDBgg7u7uUlBQoNS5PYycOnVKOnToIPHx8UrZr7/+KlqtViZOnCiZmZmyaNEisbOzk0WLFil1/va3v0lQUJBs2bJF0tPTJTo6WgIDA6W4uFhERHr27CndunWTvXv3ytGjR+Xrr7+W//u//5MbN27ImjVrBIBkZmZKTk6OXLx4sQbWpmXOnTsnGo1GEhMTK60LQBo1aiQLFy6Uo0ePyvHjx6W4uFjGjh0rO3bskGPHjsnSpUvF3t5eVq5cqYw3depUqV+/vqxZs0bpHycnpzuGkUuXLsnLL78sgYGBUlJSIiIihYWF4unpKU899ZTs27dPUlJSpEmTJmahbsaMGWI0GuXzzz+XgwcPyqhRo8TW1lbZUEybNk18fHxky5Ytkp2dLVu3bpXly5eLiMiZM2eUDX9OTo5ZCFLL+fPnRaPRKIGpIh988IFs2rRJsrKyJCUlRZo3by5DhgwRkZsBLCkpSYxGo+Tk5EhOTo4SVG4PI+fPn5fevXtL165dlbJTp06Jvb29vPLKK5KRkSHr1q0TV1dXJdCIiAwfPly8vLxkw4YNsn//fomLi5P69evL+fPnRURk6NChEhoaKjt27JCsrCz5/vvv5auvvhKRmwcTpTvnnJwcZZzapKphJD8/Xxo0aCAvvPCC7N+/XzZs2CDNmjUrN4yEh4fLjz/+KPv375dOnTpJx44dRUTk8uXL8tprr0nLli2V/rp8+bKsXbtWAEhqamql7S0vjOzYsUNcXFzk008/VcpKw8jatWslMDBQKR8wYICMGDFCRowYUSfCiMlkki5dusgjjzwijRo1kkmTJinDhg8fLo6OjmbhuSK3h5EbN27IwoULxdbWVo4cOaKUV7YfqGxfsmPHDrGxsZHly5dLdna27Nq1SwlLFy9elIiICBk0aJDS/zdu3LDCWrLcfRdGOnbsqBxNX79+XVxdXWXz5s0iIhIREWGW5EVEwsPDzcLI7UpKSsTJyUm+/vprpczX11d0Op04ODiIwWBQNgalR5YiIn379pVu3bqZTeuNN95Qzp4cOnRIAMi2bduU4efOnRM7OzslNT/44IMyfvz4cttVuhG6dZ5q+/nnnwWArF271qy8YcOG4uDgIA4ODjJq1CgRubnRHTlyZKXTHDp0qJLyRUQ8PT3ln//8p/L++vXr0rhx4zJhxMbGRpknAPH09DQ7wzV//nypX7++2RmC9evXi1arldzcXBER8fLyKnNmrX379spnaNiwYfLwww+bHQ3d6vajXLX98ssv5fZPZVatWiUNGzZU3pd3xCdyM4zY2tqKg4OD2NvbCwBp1qyZ2ZHYW2+9Jc2bNzdbZ7NnzxZHR0cpKSmRwsJCsbW1lWXLlinDi4uLxcvLS+n33r17mwX/W1V0FF+bVDWMfPTRR9KwYUO5cuWKMvzjjz+u8MxIqfXr1wsAZbzSkHCr999/XwDIH3/8oZSlpaUp3xkHBwdlm1e6Tu3s7MTBwUFsbW0FgLz00ktm0yydT3FxsTRq1Ej+7//+TwoLC8XJyUn27NlTZ8KIiEhGRoYAkAcffNAseHTv3l1at25tVnf69Olm6630wLD0rFRpuVarFb1eb3ZAWpX9QGX7kjVr1ojRaDQ7YL5VeWcs1XBf3TOSmZmJtLQ0PPfccwCAevXqISYmBgsWLAAAZGRkIDw83Gyc2/8AYF5eHgYNGoSmTZvC2dkZRqMRhYWFOHHihFm9N954A+np6di7d69y41/Pnj1RUlKizCsyMtJsnMjISBw+fBglJSXIyMhAvXr1zNrTsGFDNG/eHBkZGQCA4cOHY/LkyYiMjMS4cePu+g2Y1pKWlob09HS0bNnS7A8otmvXrkzd2bNnIywsDG5ubnB0dMT8+fOVdZ+fn4+cnByzdVavXr1yp9O1a1ekp6cjPT0daWlpiI6OxmOPPabcTJmRkYGQkBA4ODgo40RGRsJkMiEzMxMFBQU4ffp0uX1Y2j/9+vVDeno6mjdvjuHDh+O77777E2up5kkVf4z5hx9+wCOPPAJvb284OTnhxRdfxPnz56t08/Hzzz+P9PR07NmzBz/99BMCAwPx6KOP4tKlSwBurveIiAhoNBplnMjISBQWFuLUqVM4evQorl+/brbebW1t0aFDB2W9DxkyBCtWrEBoaChGjRqF7du3W7Ia6ozMzEy0bt0aBoNBKevQoUO5dVu3bq3839PTEwBw5swZi+bXunVr5TtTVFSEGzdumA1fuXKl0rf/+c9/8OWXX2L06NFlpmNra4sXXngBixYtwqpVq9CsWTOz9tUFCxcuhL29PbKyssrc/3K7/v37Iz09HfPmzUNRUZHZ98zJyUlZp7t378Z7772HwYMH4+uvvwaAKu0HKtuXdOvWDb6+vvD398eLL76IZcuW3ZUHBSx1X4WRBQsW4MaNG/Dy8kK9evVQr149fPTRR1izZk2Zm7EqEhcXh/T0dMycORPbt29Heno6GjZsiOLiYrN6rq6uCAwMRNOmTfHwww8jKSkJ27dvx+bNm622PAMHDsSxY8fw4osvYt++fWjXrh0+/PBDq03f2gIDA6HRaMrcnOXv74/AwEDY2dmZld8aBABgxYoVeP311zFgwAB89913SE9PR3x8fJl1XxUODg4IDAxEYGAg2rdvj08++QRFRUX4+OOPLV+wCrRt2xZZWVmYNGkSrly5gj59+uCZZ56x2vStrWnTptBoNDh48GCFdbKzs9GrVy+0bt0aa9aswc6dOzF79mwAqFI/ODs7K+s9MjISCxYswOHDh7Fy5UqrLUdpqHz11Vdx+vRpPPLII3j99detNv26yNbWVvl/adAzmUwV1m/atCkAmH1X9Xq90nfl8fHxQWBgIIKCgvDss89i5MiRmD59Oq5evVqmbv/+/bFq1SrMnj0b/fv3r9YyqWX79u344IMP8M0336BDhw4YMGCAEjCaNm2KY8eOmd1w7+LigsDAQHh7e5eZllarVdZp69atkZCQgC5dumDq1KlWa6+TkxN27dqFzz//HJ6enhg7dixCQkJq3ZOW900YuXHjBj777DNMnz5dSaKlKd7Lywuff/45goKC8Msvv5iN9/PPP5u937ZtG4YPH44ePXqgZcuW0Ov1OHfuXKXzt7GxAQBcuXIFABAUFIRt27aVmXazZs1gY2ODoKAg3Lhxw6w958+fR2ZmJoKDg5UyHx8fDB48GGvXrsVrr72m7Ex1Oh0AKGdiaoOGDRuiW7dumDVrFoqKiiwef9u2bejYsSNeeeUVtGnTBoGBgTh69Kgy3NnZGZ6enmbr7MaNG9i5c2el09ZoNNBqtWb9s2fPHrN2btu2DVqtFs2bN4fRaISXl1e5fXhr/xiNRsTExODjjz/GypUrsWbNGvzxxx8Abu4galP/NGjQANHR0Zg9e3a5/XPx4kXs3LkTJpMJ06dPx1/+8hc0a9aszBNpOp2uystV3vciNTXV7Ohx27ZtcHJyQuPGjREQEACdTme23q9fv44dO3aYrXc3NzfExcVh6dKlSEpKwvz585W2AbXre1FdzZs3x759+8zOJu7YscPi6ZTXX48++igaNGjwp3aKNjY2uHHjRrkhtWXLlmjZsiV+++039O3bt9rzuNsuX76Mfv36YciQIejatSsWLFiAtLQ0zJ07FwDw3HPPobCwEHPmzKn2PGxsbMy+D5XtByrblwA3zxBHRUXhn//8J/bu3Yvs7Gxs2rQJgGXf1xql7lWiu2fdunWi0+nKvZFz1KhR0q5dO1mxYoUYDAZZuHChZGZmytixY8vcwNqmTRvp1q2bHDhwQH7++Wfp1KmT2NnZmd2w6uvrKxMnTpScnBw5ffq0/PLLL9K5c2dxc3OTc+fOiYjIzp07zW46Wrx4cZkbWB9//HEJDg6WrVu3Snp6unTv3t3sxqURI0ZIcnKyHDt2THbu3Cnh4eHSp08fEbl5I6BGo5HFixfLmTNnzJ4CUdORI0fE3d1dWrRoIStWrJADBw7IwYMHZcmSJeLu7i4JCQkiUv79FDNnzhSj0SjJycmSmZkp77zzjhiNRrP+ef/996VBgwaybt06ycjIkEGDBpV7A2v37t2VG7YOHDggr7zyimg0GuX+oaKiIvH09JSnn35a9u3bJ5s2bRJ/f3+zG1g/+OADMRqNsmLFCjl48KC8+eabZjewTp8+XZYvXy4ZGRmSmZkpAwYMEA8PD+Um2aZNm8qQIUMkJyfH7Nq8mo4ePSoeHh4SHBwsq1evlkOHDsmBAwdk5syZ0qJFC0lPTxcAkpSUJEePHpXPPvtMvL29ze5P2rZtm3KfwtmzZ6WoqEhEbl6bvvVGufT0dHn66afFYDAoT3eU3sA6dOhQycjIkC+++KLMDawjRowQLy8v2bhxo9kNrKXr8N1335UvvvhCDh8+LL/99pv06tVLOnToICI37yGys7OTyZMnS25ubq24sft2cXFx0qVLF9m9e7fZ68SJE+XewBobGysHDhyQ5ORkadGihQBQnu4o796x3bt3mz01sWzZMnFwcJDdu3fL2bNn5erVqyIisnbtWrG1tZUePXpIcnKyHD16VPbs2SNTp04VAMpNwaX3jJTeFHzy5EnZsGGDeHt7m92cfPu9KYWFhWbtqgv3jAwfPlwCAwOVz7SIyNy5c8XR0VFZn6+99prY2NjIq6++Klu3bpXs7GxJTU2VF154QTQajeTn54vIzXtGbr3R+9ixYzJv3jyxsbGRCRMmKNOvbD9Q2b7k66+/lpkzZ8ru3bslOztb5syZI1qtVn777TcRERk0aJC0b99esrKy5OzZs8r26W67b8JIr169pEePHuUOK71xb8+ePTJlyhRxdXUVR0dHiYuLk1GjRpl9gXbt2iXt2rUTg8EgTZs2lVWrVpV5eub2xzbd3NykR48eZW6aK30cy9bWVh544AGZNm2a2fDSR7qcnZ3Fzs5OoqOjzR7p+sc//iEBAQGi1+vFzc1NXnzxRSXsiIhMnDhRPDw8RKPR1JpHe0VETp8+Lf/4xz+kSZMmYmtrK46OjtKhQweZNm2a8iUvL4xcvXpV+vXrJ87OzuLi4iJDhgyR0aNHm/XP9evXZcSIEWI0GsXFxUUSEhLKfbT31v5xcnKS9u3by+rVq83mV5VHe8ePHy/e3t5ia2tb5tHe+fPnS2hoqDg4OIjRaJRHHnlEdu3apQz/6quvJDAwUOrVq1drHu0Vudk/Q4cOVW7E9vb2lr/97W9KUJsxY4Z4enoqn8nPPvuszA5v8ODB0rBhwzKP9t663uvXry+dO3eWTZs2mc2/skd7r1y5IsOGDRNXV9dyH+2dNGmSBAUFiZ2dnTRo0EAef/xxOXbsmDL8448/Fh8fH9FqtbVy51fe45YAZMCAAeU+2tu6dWvR6XQSFhYmy5cvFwBKuKtKGLl69ao8/fTT4uLiojzhVWrHjh3yzDPPSKNGjaRevXrSsGFDiY6OlhUrVpR5tLf0ZWNjI40bN5ZBgwaZPSVW3o2yt6rtYeTHH38UGxsb2bp1a5lhjz76qNnN6itXrpQuXbqIs7Oz2NraSuPGjaVv377y888/K+Pc/li1Xq+XZs2ayZQpU8yeaKlsPyBy533J1q1bpXPnzlK/fn2xs7OT1q1bmz2BmJmZKX/5y1/Ezs5O1Ud7NSJVvGuNiIhqtWXLliE+Ph75+fll7sEiqs3qqd0AIiKqns8++wz+/v7w9vbGnj178Oabb6JPnz4MIlTnMIwQEdVRubm5GDt2LHJzc+Hp6Ylnn30WU6ZMUbtZRBbjZRoiIiJS1X3zaC8RERHVTgwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFX/D1bP9wIEaFbSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# algorithm comparison\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison between different Moon scores')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ylim(0.3, 1)\n",
    "plt.boxplot(moon_scores, showmeans=True)\n",
    "ax.set_xticklabels(model_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_results['Moon'] = moon_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>DNA</th>\n",
       "      <th>Moon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>96.224256</td>\n",
       "      <td>96.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>96.079878</td>\n",
       "      <td>97.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>95.991808</td>\n",
       "      <td>97.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>95.954289</td>\n",
       "      <td>97.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>96.512943</td>\n",
       "      <td>96.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Names        DNA    Moon\n",
       "0   AdaBoost  96.224256  96.948\n",
       "1  GradBoost  96.079878  97.024\n",
       "2   CatBoost  95.991808  97.062\n",
       "3   LightGBM  95.954289  97.160\n",
       "4    XGBoost  96.512943  96.508"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Algo_ult_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_ult_time_results['Moon'] = pd.Series(execution_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Wine</th>\n",
       "      <th>Moon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>877.854318</td>\n",
       "      <td>304.634132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>2370.683348</td>\n",
       "      <td>572.574119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>584.760997</td>\n",
       "      <td>19.937263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>13.880130</td>\n",
       "      <td>4.116436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>490.302212</td>\n",
       "      <td>10.219701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Names         Wine        Moon\n",
       "0   AdaBoost   877.854318  304.634132\n",
       "1  GradBoost  2370.683348  572.574119\n",
       "2   CatBoost   584.760997   19.937263\n",
       "3   LightGBM    13.880130    4.116436\n",
       "4    XGBoost   490.302212   10.219701"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Algo_ult_time_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlgoComparison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
